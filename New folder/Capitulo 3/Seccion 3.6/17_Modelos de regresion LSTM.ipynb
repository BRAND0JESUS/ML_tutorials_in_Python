{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. Modelos de regresion con LSTM\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso de estudio #1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tecnicas de ajuste de los datos y modelos:\n",
    "\n",
    "| Ingeniería de datos       | Si / No       |\n",
    "| :-------                  | :------:    |\n",
    "| Escalado de datos         | Si          |\n",
    "| Sobremuestreo  | No        |\n",
    "| Incluir variable ciclo | Si        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# librerias\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(0)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from plot_metric.functions import BinaryClassification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "keras.backend.clear_session()\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "from sklearn import datasets \n",
    "from keras.models import model_from_json\n",
    "\n",
    "from numba import cuda\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import TimeDistributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para calcular metricas de desempeño\n",
    "\n",
    "def regression_metrics(y_test, y_pred2):\n",
    "    # Mean Deviation (MD)\n",
    "    MD=np.mean(y_test - y_pred2)\n",
    "    # mean absolute error\n",
    "    MAE=mean_absolute_error(y_test,y_pred2)\n",
    "    # Mean Squared Error (MSE)\n",
    "    MSE=mean_squared_error(y_test,y_pred2)\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    RMSE= sqrt(mean_squared_error(y_test,y_pred2))\n",
    "    # Mean Percent Error (MPE)\n",
    "    MPE=np.mean((y_test - y_pred2) / y_test) * 100\n",
    "    # Mean Absolute Percent Error (MAPE)\n",
    "    MAPE=np.mean(np.abs((y_test - y_pred2) / y_test)) * 100\n",
    "    print('\\n')\n",
    "    print(\"METRICAS DE DESEMPEÑO DEL MODELO DE REGRESION\")\n",
    "    print('-'*60)\n",
    "    print(f'Mean Deviation (MD): {round(MD,2)}') \n",
    "    print(f'Mean Absolute Error (MAE): {round(MAE,2)}')\n",
    "    print('-'*60)\n",
    "    print(f'Mean Squared Error (MSE): {round(MSE,2)}') \n",
    "    print(f'Root Mean Squared Error (RMSE): {round(RMSE,2)}')\n",
    "    print('-'*60)    \n",
    "    print(f'Mean Percent Error (MPE): {round(MPE,2)}') \n",
    "    print(f'Mean Absolute Percent Error (MAPE): {round(MAPE,2)}')\n",
    "    print('-'*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ciclo</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "      <th>ttf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ciclo    set1    set2   set3  sensor1  sensor2  sensor3  sensor4  \\\n",
       "0   1      1 -0.0007 -0.0004  100.0   518.67   641.82  1589.70  1400.60   \n",
       "1   1      2  0.0019 -0.0003  100.0   518.67   642.15  1591.82  1403.14   \n",
       "2   1      3 -0.0043  0.0003  100.0   518.67   642.35  1587.99  1404.20   \n",
       "3   1      4  0.0007  0.0000  100.0   518.67   642.35  1582.79  1401.87   \n",
       "4   1      5 -0.0019 -0.0002  100.0   518.67   642.37  1582.85  1406.22   \n",
       "\n",
       "   sensor5  ...  sensor13  sensor14  sensor15  sensor16  sensor17  sensor18  \\\n",
       "0    14.62  ...   2388.02   8138.62    8.4195      0.03       392      2388   \n",
       "1    14.62  ...   2388.07   8131.49    8.4318      0.03       392      2388   \n",
       "2    14.62  ...   2388.03   8133.23    8.4178      0.03       390      2388   \n",
       "3    14.62  ...   2388.08   8133.83    8.3682      0.03       392      2388   \n",
       "4    14.62  ...   2388.04   8133.80    8.4294      0.03       393      2388   \n",
       "\n",
       "   sensor19  sensor20  sensor21  ttf  \n",
       "0     100.0     39.06   23.4190  191  \n",
       "1     100.0     39.00   23.4236  190  \n",
       "2     100.0     38.95   23.3442  189  \n",
       "3     100.0     38.88   23.3739  188  \n",
       "4     100.0     38.90   23.4044  187  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=[\"id\",\"ciclo\",\"set1\",\"set2\",\"set3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]\n",
    "train=pd.read_csv(\"train_FD001.txt\",sep=\" \",names=columns)\n",
    "test=pd.read_csv(\"test_FD001.txt\",sep=\" \",names=columns)\n",
    "rul=pd.read_csv(\"RUL_FD001.txt\",sep=\" \",header=None)\n",
    "train.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "test.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "rul.drop([1], axis=1, inplace=True)\n",
    "rul.columns = ['ttf']\n",
    "rul2=pd.DataFrame(train.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul2.columns = ['id', 'falla']\n",
    "train= train.merge(rul2, on=['id'], how='left')\n",
    "train['ttf'] = train['falla'] - train['ciclo']\n",
    "train.drop('falla', axis=1, inplace=True)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ciclo</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "      <th>ttf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8125.55</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ciclo    set1    set2   set3  sensor1  sensor2  sensor3  sensor4  \\\n",
       "0   1      1  0.0023  0.0003  100.0   518.67   643.02  1585.29  1398.21   \n",
       "1   1      2 -0.0027 -0.0003  100.0   518.67   641.71  1588.45  1395.42   \n",
       "2   1      3  0.0003  0.0001  100.0   518.67   642.46  1586.94  1401.34   \n",
       "3   1      4  0.0042  0.0000  100.0   518.67   642.44  1584.12  1406.42   \n",
       "4   1      5  0.0014  0.0000  100.0   518.67   642.51  1587.19  1401.92   \n",
       "\n",
       "   sensor5  ...  sensor13  sensor14  sensor15  sensor16  sensor17  sensor18  \\\n",
       "0    14.62  ...   2388.03   8125.55    8.4052      0.03       392      2388   \n",
       "1    14.62  ...   2388.06   8139.62    8.3803      0.03       393      2388   \n",
       "2    14.62  ...   2388.03   8130.10    8.4441      0.03       393      2388   \n",
       "3    14.62  ...   2388.05   8132.90    8.3917      0.03       391      2388   \n",
       "4    14.62  ...   2388.03   8129.54    8.4031      0.03       390      2388   \n",
       "\n",
       "   sensor19  sensor20  sensor21  ttf  \n",
       "0     100.0     38.86   23.3735  142  \n",
       "1     100.0     39.02   23.3916  141  \n",
       "2     100.0     39.08   23.4166  140  \n",
       "3     100.0     39.00   23.3737  139  \n",
       "4     100.0     38.99   23.4130  138  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rul3=pd.DataFrame(test.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul3.columns = ['id', 'falla']\n",
    "rul['id'] = rul.index + 1\n",
    "rul['falla'] = rul3['falla'] + rul['ttf']\n",
    "rul.drop('ttf', axis=1, inplace=True)\n",
    "test=test.merge(rul, on=['id'], how='left')\n",
    "test['ttf'] = test['falla'] - test['ciclo']\n",
    "test.drop('falla', axis=1, inplace=True)\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=['ciclo','set1','set2','set3','sensor1','sensor2','sensor3','sensor4','sensor5','sensor6','sensor7','sensor8','sensor9','sensor10','sensor11','sensor12','sensor13','sensor14','sensor15','sensor16','sensor17','sensor18','sensor19','sensor20','sensor21','ttf']\n",
    "\n",
    "objetivo='ttf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizado de datos \n",
    "scaler = MinMaxScaler()\n",
    "train[variables]=scaler.fit_transform(train[variables])\n",
    "test[variables]=scaler.transform(test[variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ciclo</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "      <th>ttf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>0.529086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>0.523546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00831</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>0.520776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01108</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>0.518006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ciclo      set1      set2  set3  sensor1   sensor2   sensor3   sensor4  \\\n",
       "0  0.00000  0.459770  0.166667   0.0      0.0  0.183735  0.406802  0.309757   \n",
       "1  0.00277  0.609195  0.250000   0.0      0.0  0.283133  0.453019  0.352633   \n",
       "2  0.00554  0.252874  0.750000   0.0      0.0  0.343373  0.369523  0.370527   \n",
       "3  0.00831  0.540230  0.500000   0.0      0.0  0.343373  0.256159  0.331195   \n",
       "4  0.01108  0.390805  0.333333   0.0      0.0  0.349398  0.257467  0.404625   \n",
       "\n",
       "   sensor5  sensor6  ...  sensor13  sensor14  sensor15  sensor16  sensor17  \\\n",
       "0      0.0      1.0  ...  0.205882  0.199608  0.363986       0.0  0.333333   \n",
       "1      0.0      1.0  ...  0.279412  0.162813  0.411312       0.0  0.333333   \n",
       "2      0.0      1.0  ...  0.220588  0.171793  0.357445       0.0  0.166667   \n",
       "3      0.0      1.0  ...  0.294118  0.174889  0.166603       0.0  0.333333   \n",
       "4      0.0      1.0  ...  0.235294  0.174734  0.402078       0.0  0.416667   \n",
       "\n",
       "   sensor18  sensor19  sensor20  sensor21       ttf  \n",
       "0       0.0       0.0  0.713178  0.724662  0.529086  \n",
       "1       0.0       0.0  0.666667  0.731014  0.526316  \n",
       "2       0.0       0.0  0.627907  0.621375  0.523546  \n",
       "3       0.0       0.0  0.573643  0.662386  0.520776  \n",
       "4       0.0       0.0  0.589147  0.704502  0.518006  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ciclo</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "      <th>ttf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.132160</td>\n",
       "      <td>0.308965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>0.393352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "      <td>0.390582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "      <td>0.387812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00831</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.170090</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>0.385042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01108</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.152751</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.382271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ciclo      set1      set2  set3  sensor1   sensor2   sensor3   sensor4  \\\n",
       "0  0.00000  0.632184  0.750000   0.0      0.0  0.545181  0.310661  0.269413   \n",
       "1  0.00277  0.344828  0.250000   0.0      0.0  0.150602  0.379551  0.222316   \n",
       "2  0.00554  0.517241  0.583333   0.0      0.0  0.376506  0.346632  0.322248   \n",
       "3  0.00831  0.741379  0.500000   0.0      0.0  0.370482  0.285154  0.408001   \n",
       "4  0.01108  0.580460  0.500000   0.0      0.0  0.391566  0.352082  0.332039   \n",
       "\n",
       "   sensor5  sensor6  ...  sensor13  sensor14  sensor15  sensor16  sensor17  \\\n",
       "0      0.0      1.0  ...  0.220588  0.132160  0.308965       0.0  0.333333   \n",
       "1      0.0      1.0  ...  0.264706  0.204768  0.213159       0.0  0.416667   \n",
       "2      0.0      1.0  ...  0.220588  0.155640  0.458638       0.0  0.416667   \n",
       "3      0.0      1.0  ...  0.250000  0.170090  0.257022       0.0  0.250000   \n",
       "4      0.0      1.0  ...  0.220588  0.152751  0.300885       0.0  0.166667   \n",
       "\n",
       "   sensor18  sensor19  sensor20  sensor21       ttf  \n",
       "0       0.0       0.0  0.558140  0.661834  0.393352  \n",
       "1       0.0       0.0  0.682171  0.686827  0.390582  \n",
       "2       0.0       0.0  0.728682  0.721348  0.387812  \n",
       "3       0.0       0.0  0.666667  0.662110  0.385042  \n",
       "4       0.0       0.0  0.658915  0.716377  0.382271  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de dimensiones = 2\n",
      "tamaño de la tabla = (20631, 26)\n",
      "total datos = 536406\n"
     ]
    }
   ],
   "source": [
    "print(\"numero de dimensiones =\", train.ndim)\n",
    "print(\"tamaño de la tabla =\", train.shape)\n",
    "print(\"total datos =\", train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de dimensiones = 2\n",
      "tamaño de la tabla = (13096, 26)\n",
      "total datos = 340496\n"
     ]
    }
   ],
   "source": [
    "print(\"numero de dimensiones =\", test.ndim)\n",
    "print(\"tamaño de la tabla =\", test.shape)\n",
    "print(\"total datos =\", test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ciclo</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633262</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795309</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00831</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889126</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01108</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ciclo      set1      set2  set3  sensor1   sensor2   sensor3   sensor4  \\\n",
       "0  0.00000  0.459770  0.166667   0.0      0.0  0.183735  0.406802  0.309757   \n",
       "1  0.00277  0.609195  0.250000   0.0      0.0  0.283133  0.453019  0.352633   \n",
       "2  0.00554  0.252874  0.750000   0.0      0.0  0.343373  0.369523  0.370527   \n",
       "3  0.00831  0.540230  0.500000   0.0      0.0  0.343373  0.256159  0.331195   \n",
       "4  0.01108  0.390805  0.333333   0.0      0.0  0.349398  0.257467  0.404625   \n",
       "\n",
       "   sensor5  sensor6  ...  sensor12  sensor13  sensor14  sensor15  sensor16  \\\n",
       "0      0.0      1.0  ...  0.633262  0.205882  0.199608  0.363986       0.0   \n",
       "1      0.0      1.0  ...  0.765458  0.279412  0.162813  0.411312       0.0   \n",
       "2      0.0      1.0  ...  0.795309  0.220588  0.171793  0.357445       0.0   \n",
       "3      0.0      1.0  ...  0.889126  0.294118  0.174889  0.166603       0.0   \n",
       "4      0.0      1.0  ...  0.746269  0.235294  0.174734  0.402078       0.0   \n",
       "\n",
       "   sensor17  sensor18  sensor19  sensor20  sensor21  \n",
       "0  0.333333       0.0       0.0  0.713178  0.724662  \n",
       "1  0.333333       0.0       0.0  0.666667  0.731014  \n",
       "2  0.166667       0.0       0.0  0.627907  0.621375  \n",
       "3  0.333333       0.0       0.0  0.573643  0.662386  \n",
       "4  0.416667       0.0       0.0  0.589147  0.704502  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=train.iloc[:,np.r_[0:25]]\n",
    "x_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ciclo</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646055</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.132160</td>\n",
       "      <td>0.308965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739872</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699360</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00831</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573561</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.170090</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01108</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737740</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.152751</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ciclo      set1      set2  set3  sensor1   sensor2   sensor3   sensor4  \\\n",
       "0  0.00000  0.632184  0.750000   0.0      0.0  0.545181  0.310661  0.269413   \n",
       "1  0.00277  0.344828  0.250000   0.0      0.0  0.150602  0.379551  0.222316   \n",
       "2  0.00554  0.517241  0.583333   0.0      0.0  0.376506  0.346632  0.322248   \n",
       "3  0.00831  0.741379  0.500000   0.0      0.0  0.370482  0.285154  0.408001   \n",
       "4  0.01108  0.580460  0.500000   0.0      0.0  0.391566  0.352082  0.332039   \n",
       "\n",
       "   sensor5  sensor6  ...  sensor12  sensor13  sensor14  sensor15  sensor16  \\\n",
       "0      0.0      1.0  ...  0.646055  0.220588  0.132160  0.308965       0.0   \n",
       "1      0.0      1.0  ...  0.739872  0.264706  0.204768  0.213159       0.0   \n",
       "2      0.0      1.0  ...  0.699360  0.220588  0.155640  0.458638       0.0   \n",
       "3      0.0      1.0  ...  0.573561  0.250000  0.170090  0.257022       0.0   \n",
       "4      0.0      1.0  ...  0.737740  0.220588  0.152751  0.300885       0.0   \n",
       "\n",
       "   sensor17  sensor18  sensor19  sensor20  sensor21  \n",
       "0  0.333333       0.0       0.0  0.558140  0.661834  \n",
       "1  0.416667       0.0       0.0  0.682171  0.686827  \n",
       "2  0.416667       0.0       0.0  0.728682  0.721348  \n",
       "3  0.250000       0.0       0.0  0.666667  0.662110  \n",
       "4  0.166667       0.0       0.0  0.658915  0.716377  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test=test.iloc[:,np.r_[0:25]]\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.529086\n",
       "1    0.526316\n",
       "2    0.523546\n",
       "3    0.520776\n",
       "4    0.518006\n",
       "Name: ttf, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=train.iloc[:,25]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.393352\n",
       "1    0.390582\n",
       "2    0.387812\n",
       "3    0.385042\n",
       "4    0.382271\n",
       "Name: ttf, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=test.iloc[:,25]\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar datos para LSTM (Reshape Subsequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to numpy array\n",
    "x_test=x_test.to_numpy()\n",
    "x_train=x_train.to_numpy()\n",
    "y_test=y_test.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 25)\n",
      "(20631,)\n",
      "(13096, 25)\n",
      "(13096,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tecnica para convertir datos 2d a 3d (observaciones, variables) => (observaciones, pasos de tiempo, variables)\n",
    "# reshape  = [samples, timesteps, features] \n",
    "n_steps = 1\n",
    "x_train = x_train.reshape((x_train.shape[0], n_steps, x_train.shape[1])) \n",
    "x_test = x_test.reshape((x_test.shape[0], n_steps, x_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 1, 25)\n",
      "(20631,)\n",
      "(13096, 1, 25)\n",
      "(13096,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de dimensiones x_train = 3\n",
      "tamaño de la tabla x_train = (20631, 1, 25)\n",
      "total datos x_train = 515775\n",
      "------------------------------------------------------------\n",
      "numero de dimensiones y_train = 1\n",
      "tamaño de la tabla y_train = (20631,)\n",
      "total datos y_train = 20631\n",
      "------------------------------------------------------------\n",
      "numero de dimensiones x_test = 3\n",
      "tamaño de la tabla x_test = (13096, 1, 25)\n",
      "total datos x_test = 327400\n",
      "------------------------------------------------------------\n",
      "numero de dimensiones y_test = 1\n",
      "tamaño de la tabla y_test = (13096,)\n",
      "total datos y_test = 13096\n"
     ]
    }
   ],
   "source": [
    "print(\"numero de dimensiones x_train =\", x_train.ndim)\n",
    "print(\"tamaño de la tabla x_train =\", x_train.shape)\n",
    "print(\"total datos x_train =\", x_train.size)\n",
    "print('-'*60)\n",
    "print(\"numero de dimensiones y_train =\", y_train.ndim)\n",
    "print(\"tamaño de la tabla y_train =\", y_train.shape)\n",
    "print(\"total datos y_train =\", y_train.size)\n",
    "print('-'*60)\n",
    "print(\"numero de dimensiones x_test =\", x_test.ndim)\n",
    "print(\"tamaño de la tabla x_test =\", x_test.shape)\n",
    "print(\"total datos x_test =\", x_test.size)\n",
    "print('-'*60)\n",
    "print(\"numero de dimensiones y_test =\", y_test.ndim)\n",
    "print(\"tamaño de la tabla y_test =\", y_test.shape)\n",
    "print(\"total datos y_test =\", y_test.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de regresion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 20631 samples, validate on 13096 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 0.1081 - val_loss: 0.1511\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15108, saving model to regresion2_model.h5\n",
      "Epoch 2/100\n",
      " - 4s - loss: 0.0925 - val_loss: 0.1157\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15108 to 0.11572, saving model to regresion2_model.h5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.0910 - val_loss: 0.0993\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11572 to 0.09930, saving model to regresion2_model.h5\n",
      "Epoch 4/100\n",
      " - 4s - loss: 0.0903 - val_loss: 0.0954\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09930 to 0.09543, saving model to regresion2_model.h5\n",
      "Epoch 5/100\n",
      " - 4s - loss: 0.0895 - val_loss: 0.0948\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.09543 to 0.09482, saving model to regresion2_model.h5\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.0887 - val_loss: 0.0952\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09482\n",
      "Epoch 7/100\n",
      " - 4s - loss: 0.0879 - val_loss: 0.0956\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09482\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.0870 - val_loss: 0.0951\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09482\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.0862 - val_loss: 0.0944\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09482 to 0.09439, saving model to regresion2_model.h5\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.0855 - val_loss: 0.0938\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09439 to 0.09379, saving model to regresion2_model.h5\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.0847 - val_loss: 0.0941\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.09379\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.0840 - val_loss: 0.0941\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.09379\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.0833 - val_loss: 0.0936\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.09379 to 0.09358, saving model to regresion2_model.h5\n",
      "Epoch 14/100\n",
      " - 4s - loss: 0.0827 - val_loss: 0.0933\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09358 to 0.09330, saving model to regresion2_model.h5\n",
      "Epoch 15/100\n",
      " - 4s - loss: 0.0822 - val_loss: 0.0933\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.09330 to 0.09329, saving model to regresion2_model.h5\n",
      "Epoch 16/100\n",
      " - 4s - loss: 0.0816 - val_loss: 0.0932\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.09329 to 0.09317, saving model to regresion2_model.h5\n",
      "Epoch 17/100\n",
      " - 4s - loss: 0.0811 - val_loss: 0.0925\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.09317 to 0.09247, saving model to regresion2_model.h5\n",
      "Epoch 18/100\n",
      " - 4s - loss: 0.0806 - val_loss: 0.0920\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.09247 to 0.09200, saving model to regresion2_model.h5\n",
      "Epoch 19/100\n",
      " - 4s - loss: 0.0803 - val_loss: 0.0915\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.09200 to 0.09147, saving model to regresion2_model.h5\n",
      "Epoch 20/100\n",
      " - 4s - loss: 0.0798 - val_loss: 0.0910\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.09147 to 0.09104, saving model to regresion2_model.h5\n",
      "Epoch 21/100\n",
      " - 4s - loss: 0.0794 - val_loss: 0.0905\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.09104 to 0.09055, saving model to regresion2_model.h5\n",
      "Epoch 22/100\n",
      " - 4s - loss: 0.0790 - val_loss: 0.0904\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.09055 to 0.09035, saving model to regresion2_model.h5\n",
      "Epoch 23/100\n",
      " - 4s - loss: 0.0786 - val_loss: 0.0899\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.09035 to 0.08993, saving model to regresion2_model.h5\n",
      "Epoch 24/100\n",
      " - 4s - loss: 0.0782 - val_loss: 0.0897\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.08993 to 0.08967, saving model to regresion2_model.h5\n",
      "Epoch 25/100\n",
      " - 4s - loss: 0.0779 - val_loss: 0.0895\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.08967 to 0.08949, saving model to regresion2_model.h5\n",
      "Epoch 26/100\n",
      " - 4s - loss: 0.0775 - val_loss: 0.0893\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.08949 to 0.08934, saving model to regresion2_model.h5\n",
      "Epoch 27/100\n",
      " - 4s - loss: 0.0773 - val_loss: 0.0890\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.08934 to 0.08904, saving model to regresion2_model.h5\n",
      "Epoch 28/100\n",
      " - 4s - loss: 0.0770 - val_loss: 0.0889\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.08904 to 0.08895, saving model to regresion2_model.h5\n",
      "Epoch 29/100\n",
      " - 4s - loss: 0.0767 - val_loss: 0.0888\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.08895 to 0.08875, saving model to regresion2_model.h5\n",
      "Epoch 30/100\n",
      " - 4s - loss: 0.0764 - val_loss: 0.0885\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.08875 to 0.08851, saving model to regresion2_model.h5\n",
      "Epoch 31/100\n",
      " - 4s - loss: 0.0762 - val_loss: 0.0881\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.08851 to 0.08814, saving model to regresion2_model.h5\n",
      "Epoch 32/100\n",
      " - 4s - loss: 0.0760 - val_loss: 0.0878\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.08814 to 0.08784, saving model to regresion2_model.h5\n",
      "Epoch 33/100\n",
      " - 4s - loss: 0.0758 - val_loss: 0.0875\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.08784 to 0.08754, saving model to regresion2_model.h5\n",
      "Epoch 34/100\n",
      " - 4s - loss: 0.0756 - val_loss: 0.0873\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.08754 to 0.08726, saving model to regresion2_model.h5\n",
      "Epoch 35/100\n",
      " - 4s - loss: 0.0754 - val_loss: 0.0871\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.08726 to 0.08705, saving model to regresion2_model.h5\n",
      "Epoch 36/100\n",
      " - 4s - loss: 0.0753 - val_loss: 0.0870\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.08705 to 0.08700, saving model to regresion2_model.h5\n",
      "Epoch 37/100\n",
      " - 4s - loss: 0.0751 - val_loss: 0.0868\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.08700 to 0.08676, saving model to regresion2_model.h5\n",
      "Epoch 38/100\n",
      " - 4s - loss: 0.0750 - val_loss: 0.0867\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.08676 to 0.08665, saving model to regresion2_model.h5\n",
      "Epoch 39/100\n",
      " - 4s - loss: 0.0748 - val_loss: 0.0866\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.08665 to 0.08665, saving model to regresion2_model.h5\n",
      "Epoch 40/100\n",
      " - 4s - loss: 0.0747 - val_loss: 0.0865\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.08665 to 0.08648, saving model to regresion2_model.h5\n",
      "Epoch 41/100\n",
      " - 4s - loss: 0.0746 - val_loss: 0.0863\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.08648 to 0.08634, saving model to regresion2_model.h5\n",
      "Epoch 42/100\n",
      " - 4s - loss: 0.0745 - val_loss: 0.0863\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.08634 to 0.08627, saving model to regresion2_model.h5\n",
      "Epoch 43/100\n",
      " - 4s - loss: 0.0743 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.08627 to 0.08612, saving model to regresion2_model.h5\n",
      "Epoch 44/100\n",
      " - 4s - loss: 0.0742 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.08612 to 0.08601, saving model to regresion2_model.h5\n",
      "Epoch 45/100\n",
      " - 4s - loss: 0.0741 - val_loss: 0.0859\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.08601 to 0.08592, saving model to regresion2_model.h5\n",
      "Epoch 46/100\n",
      " - 4s - loss: 0.0740 - val_loss: 0.0857\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08592 to 0.08572, saving model to regresion2_model.h5\n",
      "Epoch 47/100\n",
      " - 4s - loss: 0.0740 - val_loss: 0.0857\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.08572 to 0.08567, saving model to regresion2_model.h5\n",
      "Epoch 48/100\n",
      " - 4s - loss: 0.0739 - val_loss: 0.0856\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.08567 to 0.08563, saving model to regresion2_model.h5\n",
      "Epoch 49/100\n",
      " - 4s - loss: 0.0738 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.08563 to 0.08551, saving model to regresion2_model.h5\n",
      "Epoch 50/100\n",
      " - 5s - loss: 0.0737 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.08551 to 0.08546, saving model to regresion2_model.h5\n",
      "Epoch 51/100\n",
      " - 4s - loss: 0.0737 - val_loss: 0.0854\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.08546 to 0.08543, saving model to regresion2_model.h5\n",
      "Epoch 52/100\n",
      " - 5s - loss: 0.0736 - val_loss: 0.0853\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.08543 to 0.08535, saving model to regresion2_model.h5\n",
      "Epoch 53/100\n",
      " - 4s - loss: 0.0735 - val_loss: 0.0853\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.08535 to 0.08529, saving model to regresion2_model.h5\n",
      "Epoch 54/100\n",
      " - 4s - loss: 0.0735 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.08529 to 0.08524, saving model to regresion2_model.h5\n",
      "Epoch 55/100\n",
      " - 4s - loss: 0.0734 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.08524 to 0.08523, saving model to regresion2_model.h5\n",
      "Epoch 56/100\n",
      " - 4s - loss: 0.0733 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.08523 to 0.08515, saving model to regresion2_model.h5\n",
      "Epoch 57/100\n",
      " - 4s - loss: 0.0732 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.08515 to 0.08513, saving model to regresion2_model.h5\n",
      "Epoch 58/100\n",
      " - 4s - loss: 0.0732 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.08513 to 0.08510, saving model to regresion2_model.h5\n",
      "Epoch 59/100\n",
      " - 4s - loss: 0.0731 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.08510 to 0.08509, saving model to regresion2_model.h5\n",
      "Epoch 60/100\n",
      " - 4s - loss: 0.0730 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08509 to 0.08506, saving model to regresion2_model.h5\n",
      "Epoch 61/100\n",
      " - 4s - loss: 0.0730 - val_loss: 0.0850\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08506 to 0.08496, saving model to regresion2_model.h5\n",
      "Epoch 62/100\n",
      " - 4s - loss: 0.0729 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08496 to 0.08486, saving model to regresion2_model.h5\n",
      "Epoch 63/100\n",
      " - 4s - loss: 0.0729 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08486 to 0.08486, saving model to regresion2_model.h5\n",
      "Epoch 64/100\n",
      " - 4s - loss: 0.0728 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08486 to 0.08483, saving model to regresion2_model.h5\n",
      "Epoch 65/100\n",
      " - 4s - loss: 0.0727 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08483 to 0.08479, saving model to regresion2_model.h5\n",
      "Epoch 66/100\n",
      " - 4s - loss: 0.0727 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08479 to 0.08473, saving model to regresion2_model.h5\n",
      "Epoch 67/100\n",
      " - 4s - loss: 0.0726 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.08473\n",
      "Epoch 68/100\n",
      " - 4s - loss: 0.0725 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08473 to 0.08471, saving model to regresion2_model.h5\n",
      "Epoch 69/100\n",
      " - 4s - loss: 0.0725 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.08471\n",
      "Epoch 70/100\n",
      " - 4s - loss: 0.0724 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.08471 to 0.08471, saving model to regresion2_model.h5\n",
      "Epoch 71/100\n",
      " - 4s - loss: 0.0723 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08471\n",
      "Epoch 72/100\n",
      " - 4s - loss: 0.0723 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08471\n",
      "Epoch 73/100\n",
      " - 4s - loss: 0.0722 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08471\n",
      "Epoch 74/100\n",
      " - 4s - loss: 0.0722 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.08471\n",
      "Epoch 75/100\n",
      " - 4s - loss: 0.0721 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.08471 to 0.08470, saving model to regresion2_model.h5\n",
      "Epoch 76/100\n",
      " - 4s - loss: 0.0721 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08470 to 0.08467, saving model to regresion2_model.h5\n",
      "Epoch 77/100\n",
      " - 4s - loss: 0.0720 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.08467 to 0.08467, saving model to regresion2_model.h5\n",
      "Epoch 78/100\n",
      " - 4s - loss: 0.0720 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.08467\n",
      "Epoch 79/100\n",
      " - 4s - loss: 0.0719 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.08467\n",
      "Epoch 80/100\n",
      " - 4s - loss: 0.0719 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.08467\n",
      "Epoch 81/100\n",
      " - 4s - loss: 0.0718 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.08467\n",
      "Epoch 82/100\n",
      " - 4s - loss: 0.0718 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.08467\n",
      "Epoch 83/100\n",
      " - 4s - loss: 0.0717 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.08467\n",
      "Epoch 84/100\n",
      " - 4s - loss: 0.0717 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.08467\n",
      "Epoch 85/100\n",
      " - 4s - loss: 0.0716 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.08467\n",
      "Epoch 86/100\n",
      " - 4s - loss: 0.0716 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.08467\n",
      "Epoch 87/100\n",
      " - 4s - loss: 0.0716 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.08467\n",
      "Epoch 00087: early stopping\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "# diseñar la red\n",
    "model_path_clf = 'regresion2_model.h5'  \n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# entrenar el modelo\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test), verbose=2, shuffle=False,\n",
    "            callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=2, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path_clf, monitor='val_loss', save_best_only=True, mode='min', verbose=2)])\n",
    "print(history.history.keys())\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el mejor modelo guardado durante el entrenamiento\n",
    "\n",
    "saved_model = load_model('regresion2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizar prediccion \n",
    "yhat = saved_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5685879 ],\n",
       "       [0.54165906],\n",
       "       [0.51711226],\n",
       "       ...,\n",
       "       [0.0749625 ],\n",
       "       [0.06760633],\n",
       "       [0.04658365]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que los valores de la predicccion estan en formato 3d, se procede a convertir a 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 25)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3d a 2d\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[2]))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape((len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.115\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE en formato normalizado\n",
    "rmse = sqrt(mean_squared_error(y_test, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que los valores de prediccion estan normalizados, se procede a invertir la escala para convertirlos en formato ciclos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invertir escala del pronostico\n",
    "\n",
    "inv_yhat = concatenate((yhat, x_test[:, :]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 26)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5685879 , 0.        , 0.63218391, 0.75      , 0.        ,\n",
       "       0.        , 0.54518072, 0.31066056, 0.26941256, 0.        ,\n",
       "       1.        , 0.65217391, 0.21212121, 0.12761375, 0.        ,\n",
       "       0.20833333, 0.64605544, 0.22058824, 0.13216018, 0.30896499,\n",
       "       0.        , 0.33333333, 0.        , 0.        , 0.55813953,\n",
       "       0.66183375])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat2 = scaler.inverse_transform(inv_yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06260232e+02, -8.70000000e-03,  1.58620690e-04, ...,\n",
       "         3.81400000e+01,  2.32984047e+01,  2.38921983e+02],\n",
       "       [ 1.96538920e+02, -8.65180055e-03, -1.86206897e-04, ...,\n",
       "         3.81400000e+01,  2.33882279e+01,  2.47944490e+02],\n",
       "       [ 1.87677524e+02, -8.60360111e-03,  2.06896552e-05, ...,\n",
       "         3.81400000e+01,  2.34219116e+01,  2.60406518e+02],\n",
       "       ...,\n",
       "       [ 2.80614613e+01,  6.98891967e-04, -4.13793103e-05, ...,\n",
       "         3.81400000e+01,  2.31636698e+01,  1.54977769e+02],\n",
       "       [ 2.54058851e+01,  7.47091413e-04, -2.62068966e-04, ...,\n",
       "         3.81400000e+01,  2.31861256e+01,  1.87279343e+02],\n",
       "       [ 1.78166986e+01,  7.95290859e-04,  8.96551724e-05, ...,\n",
       "         3.81400000e+01,  2.32085814e+01,  1.45207539e+02]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat3 = inv_yhat2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([206.26023161, 196.53891963, 187.67752409, ...,  28.06146133,\n",
       "        25.4058851 ,  17.81669855])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test pronosticado transformado\n",
    "inv_yhat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143., 142., 141., ...,  23.,  22.,  21.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test transformado\n",
    "\n",
    "inv_y = concatenate((y_test, x_test[:,:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "METRICAS DE DESEMPEÑO DEL MODELO DE REGRESION\n",
      "------------------------------------------------------------\n",
      "Mean Deviation (MD): 8.48\n",
      "Mean Absolute Error (MAE): 30.57\n",
      "------------------------------------------------------------\n",
      "Mean Squared Error (MSE): 1718.37\n",
      "Root Mean Squared Error (RMSE): 41.45\n",
      "------------------------------------------------------------\n",
      "Mean Percent Error (MPE): -2.88\n",
      "Mean Absolute Percent Error (MAPE): 23.59\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "regression_metrics(inv_y, inv_yhat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar datos para el nuevo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos de nuevo para el modelo, ya que se habian modificado por escalado y reshape\n",
    "# no hay cambios en los datos, son las mismas lineas de la parte superior del codigo\n",
    "\n",
    "columns=[\"id\",\"ciclo\",\"set1\",\"set2\",\"set3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]\n",
    "train=pd.read_csv(\"train_FD001.txt\",sep=\" \",names=columns)\n",
    "test=pd.read_csv(\"test_FD001.txt\",sep=\" \",names=columns)\n",
    "rul=pd.read_csv(\"RUL_FD001.txt\",sep=\" \",header=None)\n",
    "train.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "test.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "rul.drop([1], axis=1, inplace=True)\n",
    "rul.columns = ['ttf']\n",
    "rul2=pd.DataFrame(train.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul2.columns = ['id', 'falla']\n",
    "train= train.merge(rul2, on=['id'], how='left')\n",
    "train['ttf'] = train['falla'] - train['ciclo']\n",
    "train.drop('falla', axis=1, inplace=True)\n",
    "rul3=pd.DataFrame(test.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul3.columns = ['id', 'falla']\n",
    "rul['id'] = rul.index + 1\n",
    "rul['falla'] = rul3['falla'] + rul['ttf']\n",
    "rul.drop('ttf', axis=1, inplace=True)\n",
    "test=test.merge(rul, on=['id'], how='left')\n",
    "test['ttf'] = test['falla'] - test['ciclo']\n",
    "test.drop('falla', axis=1, inplace=True)\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "variables=['ciclo','set1','set2','set3','sensor1','sensor2','sensor3','sensor4','sensor5','sensor6','sensor7','sensor8','sensor9','sensor10','sensor11','sensor12','sensor13','sensor14','sensor15','sensor16','sensor17','sensor18','sensor19','sensor20','sensor21','ttf']\n",
    "objetivo='ttf'\n",
    "scaler = MinMaxScaler()\n",
    "train[variables]=scaler.fit_transform(train[variables])\n",
    "test[variables]=scaler.transform(test[variables])\n",
    "x_train=train.iloc[:,np.r_[0:25]]\n",
    "x_test=test.iloc[:,np.r_[0:25]]\n",
    "y_train=train.iloc[:,25]\n",
    "y_test=test.iloc[:,25]\n",
    "x_test=x_test.to_numpy()\n",
    "x_train=x_train.to_numpy()\n",
    "y_test=y_test.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "n_steps = 1\n",
    "x_train = x_train.reshape((x_train.shape[0], n_steps, x_train.shape[1])) \n",
    "x_test = x_test.reshape((x_test.shape[0], n_steps, x_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Staked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20631 samples, validate on 13096 samples\n",
      "Epoch 1/50\n",
      " - 12s - loss: 0.1129 - val_loss: 0.1654\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16541, saving model to regresion3_model.h5\n",
      "Epoch 2/50\n",
      " - 11s - loss: 0.0961 - val_loss: 0.1368\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16541 to 0.13677, saving model to regresion3_model.h5\n",
      "Epoch 3/50\n",
      " - 10s - loss: 0.0938 - val_loss: 0.1155\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13677 to 0.11548, saving model to regresion3_model.h5\n",
      "Epoch 4/50\n",
      " - 11s - loss: 0.0920 - val_loss: 0.1090\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11548 to 0.10904, saving model to regresion3_model.h5\n",
      "Epoch 5/50\n",
      " - 11s - loss: 0.0911 - val_loss: 0.1052\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.10904 to 0.10519, saving model to regresion3_model.h5\n",
      "Epoch 6/50\n",
      " - 10s - loss: 0.0903 - val_loss: 0.1026\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10519 to 0.10257, saving model to regresion3_model.h5\n",
      "Epoch 7/50\n",
      " - 10s - loss: 0.0898 - val_loss: 0.1008\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10257 to 0.10077, saving model to regresion3_model.h5\n",
      "Epoch 8/50\n",
      " - 10s - loss: 0.0889 - val_loss: 0.1004\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10077 to 0.10044, saving model to regresion3_model.h5\n",
      "Epoch 9/50\n",
      " - 10s - loss: 0.0882 - val_loss: 0.0995\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10044 to 0.09951, saving model to regresion3_model.h5\n",
      "Epoch 10/50\n",
      " - 10s - loss: 0.0874 - val_loss: 0.0981\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09951 to 0.09810, saving model to regresion3_model.h5\n",
      "Epoch 11/50\n",
      " - 10s - loss: 0.0872 - val_loss: 0.0976\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09810 to 0.09758, saving model to regresion3_model.h5\n",
      "Epoch 12/50\n",
      " - 10s - loss: 0.0864 - val_loss: 0.0963\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09758 to 0.09632, saving model to regresion3_model.h5\n",
      "Epoch 13/50\n",
      " - 10s - loss: 0.0856 - val_loss: 0.0946\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.09632 to 0.09458, saving model to regresion3_model.h5\n",
      "Epoch 14/50\n",
      " - 10s - loss: 0.0851 - val_loss: 0.0938\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09458 to 0.09375, saving model to regresion3_model.h5\n",
      "Epoch 15/50\n",
      " - 10s - loss: 0.0840 - val_loss: 0.0933\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.09375 to 0.09329, saving model to regresion3_model.h5\n",
      "Epoch 16/50\n",
      " - 10s - loss: 0.0837 - val_loss: 0.0923\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.09329 to 0.09229, saving model to regresion3_model.h5\n",
      "Epoch 17/50\n",
      " - 11s - loss: 0.0826 - val_loss: 0.0918\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.09229 to 0.09181, saving model to regresion3_model.h5\n",
      "Epoch 18/50\n",
      " - 10s - loss: 0.0822 - val_loss: 0.0913\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.09181 to 0.09127, saving model to regresion3_model.h5\n",
      "Epoch 19/50\n",
      " - 10s - loss: 0.0815 - val_loss: 0.0904\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.09127 to 0.09036, saving model to regresion3_model.h5\n",
      "Epoch 20/50\n",
      " - 10s - loss: 0.0807 - val_loss: 0.0904\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.09036\n",
      "Epoch 21/50\n",
      " - 10s - loss: 0.0800 - val_loss: 0.0899\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.09036 to 0.08986, saving model to regresion3_model.h5\n",
      "Epoch 22/50\n",
      " - 11s - loss: 0.0795 - val_loss: 0.0896\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.08986 to 0.08958, saving model to regresion3_model.h5\n",
      "Epoch 23/50\n",
      " - 10s - loss: 0.0790 - val_loss: 0.0889\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.08958 to 0.08895, saving model to regresion3_model.h5\n",
      "Epoch 24/50\n",
      " - 10s - loss: 0.0782 - val_loss: 0.0895\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.08895\n",
      "Epoch 25/50\n",
      " - 10s - loss: 0.0777 - val_loss: 0.0895\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.08895\n",
      "Epoch 26/50\n",
      " - 10s - loss: 0.0773 - val_loss: 0.0897\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.08895\n",
      "Epoch 27/50\n",
      " - 10s - loss: 0.0768 - val_loss: 0.0892\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.08895\n",
      "Epoch 28/50\n",
      " - 10s - loss: 0.0765 - val_loss: 0.0896\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.08895\n",
      "Epoch 29/50\n",
      " - 10s - loss: 0.0763 - val_loss: 0.0887\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.08895 to 0.08866, saving model to regresion3_model.h5\n",
      "Epoch 30/50\n",
      " - 10s - loss: 0.0759 - val_loss: 0.0888\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.08866\n",
      "Epoch 31/50\n",
      " - 10s - loss: 0.0756 - val_loss: 0.0891\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.08866\n",
      "Epoch 32/50\n",
      " - 10s - loss: 0.0754 - val_loss: 0.0899\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.08866\n",
      "Epoch 33/50\n",
      " - 11s - loss: 0.0752 - val_loss: 0.0888\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.08866\n",
      "Epoch 34/50\n",
      " - 10s - loss: 0.0751 - val_loss: 0.0883\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.08866 to 0.08830, saving model to regresion3_model.h5\n",
      "Epoch 35/50\n",
      " - 11s - loss: 0.0748 - val_loss: 0.0883\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08830\n",
      "Epoch 36/50\n",
      " - 10s - loss: 0.0747 - val_loss: 0.0881\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.08830 to 0.08807, saving model to regresion3_model.h5\n",
      "Epoch 37/50\n",
      " - 10s - loss: 0.0745 - val_loss: 0.0882\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08807\n",
      "Epoch 38/50\n",
      " - 10s - loss: 0.0741 - val_loss: 0.0873\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.08807 to 0.08731, saving model to regresion3_model.h5\n",
      "Epoch 39/50\n",
      " - 10s - loss: 0.0741 - val_loss: 0.0878\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08731\n",
      "Epoch 40/50\n",
      " - 10s - loss: 0.0739 - val_loss: 0.0876\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08731\n",
      "Epoch 41/50\n",
      " - 10s - loss: 0.0736 - val_loss: 0.0873\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08731\n",
      "Epoch 42/50\n",
      " - 10s - loss: 0.0736 - val_loss: 0.0871\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.08731 to 0.08711, saving model to regresion3_model.h5\n",
      "Epoch 43/50\n",
      " - 10s - loss: 0.0736 - val_loss: 0.0870\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.08711 to 0.08701, saving model to regresion3_model.h5\n",
      "Epoch 44/50\n",
      " - 10s - loss: 0.0734 - val_loss: 0.0866\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.08701 to 0.08659, saving model to regresion3_model.h5\n",
      "Epoch 45/50\n",
      " - 10s - loss: 0.0732 - val_loss: 0.0865\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.08659 to 0.08653, saving model to regresion3_model.h5\n",
      "Epoch 46/50\n",
      " - 11s - loss: 0.0733 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08653 to 0.08612, saving model to regresion3_model.h5\n",
      "Epoch 47/50\n",
      " - 10s - loss: 0.0731 - val_loss: 0.0854\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.08612 to 0.08543, saving model to regresion3_model.h5\n",
      "Epoch 48/50\n",
      " - 10s - loss: 0.0729 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08543\n",
      "Epoch 49/50\n",
      " - 10s - loss: 0.0730 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.08543\n",
      "Epoch 50/50\n",
      " - 10s - loss: 0.0729 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08543\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path_clf = 'regresion3_model.h5'  \n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test), verbose=2, shuffle=False,\n",
    "            callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=2, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path_clf, monitor='val_loss', save_best_only=True, mode='min', verbose=2)])\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el mejor modelo guardado durante el entrenamiento\n",
    "\n",
    "saved_model = load_model('regresion3_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediccion\n",
    "yhat = saved_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50465786],\n",
       "       [0.5088497 ],\n",
       "       [0.49690408],\n",
       "       ...,\n",
       "       [0.05174018],\n",
       "       [0.04941075],\n",
       "       [0.0305727 ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 25)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[2]))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape((len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.119\n"
     ]
    }
   ],
   "source": [
    "# calcular RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "inv_yhat = concatenate((yhat, x_test[:, :]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 26)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50465786, 0.        , 0.63218391, 0.75      , 0.        ,\n",
       "       0.        , 0.54518072, 0.31066056, 0.26941256, 0.        ,\n",
       "       1.        , 0.65217391, 0.21212121, 0.12761375, 0.        ,\n",
       "       0.20833333, 0.64605544, 0.22058824, 0.13216018, 0.30896499,\n",
       "       0.        , 0.33333333, 0.        , 0.        , 0.55813953,\n",
       "       0.66183375])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat2 = scaler.inverse_transform(inv_yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.83181489e+02, -8.70000000e-03,  1.58620690e-04, ...,\n",
       "         3.81400000e+01,  2.32984047e+01,  2.38921983e+02],\n",
       "       [ 1.84694735e+02, -8.65180055e-03, -1.86206897e-04, ...,\n",
       "         3.81400000e+01,  2.33882279e+01,  2.47944490e+02],\n",
       "       [ 1.80382371e+02, -8.60360111e-03,  2.06896552e-05, ...,\n",
       "         3.81400000e+01,  2.34219116e+01,  2.60406518e+02],\n",
       "       ...,\n",
       "       [ 1.96782066e+01,  6.98891967e-04, -4.13793103e-05, ...,\n",
       "         3.81400000e+01,  2.31636698e+01,  1.54977769e+02],\n",
       "       [ 1.88372791e+01,  7.47091413e-04, -2.62068966e-04, ...,\n",
       "         3.81400000e+01,  2.31861256e+01,  1.87279343e+02],\n",
       "       [ 1.20367438e+01,  7.95290859e-04,  8.96551724e-05, ...,\n",
       "         3.81400000e+01,  2.32085814e+01,  1.45207539e+02]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat3 = inv_yhat2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([183.18148911, 184.69473463, 180.38237113, ...,  19.67820658,\n",
       "        18.83727913,  12.0367438 ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143., 142., 141., ...,  23.,  22.,  21.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inv_y = concatenate((y_test, x_test[:,:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "METRICAS DE DESEMPEÑO DEL MODELO DE REGRESION\n",
      "------------------------------------------------------------\n",
      "Mean Deviation (MD): 13.29\n",
      "Mean Absolute Error (MAE): 30.84\n",
      "------------------------------------------------------------\n",
      "Mean Squared Error (MSE): 1832.46\n",
      "Root Mean Squared Error (RMSE): 42.81\n",
      "------------------------------------------------------------\n",
      "Mean Percent Error (MPE): 2.01\n",
      "Mean Absolute Percent Error (MAPE): 22.72\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "regression_metrics(inv_y, inv_yhat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar datos para el nuevo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos de nuevo para el modelo, ya que se habian modificado por escalado y reshape\n",
    "# no hay cambios en los datos, son las mismas lineas de la parte superior del codigo\n",
    "\n",
    "columns=[\"id\",\"ciclo\",\"set1\",\"set2\",\"set3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]\n",
    "train=pd.read_csv(\"train_FD001.txt\",sep=\" \",names=columns)\n",
    "test=pd.read_csv(\"test_FD001.txt\",sep=\" \",names=columns)\n",
    "rul=pd.read_csv(\"RUL_FD001.txt\",sep=\" \",header=None)\n",
    "train.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "test.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "rul.drop([1], axis=1, inplace=True)\n",
    "rul.columns = ['ttf']\n",
    "rul2=pd.DataFrame(train.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul2.columns = ['id', 'falla']\n",
    "train= train.merge(rul2, on=['id'], how='left')\n",
    "train['ttf'] = train['falla'] - train['ciclo']\n",
    "train.drop('falla', axis=1, inplace=True)\n",
    "rul3=pd.DataFrame(test.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul3.columns = ['id', 'falla']\n",
    "rul['id'] = rul.index + 1\n",
    "rul['falla'] = rul3['falla'] + rul['ttf']\n",
    "rul.drop('ttf', axis=1, inplace=True)\n",
    "test=test.merge(rul, on=['id'], how='left')\n",
    "test['ttf'] = test['falla'] - test['ciclo']\n",
    "test.drop('falla', axis=1, inplace=True)\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "variables=['ciclo','set1','set2','set3','sensor1','sensor2','sensor3','sensor4','sensor5','sensor6','sensor7','sensor8','sensor9','sensor10','sensor11','sensor12','sensor13','sensor14','sensor15','sensor16','sensor17','sensor18','sensor19','sensor20','sensor21','ttf']\n",
    "objetivo='ttf'\n",
    "scaler = MinMaxScaler()\n",
    "train[variables]=scaler.fit_transform(train[variables])\n",
    "test[variables]=scaler.transform(test[variables])\n",
    "x_train=train.iloc[:,np.r_[0:25]]\n",
    "x_test=test.iloc[:,np.r_[0:25]]\n",
    "y_train=train.iloc[:,25]\n",
    "y_test=test.iloc[:,25]\n",
    "x_test=x_test.to_numpy()\n",
    "x_train=x_train.to_numpy()\n",
    "y_test=y_test.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "n_steps = 1\n",
    "x_train = x_train.reshape((x_train.shape[0], n_steps, x_train.shape[1])) \n",
    "x_test = x_test.reshape((x_test.shape[0], n_steps, x_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Staked LSTM con 4 capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20631 samples, validate on 13096 samples\n",
      "Epoch 1/100\n",
      " - 20s - loss: 0.1213 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16801, saving model to regresion6_model.h5\n",
      "Epoch 2/100\n",
      " - 14s - loss: 0.1013 - val_loss: 0.1348\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16801 to 0.13481, saving model to regresion6_model.h5\n",
      "Epoch 3/100\n",
      " - 14s - loss: 0.0972 - val_loss: 0.1193\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13481 to 0.11930, saving model to regresion6_model.h5\n",
      "Epoch 4/100\n",
      " - 14s - loss: 0.0948 - val_loss: 0.1123\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11930 to 0.11226, saving model to regresion6_model.h5\n",
      "Epoch 5/100\n",
      " - 14s - loss: 0.0935 - val_loss: 0.1022\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11226 to 0.10217, saving model to regresion6_model.h5\n",
      "Epoch 6/100\n",
      " - 14s - loss: 0.0925 - val_loss: 0.1034\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10217\n",
      "Epoch 7/100\n",
      " - 14s - loss: 0.0914 - val_loss: 0.0985\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10217 to 0.09851, saving model to regresion6_model.h5\n",
      "Epoch 8/100\n",
      " - 14s - loss: 0.0904 - val_loss: 0.0971\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09851 to 0.09710, saving model to regresion6_model.h5\n",
      "Epoch 9/100\n",
      " - 14s - loss: 0.0894 - val_loss: 0.0961\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09710 to 0.09612, saving model to regresion6_model.h5\n",
      "Epoch 10/100\n",
      " - 14s - loss: 0.0887 - val_loss: 0.0943\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09612 to 0.09433, saving model to regresion6_model.h5\n",
      "Epoch 11/100\n",
      " - 14s - loss: 0.0870 - val_loss: 0.0936\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09433 to 0.09364, saving model to regresion6_model.h5\n",
      "Epoch 12/100\n",
      " - 14s - loss: 0.0855 - val_loss: 0.0924\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09364 to 0.09236, saving model to regresion6_model.h5\n",
      "Epoch 13/100\n",
      " - 14s - loss: 0.0852 - val_loss: 0.0931\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.09236\n",
      "Epoch 14/100\n",
      " - 14s - loss: 0.0840 - val_loss: 0.0932\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.09236\n",
      "Epoch 15/100\n",
      " - 14s - loss: 0.0834 - val_loss: 0.0917\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.09236 to 0.09173, saving model to regresion6_model.h5\n",
      "Epoch 16/100\n",
      " - 14s - loss: 0.0825 - val_loss: 0.0917\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.09173\n",
      "Epoch 17/100\n",
      " - 14s - loss: 0.0819 - val_loss: 0.0900\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.09173 to 0.08997, saving model to regresion6_model.h5\n",
      "Epoch 18/100\n",
      " - 14s - loss: 0.0815 - val_loss: 0.0898\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.08997 to 0.08984, saving model to regresion6_model.h5\n",
      "Epoch 19/100\n",
      " - 14s - loss: 0.0808 - val_loss: 0.0894\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.08984 to 0.08937, saving model to regresion6_model.h5\n",
      "Epoch 20/100\n",
      " - 14s - loss: 0.0801 - val_loss: 0.0893\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.08937 to 0.08927, saving model to regresion6_model.h5\n",
      "Epoch 21/100\n",
      " - 14s - loss: 0.0794 - val_loss: 0.0899\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.08927\n",
      "Epoch 22/100\n",
      " - 14s - loss: 0.0790 - val_loss: 0.0893\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.08927\n",
      "Epoch 23/100\n",
      " - 14s - loss: 0.0784 - val_loss: 0.0901\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.08927\n",
      "Epoch 24/100\n",
      " - 14s - loss: 0.0779 - val_loss: 0.0907\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.08927\n",
      "Epoch 25/100\n",
      " - 14s - loss: 0.0774 - val_loss: 0.0905\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.08927\n",
      "Epoch 26/100\n",
      " - 14s - loss: 0.0771 - val_loss: 0.0898\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.08927\n",
      "Epoch 27/100\n",
      " - 14s - loss: 0.0765 - val_loss: 0.0908\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.08927\n",
      "Epoch 28/100\n",
      " - 14s - loss: 0.0764 - val_loss: 0.0891\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.08927 to 0.08914, saving model to regresion6_model.h5\n",
      "Epoch 29/100\n",
      " - 14s - loss: 0.0761 - val_loss: 0.0898\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.08914\n",
      "Epoch 30/100\n",
      " - 14s - loss: 0.0758 - val_loss: 0.0890\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.08914 to 0.08904, saving model to regresion6_model.h5\n",
      "Epoch 31/100\n",
      " - 14s - loss: 0.0757 - val_loss: 0.0894\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.08904\n",
      "Epoch 32/100\n",
      " - 14s - loss: 0.0754 - val_loss: 0.0888\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.08904 to 0.08882, saving model to regresion6_model.h5\n",
      "Epoch 33/100\n",
      " - 14s - loss: 0.0753 - val_loss: 0.0890\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.08882\n",
      "Epoch 34/100\n",
      " - 14s - loss: 0.0751 - val_loss: 0.0884\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.08882 to 0.08840, saving model to regresion6_model.h5\n",
      "Epoch 35/100\n",
      " - 14s - loss: 0.0749 - val_loss: 0.0875\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.08840 to 0.08750, saving model to regresion6_model.h5\n",
      "Epoch 36/100\n",
      " - 14s - loss: 0.0747 - val_loss: 0.0881\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.08750\n",
      "Epoch 37/100\n",
      " - 14s - loss: 0.0745 - val_loss: 0.0876\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08750\n",
      "Epoch 38/100\n",
      " - 14s - loss: 0.0746 - val_loss: 0.0876\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08750\n",
      "Epoch 39/100\n",
      " - 14s - loss: 0.0742 - val_loss: 0.0874\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.08750 to 0.08740, saving model to regresion6_model.h5\n",
      "Epoch 40/100\n",
      " - 14s - loss: 0.0741 - val_loss: 0.0876\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08740\n",
      "Epoch 41/100\n",
      " - 14s - loss: 0.0740 - val_loss: 0.0868\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.08740 to 0.08677, saving model to regresion6_model.h5\n",
      "Epoch 42/100\n",
      " - 14s - loss: 0.0740 - val_loss: 0.0868\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.08677\n",
      "Epoch 43/100\n",
      " - 14s - loss: 0.0738 - val_loss: 0.0868\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.08677\n",
      "Epoch 44/100\n",
      " - 14s - loss: 0.0738 - val_loss: 0.0862\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.08677 to 0.08624, saving model to regresion6_model.h5\n",
      "Epoch 45/100\n",
      " - 14s - loss: 0.0737 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.08624 to 0.08602, saving model to regresion6_model.h5\n",
      "Epoch 46/100\n",
      " - 14s - loss: 0.0737 - val_loss: 0.0866\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.08602\n",
      "Epoch 47/100\n",
      " - 14s - loss: 0.0737 - val_loss: 0.0862\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.08602\n",
      "Epoch 48/100\n",
      " - 14s - loss: 0.0733 - val_loss: 0.0864\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08602\n",
      "Epoch 49/100\n",
      " - 14s - loss: 0.0732 - val_loss: 0.0858\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.08602 to 0.08580, saving model to regresion6_model.h5\n",
      "Epoch 50/100\n",
      " - 14s - loss: 0.0732 - val_loss: 0.0859\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08580\n",
      "Epoch 51/100\n",
      " - 14s - loss: 0.0730 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.08580 to 0.08547, saving model to regresion6_model.h5\n",
      "Epoch 52/100\n",
      " - 14s - loss: 0.0732 - val_loss: 0.0854\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.08547 to 0.08540, saving model to regresion6_model.h5\n",
      "Epoch 53/100\n",
      " - 14s - loss: 0.0730 - val_loss: 0.0853\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.08540 to 0.08527, saving model to regresion6_model.h5\n",
      "Epoch 54/100\n",
      " - 14s - loss: 0.0731 - val_loss: 0.0853\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.08527\n",
      "Epoch 55/100\n",
      " - 14s - loss: 0.0729 - val_loss: 0.0854\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.08527\n",
      "Epoch 56/100\n",
      " - 14s - loss: 0.0726 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.08527 to 0.08516, saving model to regresion6_model.h5\n",
      "Epoch 57/100\n",
      " - 14s - loss: 0.0728 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.08516\n",
      "Epoch 58/100\n",
      " - 14s - loss: 0.0726 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.08516\n",
      "Epoch 59/100\n",
      " - 14s - loss: 0.0725 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.08516 to 0.08492, saving model to regresion6_model.h5\n",
      "Epoch 60/100\n",
      " - 14s - loss: 0.0723 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.08492\n",
      "Epoch 61/100\n",
      " - 14s - loss: 0.0724 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.08492\n",
      "Epoch 62/100\n",
      " - 14s - loss: 0.0725 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.08492\n",
      "Epoch 63/100\n",
      " - 14s - loss: 0.0723 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08492 to 0.08481, saving model to regresion6_model.h5\n",
      "Epoch 64/100\n",
      " - 14s - loss: 0.0721 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.08481\n",
      "Epoch 65/100\n",
      " - 14s - loss: 0.0723 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08481 to 0.08475, saving model to regresion6_model.h5\n",
      "Epoch 66/100\n",
      " - 14s - loss: 0.0723 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08475 to 0.08475, saving model to regresion6_model.h5\n",
      "Epoch 67/100\n",
      " - 14s - loss: 0.0721 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.08475\n",
      "Epoch 68/100\n",
      " - 14s - loss: 0.0720 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.08475\n",
      "Epoch 69/100\n",
      " - 14s - loss: 0.0719 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.08475 to 0.08459, saving model to regresion6_model.h5\n",
      "Epoch 70/100\n",
      " - 14s - loss: 0.0721 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.08459\n",
      "Epoch 71/100\n",
      " - 14s - loss: 0.0719 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08459\n",
      "Epoch 72/100\n",
      " - 14s - loss: 0.0720 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08459\n",
      "Epoch 73/100\n",
      " - 14s - loss: 0.0717 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08459 to 0.08445, saving model to regresion6_model.h5\n",
      "Epoch 74/100\n",
      " - 14s - loss: 0.0718 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.08445\n",
      "Epoch 75/100\n",
      " - 14s - loss: 0.0718 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.08445\n",
      "Epoch 76/100\n",
      " - 14s - loss: 0.0718 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.08445\n",
      "Epoch 77/100\n",
      " - 14s - loss: 0.0718 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.08445\n",
      "Epoch 78/100\n",
      " - 14s - loss: 0.0716 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.08445\n",
      "Epoch 79/100\n",
      " - 14s - loss: 0.0717 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.08445\n",
      "Epoch 80/100\n",
      " - 14s - loss: 0.0717 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.08445\n",
      "Epoch 81/100\n",
      " - 14s - loss: 0.0717 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.08445 to 0.08445, saving model to regresion6_model.h5\n",
      "Epoch 82/100\n",
      " - 15s - loss: 0.0719 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.08445 to 0.08442, saving model to regresion6_model.h5\n",
      "Epoch 83/100\n",
      " - 14s - loss: 0.0719 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.08442\n",
      "Epoch 84/100\n",
      " - 14s - loss: 0.0717 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.08442 to 0.08437, saving model to regresion6_model.h5\n",
      "Epoch 85/100\n",
      " - 15s - loss: 0.0714 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.08437\n",
      "Epoch 86/100\n",
      " - 14s - loss: 0.0713 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.08437\n",
      "Epoch 87/100\n",
      " - 14s - loss: 0.0714 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.08437\n",
      "Epoch 88/100\n",
      " - 14s - loss: 0.0715 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.08437\n",
      "Epoch 89/100\n",
      " - 14s - loss: 0.0714 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.08437\n",
      "Epoch 90/100\n",
      " - 15s - loss: 0.0714 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.08437\n",
      "Epoch 91/100\n",
      " - 15s - loss: 0.0714 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.08437\n",
      "Epoch 92/100\n",
      " - 15s - loss: 0.0715 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.08437\n",
      "Epoch 93/100\n",
      " - 15s - loss: 0.0716 - val_loss: 0.0844\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.08437\n",
      "Epoch 94/100\n",
      " - 15s - loss: 0.0713 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.08437\n",
      "Epoch 00094: early stopping\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "model_path_clf = 'regresion6_model.h5'  \n",
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(200, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "\n",
    "# fit network\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test), verbose=2, shuffle=False,\n",
    "            callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=2, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path_clf, monitor='val_loss', save_best_only=True, mode='min', verbose=2)])\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el mejor modelo guardado durante el entrenamiento\n",
    "\n",
    "saved_model = load_model('regresion6_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediccion\n",
    "yhat = saved_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52207667],\n",
       "       [0.523903  ],\n",
       "       [0.50842625],\n",
       "       ...,\n",
       "       [0.03814742],\n",
       "       [0.04011813],\n",
       "       [0.02726528]], dtype=float32)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 25)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[2]))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape((len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.114\n"
     ]
    }
   ],
   "source": [
    "# calcular RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat = concatenate((yhat, x_test[:, :]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 26)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52207667, 0.        , 0.63218391, 0.75      , 0.        ,\n",
       "       0.        , 0.54518072, 0.31066056, 0.26941256, 0.        ,\n",
       "       1.        , 0.65217391, 0.21212121, 0.12761375, 0.        ,\n",
       "       0.20833333, 0.64605544, 0.22058824, 0.13216018, 0.30896499,\n",
       "       0.        , 0.33333333, 0.        , 0.        , 0.55813953,\n",
       "       0.66183375])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat2 = scaler.inverse_transform(inv_yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.89469677e+02, -8.70000000e-03,  1.58620690e-04, ...,\n",
       "         3.81400000e+01,  2.32984047e+01,  2.38921983e+02],\n",
       "       [ 1.90128987e+02, -8.65180055e-03, -1.86206897e-04, ...,\n",
       "         3.81400000e+01,  2.33882279e+01,  2.47944490e+02],\n",
       "       [ 1.84541876e+02, -8.60360111e-03,  2.06896552e-05, ...,\n",
       "         3.81400000e+01,  2.34219116e+01,  2.60406518e+02],\n",
       "       ...,\n",
       "       [ 1.47712185e+01,  6.98891967e-04, -4.13793103e-05, ...,\n",
       "         3.81400000e+01,  2.31636698e+01,  1.54977769e+02],\n",
       "       [ 1.54826442e+01,  7.47091413e-04, -2.62068966e-04, ...,\n",
       "         3.81400000e+01,  2.31861256e+01,  1.87279343e+02],\n",
       "       [ 1.08427663e+01,  7.95290859e-04,  8.96551724e-05, ...,\n",
       "         3.81400000e+01,  2.32085814e+01,  1.45207539e+02]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat3 = inv_yhat2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([189.46967655, 190.12898743, 184.5418759 , ...,  14.77121851,\n",
       "        15.48264423,  10.84276626])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143., 142., 141., ...,  23.,  22.,  21.])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inv_y = concatenate((y_test, x_test[:,:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "METRICAS DE DESEMPEÑO DEL MODELO DE REGRESION\n",
      "------------------------------------------------------------\n",
      "Mean Deviation (MD): 7.67\n",
      "Mean Absolute Error (MAE): 30.46\n",
      "------------------------------------------------------------\n",
      "Mean Squared Error (MSE): 1690.81\n",
      "Root Mean Squared Error (RMSE): 41.12\n",
      "------------------------------------------------------------\n",
      "Mean Percent Error (MPE): -1.65\n",
      "Mean Absolute Percent Error (MAPE): 23.21\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "regression_metrics(inv_y, inv_yhat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar datos para el nuevo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos de nuevo para el modelo, ya que se habian modificado por escalado y reshape\n",
    "# no hay cambios en los datos, son las mismas lineas de la parte superior del codigo\n",
    "\n",
    "columns=[\"id\",\"ciclo\",\"set1\",\"set2\",\"set3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]\n",
    "train=pd.read_csv(\"train_FD001.txt\",sep=\" \",names=columns)\n",
    "test=pd.read_csv(\"test_FD001.txt\",sep=\" \",names=columns)\n",
    "rul=pd.read_csv(\"RUL_FD001.txt\",sep=\" \",header=None)\n",
    "train.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "test.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "rul.drop([1], axis=1, inplace=True)\n",
    "rul.columns = ['ttf']\n",
    "rul2=pd.DataFrame(train.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul2.columns = ['id', 'falla']\n",
    "train= train.merge(rul2, on=['id'], how='left')\n",
    "train['ttf'] = train['falla'] - train['ciclo']\n",
    "train.drop('falla', axis=1, inplace=True)\n",
    "rul3=pd.DataFrame(test.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul3.columns = ['id', 'falla']\n",
    "rul['id'] = rul.index + 1\n",
    "rul['falla'] = rul3['falla'] + rul['ttf']\n",
    "rul.drop('ttf', axis=1, inplace=True)\n",
    "test=test.merge(rul, on=['id'], how='left')\n",
    "test['ttf'] = test['falla'] - test['ciclo']\n",
    "test.drop('falla', axis=1, inplace=True)\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "variables=['ciclo','set1','set2','set3','sensor1','sensor2','sensor3','sensor4','sensor5','sensor6','sensor7','sensor8','sensor9','sensor10','sensor11','sensor12','sensor13','sensor14','sensor15','sensor16','sensor17','sensor18','sensor19','sensor20','sensor21','ttf']\n",
    "objetivo='ttf'\n",
    "scaler = MinMaxScaler()\n",
    "train[variables]=scaler.fit_transform(train[variables])\n",
    "test[variables]=scaler.transform(test[variables])\n",
    "x_train=train.iloc[:,np.r_[0:25]]\n",
    "x_test=test.iloc[:,np.r_[0:25]]\n",
    "y_train=train.iloc[:,25]\n",
    "y_test=test.iloc[:,25]\n",
    "x_test=x_test.to_numpy()\n",
    "x_train=x_train.to_numpy()\n",
    "y_test=y_test.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "n_steps = 1\n",
    "x_train = x_train.reshape((x_train.shape[0], n_steps, x_train.shape[1])) \n",
    "x_test = x_test.reshape((x_test.shape[0], n_steps, x_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoder LSTM With Multivariate Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train de 2d a 3d\n",
    "y_train3d = y_train.reshape((y_train.shape[0], n_steps, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 1, 1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1, 1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test de 2d a 3d\n",
    "y_test3d = y_test.reshape((y_test.shape[0], n_steps, 1))\n",
    "y_test3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20631 samples, validate on 13096 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 0.0229 - val_loss: 0.0341\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03409, saving model to regresion4_model.h5\n",
      "Epoch 2/100\n",
      " - 8s - loss: 0.0157 - val_loss: 0.0303\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03409 to 0.03026, saving model to regresion4_model.h5\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.0146 - val_loss: 0.0307\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03026\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.0141 - val_loss: 0.0312\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03026\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.0136 - val_loss: 0.0243\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03026 to 0.02428, saving model to regresion4_model.h5\n",
      "Epoch 6/100\n",
      " - 8s - loss: 0.0133 - val_loss: 0.0223\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02428 to 0.02229, saving model to regresion4_model.h5\n",
      "Epoch 7/100\n",
      " - 8s - loss: 0.0131 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02229 to 0.02086, saving model to regresion4_model.h5\n",
      "Epoch 8/100\n",
      " - 8s - loss: 0.0130 - val_loss: 0.0197\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02086 to 0.01969, saving model to regresion4_model.h5\n",
      "Epoch 9/100\n",
      " - 8s - loss: 0.0129 - val_loss: 0.0187\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01969 to 0.01868, saving model to regresion4_model.h5\n",
      "Epoch 10/100\n",
      " - 8s - loss: 0.0128 - val_loss: 0.0178\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01868 to 0.01779, saving model to regresion4_model.h5\n",
      "Epoch 11/100\n",
      " - 8s - loss: 0.0127 - val_loss: 0.0170\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01779 to 0.01701, saving model to regresion4_model.h5\n",
      "Epoch 12/100\n",
      " - 8s - loss: 0.0126 - val_loss: 0.0165\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01701 to 0.01653, saving model to regresion4_model.h5\n",
      "Epoch 13/100\n",
      " - 8s - loss: 0.0126 - val_loss: 0.0158\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01653 to 0.01580, saving model to regresion4_model.h5\n",
      "Epoch 14/100\n",
      " - 8s - loss: 0.0126 - val_loss: 0.0160\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01580\n",
      "Epoch 15/100\n",
      " - 8s - loss: 0.0125 - val_loss: 0.0150\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01580 to 0.01498, saving model to regresion4_model.h5\n",
      "Epoch 16/100\n",
      " - 8s - loss: 0.0124 - val_loss: 0.0147\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01498 to 0.01469, saving model to regresion4_model.h5\n",
      "Epoch 17/100\n",
      " - 8s - loss: 0.0124 - val_loss: 0.0145\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01469 to 0.01445, saving model to regresion4_model.h5\n",
      "Epoch 18/100\n",
      " - 8s - loss: 0.0123 - val_loss: 0.0144\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01445 to 0.01437, saving model to regresion4_model.h5\n",
      "Epoch 19/100\n",
      " - 8s - loss: 0.0123 - val_loss: 0.0141\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01437 to 0.01407, saving model to regresion4_model.h5\n",
      "Epoch 20/100\n",
      " - 8s - loss: 0.0122 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01407 to 0.01391, saving model to regresion4_model.h5\n",
      "Epoch 21/100\n",
      " - 7s - loss: 0.0122 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01391 to 0.01388, saving model to regresion4_model.h5\n",
      "Epoch 22/100\n",
      " - 8s - loss: 0.0122 - val_loss: 0.0137\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01388 to 0.01374, saving model to regresion4_model.h5\n",
      "Epoch 23/100\n",
      " - 8s - loss: 0.0121 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01374 to 0.01355, saving model to regresion4_model.h5\n",
      "Epoch 24/100\n",
      " - 8s - loss: 0.0121 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01355 to 0.01347, saving model to regresion4_model.h5\n",
      "Epoch 25/100\n",
      " - 8s - loss: 0.0120 - val_loss: 0.0143\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01347\n",
      "Epoch 26/100\n",
      " - 8s - loss: 0.0120 - val_loss: 0.0133\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01347 to 0.01333, saving model to regresion4_model.h5\n",
      "Epoch 27/100\n",
      " - 8s - loss: 0.0120 - val_loss: 0.0133\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01333 to 0.01329, saving model to regresion4_model.h5\n",
      "Epoch 28/100\n",
      " - 8s - loss: 0.0119 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01329 to 0.01325, saving model to regresion4_model.h5\n",
      "Epoch 29/100\n",
      " - 8s - loss: 0.0119 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01325 to 0.01321, saving model to regresion4_model.h5\n",
      "Epoch 30/100\n",
      " - 8s - loss: 0.0119 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01321 to 0.01319, saving model to regresion4_model.h5\n",
      "Epoch 31/100\n",
      " - 8s - loss: 0.0118 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01319 to 0.01315, saving model to regresion4_model.h5\n",
      "Epoch 32/100\n",
      " - 8s - loss: 0.0118 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.01315 to 0.01314, saving model to regresion4_model.h5\n",
      "Epoch 33/100\n",
      " - 8s - loss: 0.0118 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01314 to 0.01312, saving model to regresion4_model.h5\n",
      "Epoch 34/100\n",
      " - 8s - loss: 0.0117 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.01312 to 0.01310, saving model to regresion4_model.h5\n",
      "Epoch 35/100\n",
      " - 8s - loss: 0.0117 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.01310 to 0.01307, saving model to regresion4_model.h5\n",
      "Epoch 36/100\n",
      " - 8s - loss: 0.0117 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.01307 to 0.01307, saving model to regresion4_model.h5\n",
      "Epoch 37/100\n",
      " - 8s - loss: 0.0116 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.01307 to 0.01305, saving model to regresion4_model.h5\n",
      "Epoch 38/100\n",
      " - 8s - loss: 0.0116 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01305\n",
      "Epoch 39/100\n",
      " - 8s - loss: 0.0116 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.01305 to 0.01304, saving model to regresion4_model.h5\n",
      "Epoch 40/100\n",
      " - 8s - loss: 0.0116 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01304\n",
      "Epoch 41/100\n",
      " - 8s - loss: 0.0116 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.01304 to 0.01302, saving model to regresion4_model.h5\n",
      "Epoch 42/100\n",
      " - 8s - loss: 0.0115 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.01302 to 0.01302, saving model to regresion4_model.h5\n",
      "Epoch 43/100\n",
      " - 8s - loss: 0.0115 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.01302 to 0.01301, saving model to regresion4_model.h5\n",
      "Epoch 44/100\n",
      " - 8s - loss: 0.0115 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.01301 to 0.01300, saving model to regresion4_model.h5\n",
      "Epoch 45/100\n",
      " - 8s - loss: 0.0114 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.01300 to 0.01299, saving model to regresion4_model.h5\n",
      "Epoch 46/100\n",
      " - 8s - loss: 0.0114 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.01299 to 0.01299, saving model to regresion4_model.h5\n",
      "Epoch 47/100\n",
      " - 8s - loss: 0.0114 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.01299 to 0.01299, saving model to regresion4_model.h5\n",
      "Epoch 48/100\n",
      " - 8s - loss: 0.0114 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.01299 to 0.01297, saving model to regresion4_model.h5\n",
      "Epoch 49/100\n",
      " - 8s - loss: 0.0113 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.01297\n",
      "Epoch 50/100\n",
      " - 8s - loss: 0.0113 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.01297 to 0.01297, saving model to regresion4_model.h5\n",
      "Epoch 51/100\n",
      " - 8s - loss: 0.0113 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.01297 to 0.01296, saving model to regresion4_model.h5\n",
      "Epoch 52/100\n",
      " - 8s - loss: 0.0113 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.01296\n",
      "Epoch 53/100\n",
      " - 8s - loss: 0.0112 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.01296\n",
      "Epoch 54/100\n",
      " - 8s - loss: 0.0113 - val_loss: 0.0133\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.01296\n",
      "Epoch 55/100\n",
      " - 8s - loss: 0.0113 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.01296 to 0.01295, saving model to regresion4_model.h5\n",
      "Epoch 56/100\n",
      " - 8s - loss: 0.0112 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.01295\n",
      "Epoch 57/100\n",
      " - 8s - loss: 0.0112 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.01295\n",
      "Epoch 58/100\n",
      " - 8s - loss: 0.0111 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.01295\n",
      "Epoch 59/100\n",
      " - 8s - loss: 0.0111 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.01295\n",
      "Epoch 60/100\n",
      " - 8s - loss: 0.0111 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.01295\n",
      "Epoch 61/100\n",
      " - 8s - loss: 0.0111 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.01295\n",
      "Epoch 62/100\n",
      " - 8s - loss: 0.0111 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.01295\n",
      "Epoch 63/100\n",
      " - 8s - loss: 0.0111 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.01295\n",
      "Epoch 64/100\n",
      " - 8s - loss: 0.0110 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.01295\n",
      "Epoch 65/100\n",
      " - 8s - loss: 0.0110 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.01295\n",
      "Epoch 00065: early stopping\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "# modelo\n",
    "\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "n_outputs=1\n",
    "model_path_clf = 'regresion4_model.h5'  \n",
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(RepeatVector(n_outputs))\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(loss='mse', optimizer='adam') # con perdida mse\n",
    "\n",
    "\n",
    "# entrenar la red\n",
    "history = model.fit(x_train, y_train3d, epochs=100, batch_size=32, validation_data=(x_test, y_test3d), verbose=2, shuffle=False,\n",
    "            callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=2, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path_clf, monitor='val_loss', save_best_only=True, mode='min', verbose=2)])\n",
    "print(history.history.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el mejor modelo guardado durante el entrenamiento\n",
    "\n",
    "saved_model = load_model('regresion4_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediccion\n",
    "yhat = saved_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1, 1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.52438605]],\n",
       "\n",
       "       [[0.5307803 ]],\n",
       "\n",
       "       [[0.51905566]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.07463536]],\n",
       "\n",
       "       [[0.0654662 ]],\n",
       "\n",
       "       [[0.02439013]]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 25)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[2]))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape((len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir el pronostico a 2d\n",
    "yhat = yhat.reshape((len(yhat), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.114\n"
     ]
    }
   ],
   "source": [
    "# calcular RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat = concatenate((yhat, x_test[:, :]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 26)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52438605, 0.        , 0.63218391, 0.75      , 0.        ,\n",
       "       0.        , 0.54518072, 0.31066056, 0.26941256, 0.        ,\n",
       "       1.        , 0.65217391, 0.21212121, 0.12761375, 0.        ,\n",
       "       0.20833333, 0.64605544, 0.22058824, 0.13216018, 0.30896499,\n",
       "       0.        , 0.33333333, 0.        , 0.        , 0.55813953,\n",
       "       0.66183375])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat2 = scaler.inverse_transform(inv_yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.90303363e+02, -8.70000000e-03,  1.58620690e-04, ...,\n",
       "         3.81400000e+01,  2.32984047e+01,  2.38921983e+02],\n",
       "       [ 1.92611694e+02, -8.65180055e-03, -1.86206897e-04, ...,\n",
       "         3.81400000e+01,  2.33882279e+01,  2.47944490e+02],\n",
       "       [ 1.88379095e+02, -8.60360111e-03,  2.06896552e-05, ...,\n",
       "         3.81400000e+01,  2.34219116e+01,  2.60406518e+02],\n",
       "       ...,\n",
       "       [ 2.79433638e+01,  6.98891967e-04, -4.13793103e-05, ...,\n",
       "         3.81400000e+01,  2.31636698e+01,  1.54977769e+02],\n",
       "       [ 2.46332965e+01,  7.47091413e-04, -2.62068966e-04, ...,\n",
       "         3.81400000e+01,  2.31861256e+01,  1.87279343e+02],\n",
       "       [ 9.80483738e+00,  7.95290859e-04,  8.96551724e-05, ...,\n",
       "         3.81400000e+01,  2.32085814e+01,  1.45207539e+02]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat3 = inv_yhat2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([190.30336344, 192.61169386, 188.3790949 , ...,  27.94336376,\n",
       "        24.63329652,   9.80483738])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143., 142., 141., ...,  23.,  22.,  21.])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inv_y = concatenate((y_test, x_test[:,:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "METRICAS DE DESEMPEÑO DEL MODELO DE REGRESION\n",
      "------------------------------------------------------------\n",
      "Mean Deviation (MD): -1.62\n",
      "Mean Absolute Error (MAE): 32.14\n",
      "------------------------------------------------------------\n",
      "Mean Squared Error (MSE): 1688.19\n",
      "Root Mean Squared Error (RMSE): 41.09\n",
      "------------------------------------------------------------\n",
      "Mean Percent Error (MPE): -9.71\n",
      "Mean Absolute Percent Error (MAPE): 26.61\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "regression_metrics(inv_y, inv_yhat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar datos para el nuevo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos de nuevo para el modelo, ya que se habian modificado por escalado y reshape\n",
    "# no hay cambios en los datos, son las mismas lineas de la parte superior del codigo\n",
    "\n",
    "columns=[\"id\",\"ciclo\",\"set1\",\"set2\",\"set3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]\n",
    "train=pd.read_csv(\"train_FD001.txt\",sep=\" \",names=columns)\n",
    "test=pd.read_csv(\"test_FD001.txt\",sep=\" \",names=columns)\n",
    "rul=pd.read_csv(\"RUL_FD001.txt\",sep=\" \",header=None)\n",
    "train.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "test.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "rul.drop([1], axis=1, inplace=True)\n",
    "rul.columns = ['ttf']\n",
    "rul2=pd.DataFrame(train.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul2.columns = ['id', 'falla']\n",
    "train= train.merge(rul2, on=['id'], how='left')\n",
    "train['ttf'] = train['falla'] - train['ciclo']\n",
    "train.drop('falla', axis=1, inplace=True)\n",
    "rul3=pd.DataFrame(test.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul3.columns = ['id', 'falla']\n",
    "rul['id'] = rul.index + 1\n",
    "rul['falla'] = rul3['falla'] + rul['ttf']\n",
    "rul.drop('ttf', axis=1, inplace=True)\n",
    "test=test.merge(rul, on=['id'], how='left')\n",
    "test['ttf'] = test['falla'] - test['ciclo']\n",
    "test.drop('falla', axis=1, inplace=True)\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "variables=['ciclo','set1','set2','set3','sensor1','sensor2','sensor3','sensor4','sensor5','sensor6','sensor7','sensor8','sensor9','sensor10','sensor11','sensor12','sensor13','sensor14','sensor15','sensor16','sensor17','sensor18','sensor19','sensor20','sensor21','ttf']\n",
    "objetivo='ttf'\n",
    "scaler = MinMaxScaler()\n",
    "train[variables]=scaler.fit_transform(train[variables])\n",
    "test[variables]=scaler.transform(test[variables])\n",
    "x_train=train.iloc[:,np.r_[0:25]]\n",
    "x_test=test.iloc[:,np.r_[0:25]]\n",
    "y_train=train.iloc[:,25]\n",
    "y_test=test.iloc[:,25]\n",
    "x_test=x_test.to_numpy()\n",
    "x_train=x_train.to_numpy()\n",
    "y_test=y_test.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "n_steps = 1\n",
    "x_train = x_train.reshape((x_train.shape[0], n_steps, x_train.shape[1])) \n",
    "x_test = x_test.reshape((x_test.shape[0], n_steps, x_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covertir y_train de 2d a 3d\n",
    "y_train3d = y_train.reshape((y_train.shape[0], n_steps, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 1, 1)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1, 1)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covertir y_test de 2d a 3d\n",
    "y_test3d = y_test.reshape((y_test.shape[0], n_steps, 1))\n",
    "y_test3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20631 samples, validate on 13096 samples\n",
      "Epoch 1/100\n",
      " - 11s - loss: 0.1094 - val_loss: 0.2020\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20200, saving model to regresion5_model.h5\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.0944 - val_loss: 0.1731\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20200 to 0.17307, saving model to regresion5_model.h5\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0912 - val_loss: 0.1225\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17307 to 0.12247, saving model to regresion5_model.h5\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0886 - val_loss: 0.1111\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12247 to 0.11105, saving model to regresion5_model.h5\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0874 - val_loss: 0.1062\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11105 to 0.10617, saving model to regresion5_model.h5\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0866 - val_loss: 0.1036\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10617 to 0.10358, saving model to regresion5_model.h5\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.0861 - val_loss: 0.1009\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10358 to 0.10085, saving model to regresion5_model.h5\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.0854 - val_loss: 0.0991\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10085 to 0.09910, saving model to regresion5_model.h5\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.0850 - val_loss: 0.0977\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09910 to 0.09775, saving model to regresion5_model.h5\n",
      "Epoch 10/100\n",
      " - 7s - loss: 0.0845 - val_loss: 0.0968\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09775 to 0.09679, saving model to regresion5_model.h5\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.0843 - val_loss: 0.0964\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09679 to 0.09639, saving model to regresion5_model.h5\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.0836 - val_loss: 0.0957\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09639 to 0.09569, saving model to regresion5_model.h5\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.0833 - val_loss: 0.0954\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.09569 to 0.09540, saving model to regresion5_model.h5\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.0827 - val_loss: 0.0949\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09540 to 0.09489, saving model to regresion5_model.h5\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.0824 - val_loss: 0.0947\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.09489 to 0.09466, saving model to regresion5_model.h5\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.0817 - val_loss: 0.0946\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.09466 to 0.09458, saving model to regresion5_model.h5\n",
      "Epoch 17/100\n",
      " - 7s - loss: 0.0816 - val_loss: 0.0945\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.09458 to 0.09445, saving model to regresion5_model.h5\n",
      "Epoch 18/100\n",
      " - 7s - loss: 0.0807 - val_loss: 0.0939\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.09445 to 0.09393, saving model to regresion5_model.h5\n",
      "Epoch 19/100\n",
      " - 7s - loss: 0.0801 - val_loss: 0.0938\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.09393 to 0.09379, saving model to regresion5_model.h5\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.0795 - val_loss: 0.0934\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.09379 to 0.09341, saving model to regresion5_model.h5\n",
      "Epoch 21/100\n",
      " - 7s - loss: 0.0789 - val_loss: 0.0935\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.09341\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.0784 - val_loss: 0.0933\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.09341 to 0.09332, saving model to regresion5_model.h5\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.0779 - val_loss: 0.0930\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.09332 to 0.09297, saving model to regresion5_model.h5\n",
      "Epoch 24/100\n",
      " - 7s - loss: 0.0776 - val_loss: 0.0929\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.09297 to 0.09290, saving model to regresion5_model.h5\n",
      "Epoch 25/100\n",
      " - 7s - loss: 0.0775 - val_loss: 0.0919\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.09290 to 0.09189, saving model to regresion5_model.h5\n",
      "Epoch 26/100\n",
      " - 7s - loss: 0.0771 - val_loss: 0.0917\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.09189 to 0.09165, saving model to regresion5_model.h5\n",
      "Epoch 27/100\n",
      " - 7s - loss: 0.0766 - val_loss: 0.0920\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.09165\n",
      "Epoch 28/100\n",
      " - 7s - loss: 0.0763 - val_loss: 0.0921\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.09165\n",
      "Epoch 29/100\n",
      " - 7s - loss: 0.0758 - val_loss: 0.0922\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.09165\n",
      "Epoch 30/100\n",
      " - 7s - loss: 0.0756 - val_loss: 0.0915\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.09165 to 0.09149, saving model to regresion5_model.h5\n",
      "Epoch 31/100\n",
      " - 7s - loss: 0.0754 - val_loss: 0.0913\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.09149 to 0.09127, saving model to regresion5_model.h5\n",
      "Epoch 32/100\n",
      " - 7s - loss: 0.0752 - val_loss: 0.0909\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.09127 to 0.09089, saving model to regresion5_model.h5\n",
      "Epoch 33/100\n",
      " - 7s - loss: 0.0750 - val_loss: 0.0907\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.09089 to 0.09073, saving model to regresion5_model.h5\n",
      "Epoch 34/100\n",
      " - 7s - loss: 0.0748 - val_loss: 0.0903\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.09073 to 0.09026, saving model to regresion5_model.h5\n",
      "Epoch 35/100\n",
      " - 7s - loss: 0.0747 - val_loss: 0.0899\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.09026 to 0.08988, saving model to regresion5_model.h5\n",
      "Epoch 36/100\n",
      " - 7s - loss: 0.0745 - val_loss: 0.0897\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.08988 to 0.08971, saving model to regresion5_model.h5\n",
      "Epoch 37/100\n",
      " - 7s - loss: 0.0745 - val_loss: 0.0895\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.08971 to 0.08954, saving model to regresion5_model.h5\n",
      "Epoch 38/100\n",
      " - 7s - loss: 0.0744 - val_loss: 0.0891\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.08954 to 0.08914, saving model to regresion5_model.h5\n",
      "Epoch 39/100\n",
      " - 7s - loss: 0.0742 - val_loss: 0.0915\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08914\n",
      "Epoch 40/100\n",
      " - 7s - loss: 0.0743 - val_loss: 0.0888\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.08914 to 0.08884, saving model to regresion5_model.h5\n",
      "Epoch 41/100\n",
      " - 7s - loss: 0.0740 - val_loss: 0.0887\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.08884 to 0.08871, saving model to regresion5_model.h5\n",
      "Epoch 42/100\n",
      " - 7s - loss: 0.0738 - val_loss: 0.0885\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.08871 to 0.08852, saving model to regresion5_model.h5\n",
      "Epoch 43/100\n",
      " - 7s - loss: 0.0737 - val_loss: 0.0884\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.08852 to 0.08840, saving model to regresion5_model.h5\n",
      "Epoch 44/100\n",
      " - 7s - loss: 0.0737 - val_loss: 0.0884\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.08840 to 0.08835, saving model to regresion5_model.h5\n",
      "Epoch 45/100\n",
      " - 7s - loss: 0.0735 - val_loss: 0.0884\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08835\n",
      "Epoch 46/100\n",
      " - 7s - loss: 0.0734 - val_loss: 0.0880\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08835 to 0.08804, saving model to regresion5_model.h5\n",
      "Epoch 47/100\n",
      " - 7s - loss: 0.0733 - val_loss: 0.0879\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.08804 to 0.08789, saving model to regresion5_model.h5\n",
      "Epoch 48/100\n",
      " - 7s - loss: 0.0731 - val_loss: 0.0875\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.08789 to 0.08752, saving model to regresion5_model.h5\n",
      "Epoch 49/100\n",
      " - 7s - loss: 0.0731 - val_loss: 0.0875\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.08752 to 0.08747, saving model to regresion5_model.h5\n",
      "Epoch 50/100\n",
      " - 7s - loss: 0.0730 - val_loss: 0.0871\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.08747 to 0.08715, saving model to regresion5_model.h5\n",
      "Epoch 51/100\n",
      " - 7s - loss: 0.0729 - val_loss: 0.0872\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.08715\n",
      "Epoch 52/100\n",
      " - 7s - loss: 0.0728 - val_loss: 0.0870\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.08715 to 0.08705, saving model to regresion5_model.h5\n",
      "Epoch 53/100\n",
      " - 7s - loss: 0.0727 - val_loss: 0.0870\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.08705 to 0.08704, saving model to regresion5_model.h5\n",
      "Epoch 54/100\n",
      " - 7s - loss: 0.0726 - val_loss: 0.0870\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.08704 to 0.08700, saving model to regresion5_model.h5\n",
      "Epoch 55/100\n",
      " - 7s - loss: 0.0725 - val_loss: 0.0869\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.08700 to 0.08695, saving model to regresion5_model.h5\n",
      "Epoch 56/100\n",
      " - 7s - loss: 0.0724 - val_loss: 0.0867\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.08695 to 0.08671, saving model to regresion5_model.h5\n",
      "Epoch 57/100\n",
      " - 7s - loss: 0.0724 - val_loss: 0.0865\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.08671 to 0.08654, saving model to regresion5_model.h5\n",
      "Epoch 58/100\n",
      " - 7s - loss: 0.0723 - val_loss: 0.0865\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.08654 to 0.08646, saving model to regresion5_model.h5\n",
      "Epoch 59/100\n",
      " - 7s - loss: 0.0722 - val_loss: 0.0862\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.08646 to 0.08618, saving model to regresion5_model.h5\n",
      "Epoch 60/100\n",
      " - 7s - loss: 0.0721 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08618 to 0.08608, saving model to regresion5_model.h5\n",
      "Epoch 61/100\n",
      " - 7s - loss: 0.0720 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08608 to 0.08607, saving model to regresion5_model.h5\n",
      "Epoch 62/100\n",
      " - 7s - loss: 0.0719 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08607 to 0.08606, saving model to regresion5_model.h5\n",
      "Epoch 63/100\n",
      " - 7s - loss: 0.0718 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08606 to 0.08606, saving model to regresion5_model.h5\n",
      "Epoch 64/100\n",
      " - 7s - loss: 0.0718 - val_loss: 0.0862\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.08606\n",
      "Epoch 65/100\n",
      " - 7s - loss: 0.0718 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08606 to 0.08601, saving model to regresion5_model.h5\n",
      "Epoch 66/100\n",
      " - 7s - loss: 0.0717 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08601 to 0.08596, saving model to regresion5_model.h5\n",
      "Epoch 67/100\n",
      " - 7s - loss: 0.0716 - val_loss: 0.0859\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08596 to 0.08586, saving model to regresion5_model.h5\n",
      "Epoch 68/100\n",
      " - 7s - loss: 0.0716 - val_loss: 0.0858\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08586 to 0.08581, saving model to regresion5_model.h5\n",
      "Epoch 69/100\n",
      " - 7s - loss: 0.0716 - val_loss: 0.0858\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.08581 to 0.08578, saving model to regresion5_model.h5\n",
      "Epoch 70/100\n",
      " - 7s - loss: 0.0715 - val_loss: 0.0857\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.08578 to 0.08571, saving model to regresion5_model.h5\n",
      "Epoch 71/100\n",
      " - 7s - loss: 0.0715 - val_loss: 0.0858\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08571\n",
      "Epoch 72/100\n",
      " - 7s - loss: 0.0714 - val_loss: 0.0856\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08571 to 0.08555, saving model to regresion5_model.h5\n",
      "Epoch 73/100\n",
      " - 7s - loss: 0.0714 - val_loss: 0.0856\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08555\n",
      "Epoch 74/100\n",
      " - 7s - loss: 0.0714 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.08555 to 0.08551, saving model to regresion5_model.h5\n",
      "Epoch 75/100\n",
      " - 7s - loss: 0.0714 - val_loss: 0.0856\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.08551\n",
      "Epoch 76/100\n",
      " - 7s - loss: 0.0713 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08551 to 0.08521, saving model to regresion5_model.h5\n",
      "Epoch 77/100\n",
      " - 7s - loss: 0.0713 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.08521\n",
      "Epoch 78/100\n",
      " - 7s - loss: 0.0713 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.08521\n",
      "Epoch 79/100\n",
      " - 7s - loss: 0.0712 - val_loss: 0.0854\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.08521\n",
      "Epoch 80/100\n",
      " - 7s - loss: 0.0713 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.08521 to 0.08492, saving model to regresion5_model.h5\n",
      "Epoch 81/100\n",
      " - 7s - loss: 0.0712 - val_loss: 0.0854\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.08492\n",
      "Epoch 82/100\n",
      " - 7s - loss: 0.0712 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.08492\n",
      "Epoch 83/100\n",
      " - 7s - loss: 0.0710 - val_loss: 0.0853\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.08492\n",
      "Epoch 84/100\n",
      " - 7s - loss: 0.0710 - val_loss: 0.0850\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.08492\n",
      "Epoch 85/100\n",
      " - 7s - loss: 0.0710 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.08492\n",
      "Epoch 86/100\n",
      " - 7s - loss: 0.0710 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.08492\n",
      "Epoch 87/100\n",
      " - 7s - loss: 0.0709 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.08492\n",
      "Epoch 88/100\n",
      " - 7s - loss: 0.0708 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.08492\n",
      "Epoch 89/100\n",
      " - 7s - loss: 0.0708 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.08492 to 0.08489, saving model to regresion5_model.h5\n",
      "Epoch 90/100\n",
      " - 7s - loss: 0.0708 - val_loss: 0.0850\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.08489\n",
      "Epoch 91/100\n",
      " - 7s - loss: 0.0708 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.08489\n",
      "Epoch 92/100\n",
      " - 7s - loss: 0.0707 - val_loss: 0.0850\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.08489\n",
      "Epoch 93/100\n",
      " - 7s - loss: 0.0707 - val_loss: 0.0850\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.08489\n",
      "Epoch 94/100\n",
      " - 7s - loss: 0.0707 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.08489\n",
      "Epoch 95/100\n",
      " - 7s - loss: 0.0706 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.08489\n",
      "Epoch 96/100\n",
      " - 7s - loss: 0.0706 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.08489\n",
      "Epoch 97/100\n",
      " - 7s - loss: 0.0705 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.08489\n",
      "Epoch 98/100\n",
      " - 7s - loss: 0.0705 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.08489\n",
      "Epoch 99/100\n",
      " - 7s - loss: 0.0705 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.08489\n",
      "Epoch 00099: early stopping\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "# diseñar la red bidireccional LSTM\n",
    "\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "n_outputs=1\n",
    "model_path_clf = 'regresion5_model.h5'  \n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(200,return_sequences=True), input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "# entrenar la red\n",
    "history = model.fit(x_train, y_train3d, epochs=100, batch_size=32, validation_data=(x_test, y_test3d), verbose=2, shuffle=False,\n",
    "            callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=2, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path_clf, monitor='val_loss', save_best_only=True, mode='min', verbose=2)])\n",
    "print(history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el mejor modelo guardado durante el entrenamiento\n",
    "\n",
    "saved_model = load_model('regresion5_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediccion\n",
    "yhat = saved_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1, 1)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.49805832]],\n",
       "\n",
       "       [[0.5158036 ]],\n",
       "\n",
       "       [[0.50115514]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.04012182]],\n",
       "\n",
       "       [[0.03145239]],\n",
       "\n",
       "       [[0.01738974]]], dtype=float32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 25)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[2]))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape((len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir el pronostico a 2d\n",
    "yhat = yhat.reshape((len(yhat), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.115\n"
     ]
    }
   ],
   "source": [
    "# calcular RMSE\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat = concatenate((yhat, x_test[:, :]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 26)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49805832, 0.        , 0.63218391, 0.75      , 0.        ,\n",
       "       0.        , 0.54518072, 0.31066056, 0.26941256, 0.        ,\n",
       "       1.        , 0.65217391, 0.21212121, 0.12761375, 0.        ,\n",
       "       0.20833333, 0.64605544, 0.22058824, 0.13216018, 0.30896499,\n",
       "       0.        , 0.33333333, 0.        , 0.        , 0.55813953,\n",
       "       0.66183375])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat2 = scaler.inverse_transform(inv_yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.80799053e+02, -8.70000000e-03,  1.58620690e-04, ...,\n",
       "         3.81400000e+01,  2.32984047e+01,  2.38921983e+02],\n",
       "       [ 1.87205091e+02, -8.65180055e-03, -1.86206897e-04, ...,\n",
       "         3.81400000e+01,  2.33882279e+01,  2.47944490e+02],\n",
       "       [ 1.81917005e+02, -8.60360111e-03,  2.06896552e-05, ...,\n",
       "         3.81400000e+01,  2.34219116e+01,  2.60406518e+02],\n",
       "       ...,\n",
       "       [ 1.54839783e+01,  6.98891967e-04, -4.13793103e-05, ...,\n",
       "         3.81400000e+01,  2.31636698e+01,  1.54977769e+02],\n",
       "       [ 1.23543119e+01,  7.47091413e-04, -2.62068966e-04, ...,\n",
       "         3.81400000e+01,  2.31861256e+01,  1.87279343e+02],\n",
       "       [ 7.27769777e+00,  7.95290859e-04,  8.96551724e-05, ...,\n",
       "         3.81400000e+01,  2.32085814e+01,  1.45207539e+02]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat3 = inv_yhat2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([180.79905319, 187.20509076, 181.91700482, ...,  15.4839783 ,\n",
       "        12.35431191,   7.27769777])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test transformado\n",
    "inv_yhat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143., 142., 141., ...,  23.,  22.,  21.])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inv_y = concatenate((y_test, x_test[:,:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "METRICAS DE DESEMPEÑO DEL MODELO DE REGRESION\n",
      "------------------------------------------------------------\n",
      "Mean Deviation (MD): 8.81\n",
      "Mean Absolute Error (MAE): 30.64\n",
      "------------------------------------------------------------\n",
      "Mean Squared Error (MSE): 1714.39\n",
      "Root Mean Squared Error (RMSE): 41.41\n",
      "------------------------------------------------------------\n",
      "Mean Percent Error (MPE): -1.23\n",
      "Mean Absolute Percent Error (MAPE): 23.12\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "regression_metrics(inv_y, inv_yhat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo con menor error relativo es la red stacked LSTM con un MAPE estimado del 22.72%, pero si tomamos en cuenta las dos metricas, el algoritmo de regresion con mejor desempeño es la red LSTM bidireccional (BLSTM) con un RMSE de 41.41 ciclos (unidad de medida de tiempo) y un MAPE de 23.12%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar datos para el nuevo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos de nuevo para el modelo, ya que se habian modificado por escalado y reshape\n",
    "# no hay cambios en los datos, son las mismas lineas de la parte superior del codigo\n",
    "\n",
    "columns=[\"id\",\"ciclo\",\"set1\",\"set2\",\"set3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]\n",
    "train=pd.read_csv(\"train_FD001.txt\",sep=\" \",names=columns)\n",
    "test=pd.read_csv(\"test_FD001.txt\",sep=\" \",names=columns)\n",
    "rul=pd.read_csv(\"RUL_FD001.txt\",sep=\" \",header=None)\n",
    "train.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "test.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "rul.drop([1], axis=1, inplace=True)\n",
    "rul.columns = ['ttf']\n",
    "rul2=pd.DataFrame(train.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul2.columns = ['id', 'falla']\n",
    "train= train.merge(rul2, on=['id'], how='left')\n",
    "train['ttf'] = train['falla'] - train['ciclo']\n",
    "train.drop('falla', axis=1, inplace=True)\n",
    "rul3=pd.DataFrame(test.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul3.columns = ['id', 'falla']\n",
    "rul['id'] = rul.index + 1\n",
    "rul['falla'] = rul3['falla'] + rul['ttf']\n",
    "rul.drop('ttf', axis=1, inplace=True)\n",
    "test=test.merge(rul, on=['id'], how='left')\n",
    "test['ttf'] = test['falla'] - test['ciclo']\n",
    "test.drop('falla', axis=1, inplace=True)\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "variables=['ciclo','set1','set2','set3','sensor1','sensor2','sensor3','sensor4','sensor5','sensor6','sensor7','sensor8','sensor9','sensor10','sensor11','sensor12','sensor13','sensor14','sensor15','sensor16','sensor17','sensor18','sensor19','sensor20','sensor21','ttf']\n",
    "objetivo='ttf'\n",
    "scaler = MinMaxScaler()\n",
    "train[variables]=scaler.fit_transform(train[variables])\n",
    "test[variables]=scaler.transform(test[variables])\n",
    "x_train=train.iloc[:,np.r_[0:25]]\n",
    "x_test=test.iloc[:,np.r_[0:25]]\n",
    "y_train=train.iloc[:,25]\n",
    "y_test=test.iloc[:,25]\n",
    "x_test=x_test.to_numpy()\n",
    "x_train=x_train.to_numpy()\n",
    "y_test=y_test.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "n_steps = 1\n",
    "x_train = x_train.reshape((x_train.shape[0], n_steps, x_train.shape[1])) \n",
    "x_test = x_test.reshape((x_test.shape[0], n_steps, x_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covertir y_train de 2d a 3d\n",
    "y_train3d = y_train.reshape((y_train.shape[0], n_steps, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 1, 1)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1, 1)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covertir y_test de 2d a 3d\n",
    "y_test3d = y_test.reshape((y_test.shape[0], n_steps, 1))\n",
    "y_test3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20631 samples, validate on 13096 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 0.1124 - val_loss: 0.1772\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17725, saving model to regresion7_model.h5\n",
      "Epoch 2/100\n",
      " - 8s - loss: 0.0971 - val_loss: 0.1942\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.17725\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.0939 - val_loss: 0.1491\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17725 to 0.14914, saving model to regresion7_model.h5\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.0911 - val_loss: 0.1155\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.14914 to 0.11546, saving model to regresion7_model.h5\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0882 - val_loss: 0.1100\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11546 to 0.11002, saving model to regresion7_model.h5\n",
      "Epoch 6/100\n",
      " - 8s - loss: 0.0874 - val_loss: 0.1048\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11002 to 0.10478, saving model to regresion7_model.h5\n",
      "Epoch 7/100\n",
      " - 8s - loss: 0.0873 - val_loss: 0.1042\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10478 to 0.10417, saving model to regresion7_model.h5\n",
      "Epoch 8/100\n",
      " - 8s - loss: 0.0862 - val_loss: 0.0989\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10417 to 0.09890, saving model to regresion7_model.h5\n",
      "Epoch 9/100\n",
      " - 8s - loss: 0.0857 - val_loss: 0.0974\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09890 to 0.09739, saving model to regresion7_model.h5\n",
      "Epoch 10/100\n",
      " - 8s - loss: 0.0850 - val_loss: 0.0964\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09739 to 0.09636, saving model to regresion7_model.h5\n",
      "Epoch 11/100\n",
      " - 8s - loss: 0.0841 - val_loss: 0.0996\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.09636\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.0837 - val_loss: 0.0951\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09636 to 0.09515, saving model to regresion7_model.h5\n",
      "Epoch 13/100\n",
      " - 8s - loss: 0.0826 - val_loss: 0.0937\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.09515 to 0.09365, saving model to regresion7_model.h5\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.0823 - val_loss: 0.0927\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09365 to 0.09269, saving model to regresion7_model.h5\n",
      "Epoch 15/100\n",
      " - 8s - loss: 0.0815 - val_loss: 0.0916\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.09269 to 0.09159, saving model to regresion7_model.h5\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.0813 - val_loss: 0.0969\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.09159\n",
      "Epoch 17/100\n",
      " - 7s - loss: 0.0811 - val_loss: 0.0909\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.09159 to 0.09092, saving model to regresion7_model.h5\n",
      "Epoch 18/100\n",
      " - 8s - loss: 0.0802 - val_loss: 0.0916\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.09092\n",
      "Epoch 19/100\n",
      " - 8s - loss: 0.0798 - val_loss: 0.0895\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.09092 to 0.08949, saving model to regresion7_model.h5\n",
      "Epoch 20/100\n",
      " - 8s - loss: 0.0789 - val_loss: 0.0896\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.08949\n",
      "Epoch 21/100\n",
      " - 8s - loss: 0.0786 - val_loss: 0.0893\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.08949 to 0.08931, saving model to regresion7_model.h5\n",
      "Epoch 22/100\n",
      " - 8s - loss: 0.0783 - val_loss: 0.0892\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.08931 to 0.08924, saving model to regresion7_model.h5\n",
      "Epoch 23/100\n",
      " - 8s - loss: 0.0775 - val_loss: 0.0893\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.08924\n",
      "Epoch 24/100\n",
      " - 8s - loss: 0.0772 - val_loss: 0.0893\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.08924\n",
      "Epoch 25/100\n",
      " - 8s - loss: 0.0768 - val_loss: 0.0892\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.08924 to 0.08922, saving model to regresion7_model.h5\n",
      "Epoch 26/100\n",
      " - 8s - loss: 0.0763 - val_loss: 0.0892\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.08922 to 0.08915, saving model to regresion7_model.h5\n",
      "Epoch 27/100\n",
      " - 8s - loss: 0.0761 - val_loss: 0.0892\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.08915\n",
      "Epoch 28/100\n",
      " - 8s - loss: 0.0759 - val_loss: 0.0894\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.08915\n",
      "Epoch 29/100\n",
      " - 8s - loss: 0.0756 - val_loss: 0.0891\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.08915 to 0.08912, saving model to regresion7_model.h5\n",
      "Epoch 30/100\n",
      " - 8s - loss: 0.0753 - val_loss: 0.0893\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.08912\n",
      "Epoch 31/100\n",
      " - 8s - loss: 0.0751 - val_loss: 0.0891\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.08912 to 0.08908, saving model to regresion7_model.h5\n",
      "Epoch 32/100\n",
      " - 8s - loss: 0.0749 - val_loss: 0.0894\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.08908\n",
      "Epoch 33/100\n",
      " - 8s - loss: 0.0747 - val_loss: 0.0914\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.08908\n",
      "Epoch 34/100\n",
      " - 7s - loss: 0.0745 - val_loss: 0.0891\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.08908\n",
      "Epoch 35/100\n",
      " - 8s - loss: 0.0744 - val_loss: 0.0897\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08908\n",
      "Epoch 36/100\n",
      " - 8s - loss: 0.0742 - val_loss: 0.0895\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.08908\n",
      "Epoch 37/100\n",
      " - 8s - loss: 0.0740 - val_loss: 0.0891\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08908\n",
      "Epoch 38/100\n",
      " - 8s - loss: 0.0739 - val_loss: 0.0887\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.08908 to 0.08875, saving model to regresion7_model.h5\n",
      "Epoch 39/100\n",
      " - 8s - loss: 0.0737 - val_loss: 0.0894\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08875\n",
      "Epoch 40/100\n",
      " - 7s - loss: 0.0735 - val_loss: 0.0888\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08875\n",
      "Epoch 41/100\n",
      " - 7s - loss: 0.0734 - val_loss: 0.0887\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.08875 to 0.08869, saving model to regresion7_model.h5\n",
      "Epoch 42/100\n",
      " - 7s - loss: 0.0733 - val_loss: 0.0886\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.08869 to 0.08856, saving model to regresion7_model.h5\n",
      "Epoch 43/100\n",
      " - 7s - loss: 0.0732 - val_loss: 0.0887\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.08856\n",
      "Epoch 44/100\n",
      " - 7s - loss: 0.0731 - val_loss: 0.0890\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08856\n",
      "Epoch 45/100\n",
      " - 7s - loss: 0.0730 - val_loss: 0.0887\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08856\n",
      "Epoch 46/100\n",
      " - 7s - loss: 0.0729 - val_loss: 0.0884\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08856 to 0.08841, saving model to regresion7_model.h5\n",
      "Epoch 47/100\n",
      " - 8s - loss: 0.0729 - val_loss: 0.0885\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.08841\n",
      "Epoch 48/100\n",
      " - 7s - loss: 0.0727 - val_loss: 0.0885\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08841\n",
      "Epoch 49/100\n",
      " - 8s - loss: 0.0726 - val_loss: 0.0883\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.08841 to 0.08828, saving model to regresion7_model.h5\n",
      "Epoch 50/100\n",
      " - 7s - loss: 0.0728 - val_loss: 0.0881\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.08828 to 0.08813, saving model to regresion7_model.h5\n",
      "Epoch 51/100\n",
      " - 8s - loss: 0.0726 - val_loss: 0.0884\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.08813\n",
      "Epoch 52/100\n",
      " - 7s - loss: 0.0725 - val_loss: 0.0882\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.08813\n",
      "Epoch 53/100\n",
      " - 7s - loss: 0.0724 - val_loss: 0.0881\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.08813 to 0.08806, saving model to regresion7_model.h5\n",
      "Epoch 54/100\n",
      " - 8s - loss: 0.0724 - val_loss: 0.0881\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.08806\n",
      "Epoch 55/100\n",
      " - 7s - loss: 0.0724 - val_loss: 0.0881\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.08806\n",
      "Epoch 56/100\n",
      " - 8s - loss: 0.0723 - val_loss: 0.0880\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.08806 to 0.08799, saving model to regresion7_model.h5\n",
      "Epoch 57/100\n",
      " - 7s - loss: 0.0723 - val_loss: 0.0877\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.08799 to 0.08771, saving model to regresion7_model.h5\n",
      "Epoch 58/100\n",
      " - 7s - loss: 0.0722 - val_loss: 0.0882\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.08771\n",
      "Epoch 59/100\n",
      " - 8s - loss: 0.0722 - val_loss: 0.0877\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.08771\n",
      "Epoch 60/100\n",
      " - 8s - loss: 0.0722 - val_loss: 0.0877\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.08771\n",
      "Epoch 61/100\n",
      " - 7s - loss: 0.0720 - val_loss: 0.0878\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.08771\n",
      "Epoch 62/100\n",
      " - 8s - loss: 0.0720 - val_loss: 0.0874\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08771 to 0.08736, saving model to regresion7_model.h5\n",
      "Epoch 63/100\n",
      " - 7s - loss: 0.0720 - val_loss: 0.0872\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08736 to 0.08719, saving model to regresion7_model.h5\n",
      "Epoch 64/100\n",
      " - 8s - loss: 0.0720 - val_loss: 0.0868\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.08719 to 0.08682, saving model to regresion7_model.h5\n",
      "Epoch 65/100\n",
      " - 8s - loss: 0.0720 - val_loss: 0.0869\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.08682\n",
      "Epoch 66/100\n",
      " - 8s - loss: 0.0719 - val_loss: 0.0869\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.08682\n",
      "Epoch 67/100\n",
      " - 7s - loss: 0.0719 - val_loss: 0.0866\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.08682 to 0.08658, saving model to regresion7_model.h5\n",
      "Epoch 68/100\n",
      " - 7s - loss: 0.0718 - val_loss: 0.0867\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.08658\n",
      "Epoch 69/100\n",
      " - 8s - loss: 0.0718 - val_loss: 0.0864\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.08658 to 0.08645, saving model to regresion7_model.h5\n",
      "Epoch 70/100\n",
      " - 7s - loss: 0.0717 - val_loss: 0.0863\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.08645 to 0.08632, saving model to regresion7_model.h5\n",
      "Epoch 71/100\n",
      " - 7s - loss: 0.0716 - val_loss: 0.0864\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08632\n",
      "Epoch 72/100\n",
      " - 8s - loss: 0.0717 - val_loss: 0.0863\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.08632 to 0.08626, saving model to regresion7_model.h5\n",
      "Epoch 73/100\n",
      " - 8s - loss: 0.0716 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.08626 to 0.08612, saving model to regresion7_model.h5\n",
      "Epoch 74/100\n",
      " - 7s - loss: 0.0716 - val_loss: 0.0863\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.08612\n",
      "Epoch 75/100\n",
      " - 7s - loss: 0.0715 - val_loss: 0.0862\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.08612\n",
      "Epoch 76/100\n",
      " - 8s - loss: 0.0715 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.08612 to 0.08605, saving model to regresion7_model.h5\n",
      "Epoch 77/100\n",
      " - 7s - loss: 0.0712 - val_loss: 0.0865\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.08605\n",
      "Epoch 78/100\n",
      " - 7s - loss: 0.0713 - val_loss: 0.0862\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.08605\n",
      "Epoch 79/100\n",
      " - 8s - loss: 0.0712 - val_loss: 0.0862\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.08605\n",
      "Epoch 80/100\n",
      " - 7s - loss: 0.0712 - val_loss: 0.0862\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.08605\n",
      "Epoch 81/100\n",
      " - 8s - loss: 0.0712 - val_loss: 0.0861\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.08605\n",
      "Epoch 82/100\n",
      " - 7s - loss: 0.0712 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.08605 to 0.08596, saving model to regresion7_model.h5\n",
      "Epoch 83/100\n",
      " - 7s - loss: 0.0711 - val_loss: 0.0859\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.08596 to 0.08591, saving model to regresion7_model.h5\n",
      "Epoch 84/100\n",
      " - 7s - loss: 0.0710 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.08591\n",
      "Epoch 85/100\n",
      " - 7s - loss: 0.0709 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.08591\n",
      "Epoch 86/100\n",
      " - 7s - loss: 0.0711 - val_loss: 0.0856\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.08591 to 0.08559, saving model to regresion7_model.h5\n",
      "Epoch 87/100\n",
      " - 8s - loss: 0.0709 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.08559\n",
      "Epoch 88/100\n",
      " - 8s - loss: 0.0710 - val_loss: 0.0859\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.08559\n",
      "Epoch 89/100\n",
      " - 7s - loss: 0.0709 - val_loss: 0.0859\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.08559\n",
      "Epoch 90/100\n",
      " - 7s - loss: 0.0710 - val_loss: 0.0859\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.08559\n",
      "Epoch 91/100\n",
      " - 8s - loss: 0.0708 - val_loss: 0.0858\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.08559\n",
      "Epoch 92/100\n",
      " - 8s - loss: 0.0709 - val_loss: 0.0857\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.08559\n",
      "Epoch 93/100\n",
      " - 7s - loss: 0.0708 - val_loss: 0.0859\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.08559\n",
      "Epoch 94/100\n",
      " - 7s - loss: 0.0708 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.08559 to 0.08552, saving model to regresion7_model.h5\n",
      "Epoch 95/100\n",
      " - 7s - loss: 0.0708 - val_loss: 0.0857\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.08552\n",
      "Epoch 96/100\n",
      " - 8s - loss: 0.0709 - val_loss: 0.0857\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.08552\n",
      "Epoch 97/100\n",
      " - 7s - loss: 0.0707 - val_loss: 0.0856\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.08552\n",
      "Epoch 98/100\n",
      " - 8s - loss: 0.0707 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.08552 to 0.08548, saving model to regresion7_model.h5\n",
      "Epoch 99/100\n",
      " - 7s - loss: 0.0707 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.08548\n",
      "Epoch 100/100\n",
      " - 7s - loss: 0.0708 - val_loss: 0.0855\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.08548\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "# diseñar la red bidireccional LSTM\n",
    "\n",
    "n_outputs=1\n",
    "model_path_clf = 'regresion7_model.h5'  \n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(400,return_sequences=True), input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(TimeDistributed(Dense(200, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "# entrenar la red\n",
    "history = model.fit(x_train, y_train3d, epochs=100, batch_size=32, validation_data=(x_test, y_test3d), verbose=2, shuffle=False,\n",
    "            callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=2, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path_clf, monitor='val_loss', save_best_only=True, mode='min', verbose=2)])\n",
    "print(history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el mejor modelo guardado durante el entrenamiento\n",
    "\n",
    "saved_model = load_model('regresion7_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediccion\n",
    "yhat = saved_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1, 1)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4982419 ]],\n",
       "\n",
       "       [[0.5301308 ]],\n",
       "\n",
       "       [[0.49586183]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.03285381]],\n",
       "\n",
       "       [[0.03530513]],\n",
       "\n",
       "       [[0.02005161]]], dtype=float32)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 25)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[2]))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape((len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 1)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir el pronostico a 2d\n",
    "yhat = yhat.reshape((len(yhat), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.116\n"
     ]
    }
   ],
   "source": [
    "# calcular RMSE\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat = concatenate((yhat, x_test[:, :]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096, 26)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4982419 , 0.        , 0.63218391, 0.75      , 0.        ,\n",
       "       0.        , 0.54518072, 0.31066056, 0.26941256, 0.        ,\n",
       "       1.        , 0.65217391, 0.21212121, 0.12761375, 0.        ,\n",
       "       0.20833333, 0.64605544, 0.22058824, 0.13216018, 0.30896499,\n",
       "       0.        , 0.33333333, 0.        , 0.        , 0.55813953,\n",
       "       0.66183375])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat2 = scaler.inverse_transform(inv_yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.80865326e+02, -8.70000000e-03,  1.58620690e-04, ...,\n",
       "         3.81400000e+01,  2.32984047e+01,  2.38921983e+02],\n",
       "       [ 1.92377220e+02, -8.65180055e-03, -1.86206897e-04, ...,\n",
       "         3.81400000e+01,  2.33882279e+01,  2.47944490e+02],\n",
       "       [ 1.80006120e+02, -8.60360111e-03,  2.06896552e-05, ...,\n",
       "         3.81400000e+01,  2.34219116e+01,  2.60406518e+02],\n",
       "       ...,\n",
       "       [ 1.28602261e+01,  6.98891967e-04, -4.13793103e-05, ...,\n",
       "         3.81400000e+01,  2.31636698e+01,  1.54977769e+02],\n",
       "       [ 1.37451510e+01,  7.47091413e-04, -2.62068966e-04, ...,\n",
       "         3.81400000e+01,  2.31861256e+01,  1.87279343e+02],\n",
       "       [ 8.23863246e+00,  7.95290859e-04,  8.96551724e-05, ...,\n",
       "         3.81400000e+01,  2.32085814e+01,  1.45207539e+02]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat3 = inv_yhat2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([180.8653264 , 192.37722009, 180.00612003, ...,  12.86022612,\n",
       "        13.74515103,   8.23863246])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test transformado\n",
    "inv_yhat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143., 142., 141., ...,  23.,  22.,  21.])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inv_y = concatenate((y_test, x_test[:,:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "METRICAS DE DESEMPEÑO DEL MODELO DE REGRESION\n",
      "------------------------------------------------------------\n",
      "Mean Deviation (MD): 10.71\n",
      "Mean Absolute Error (MAE): 30.86\n",
      "------------------------------------------------------------\n",
      "Mean Squared Error (MSE): 1764.65\n",
      "Root Mean Squared Error (RMSE): 42.01\n",
      "------------------------------------------------------------\n",
      "Mean Percent Error (MPE): 0.28\n",
      "Mean Absolute Percent Error (MAPE): 23.11\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "regression_metrics(inv_y, inv_yhat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta las tres métricas de desempeño se observa que los algoritmos con la mejor precisión (menor MAPE y RMSE) y con menor sesgo (MPE cercano a cero) son las redes neuronales profundas (DNN), específicamente las redes neuronales LSTM y el perceptrón multicapa; en el segundo grupo ordenados en términos de desempeño están los algoritmos de conjunto, por último, se presentan los algoritmos de ML lineales y no lineales con los mayores errores de los experimentos. \n",
    "\n",
    "El algoritmo con menor error relativo es la red apilada LSTM con un MAPE estimado del 22.72% y el algoritmo con menor error absoluto es Gradient Boosting con un RMSE estimado de 40.8 ciclos (unidad de medida de tiempo), pero si tomamos en cuenta las tres métricas, el algoritmo de regresión con mejor desempeño es la red LSTM bidireccional (BLSTM) con un MAPE de 23.11%, un RMSE de 42.01 ciclos y un MPE de 0.28% lo que indica un bajo sesgo de los valores estimados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
