{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Ajuste de la arquitectura para la red LSTM\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso de estudio #1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tecnicas de ajuste de los datos y modelos:\n",
    "\n",
    "| Ingeniería de datos       | Si / No       |\n",
    "| :-------                  | :------:    |\n",
    "| Escalado de datos         | Si          |\n",
    "| Ajuste celdas de memoria            | Si          |\n",
    "| Ajuste tamaño de lote  | Si          |\n",
    "| Regularizacion  | Si          |\n",
    "| Ajuste de pesos  | Si          |\n",
    "| Sobremuestreo  | No        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# librerias\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from plot_metric.functions import BinaryClassification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "from sklearn import datasets \n",
    "from keras.models import model_from_json\n",
    "\n",
    "from numba import cuda\n",
    "from pandas import DataFrame\n",
    "from numpy import array\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from pandas import DataFrame\n",
    "from numpy import array\n",
    "from matplotlib import pyplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARIA funcion para generar matriz de confusion y medidas de desempeño del modelos clasificacion binarios\n",
    "def model_evaluation(data_train, label_train, data_test, label_test, modelo, label_pred):\n",
    "   # Medidas de desempeño del modelo\n",
    "    matriz = confusion_matrix(label_test, label_pred)\n",
    "    print('Confusion Matrix: \\n',confusion_matrix(label_test,label_pred))\n",
    "    print('\\n')\n",
    "    print(\"MEDIDAS DE DESEMPEÑO DEL MODELO\")\n",
    "    print('\\n')\n",
    "    print('Exactitud - Accuracy: {}'.format(accuracy_score(label_test,label_pred)))\n",
    "    print('ROC AUC: {}'.format (metrics.roc_auc_score(label_test, label_pred)))\n",
    "    print('-'*60)\n",
    "    print('Precisión por clase: {}'.format(metrics.precision_score(label_test, label_pred, average=None)))\n",
    "    print('Sensibilidad - Recall por clase: {}'.format(metrics.recall_score(label_test, label_pred, average=None)))\n",
    "    print('F1 por clase: {}'.format(metrics.f1_score(label_test, label_pred, average=None)))\n",
    "    print('-'*60)\n",
    "    print('F1 Macro: {}'.format(metrics.f1_score(label_test, label_pred, average='macro')))\n",
    "    print('F1 Micro: {}'.format(metrics.f1_score(label_test, label_pred, average='micro')))\n",
    "    print('F1 Weighted: {}'.format(metrics.f1_score(label_test, label_pred, average='weighted')))\n",
    "    print('-'*60)\n",
    "    print('Sensibilidad - Recall Macro: {}'.format(metrics.recall_score(label_test, label_pred, average='macro')))\n",
    "    print('Sensibilidad - Recall Micro: {}'.format(metrics.recall_score(label_test, label_pred, average='micro')))\n",
    "    print('Sensibilidad - Recall Weighted: {}'.format(metrics.recall_score(label_test, label_pred, average='weighted')))\n",
    "    print('-'*60)\n",
    "    print('Precisión Macro: {}'.format(metrics.precision_score(label_test, label_pred, average='macro')))\n",
    "    print('Precisión Micro: {}'.format(metrics.precision_score(label_test, label_pred, average='micro')))\n",
    "    print('Precisión Weighted: {}'.format(metrics.precision_score(label_test, label_pred, average='weighted')))\n",
    "   \n",
    "    TP = matriz[1][1]\n",
    "    TN = matriz[0][0]\n",
    "    FP = matriz[0][1]\n",
    "    FN = matriz[1][0]\n",
    "    print('-'*60)\n",
    "    print('Verdaderos positivos - True Positives:', TP)\n",
    "    print('Verdaderos negativos - True Negatives:', TN)\n",
    "    print('Falsos positivos - False Positives:', FP)\n",
    "    print('Falsos negativos - False Negatives:', FN)\n",
    "        # calculate accuracy\n",
    "    conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n",
    "        # calculate mis-classification\n",
    "    conf_misclassification = 1- conf_accuracy\n",
    "        # calculate the sensitivity\n",
    "    conf_sensitivity = (TP / float(TP + FN))\n",
    "        # calculate the specificity\n",
    "    conf_specificity = (TN / float(TN + FN))\n",
    "        # calculate precision\n",
    "    conf_precision = (TP / float(TP + FP))\n",
    "        # calculate f_1 score\n",
    "    conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))\n",
    "        # calculate FPR tasa de falsos positivos\n",
    "    conf_FPR = 1 - conf_specificity\n",
    "    print('-'*60)\n",
    "    print(f'Error de clasificacion: {round(conf_misclassification,3)}') \n",
    "    print(f'Especificidad - Specificity: {round(conf_specificity,3)}') \n",
    "    print(f'Tasa de falsos positivos FPR: {round(conf_FPR,3)}')\n",
    "    print('-'*60)\n",
    "    print(classification_report(label_test, label_pred))\n",
    "    # curva ROC clasificacion binaria\n",
    "    bc = BinaryClassification(label_test, label_pred, labels=[\"Class 0\", \"Class 1\"])\n",
    "    plt.figure(figsize=(5,5))\n",
    "    bc.plot_roc_curve()\n",
    "    print('\\n')\n",
    "    print(\"CURVA ROC\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para graficar curva de aprendizaje de perdida y precision \n",
    "def history_plot(hist1, hist2, title, ylabl, xlabl):\n",
    "    fig_acc = plt.figure(figsize=(12,4))\n",
    "    plt.plot(history.history[hist1])\n",
    "    plt.plot(history.history[hist2])\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabl)\n",
    "    plt.xlabel(xlabl)\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ciclo</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "      <th>ttf</th>\n",
       "      <th>clase1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ciclo    set1    set2   set3  sensor1  sensor2  sensor3  sensor4  \\\n",
       "0   1      1 -0.0007 -0.0004  100.0   518.67   641.82  1589.70  1400.60   \n",
       "1   1      2  0.0019 -0.0003  100.0   518.67   642.15  1591.82  1403.14   \n",
       "2   1      3 -0.0043  0.0003  100.0   518.67   642.35  1587.99  1404.20   \n",
       "3   1      4  0.0007  0.0000  100.0   518.67   642.35  1582.79  1401.87   \n",
       "4   1      5 -0.0019 -0.0002  100.0   518.67   642.37  1582.85  1406.22   \n",
       "\n",
       "   sensor5  ...  sensor14  sensor15  sensor16  sensor17  sensor18  sensor19  \\\n",
       "0    14.62  ...   8138.62    8.4195      0.03       392      2388     100.0   \n",
       "1    14.62  ...   8131.49    8.4318      0.03       392      2388     100.0   \n",
       "2    14.62  ...   8133.23    8.4178      0.03       390      2388     100.0   \n",
       "3    14.62  ...   8133.83    8.3682      0.03       392      2388     100.0   \n",
       "4    14.62  ...   8133.80    8.4294      0.03       393      2388     100.0   \n",
       "\n",
       "   sensor20  sensor21  ttf  clase1  \n",
       "0     39.06   23.4190  191       0  \n",
       "1     39.00   23.4236  190       0  \n",
       "2     38.95   23.3442  189       0  \n",
       "3     38.88   23.3739  188       0  \n",
       "4     38.90   23.4044  187       0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=[\"id\",\"ciclo\",\"set1\",\"set2\",\"set3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]\n",
    "train=pd.read_csv(\"train_FD001.txt\",sep=\" \",names=columns)\n",
    "test=pd.read_csv(\"test_FD001.txt\",sep=\" \",names=columns)\n",
    "rul=pd.read_csv(\"RUL_FD001.txt\",sep=\" \",header=None)\n",
    "train.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "test.drop(['sensor22','sensor23'], axis=1, inplace=True)\n",
    "rul.drop([1], axis=1, inplace=True)\n",
    "rul.columns = ['ttf']\n",
    "rul2=pd.DataFrame(train.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul2.columns = ['id', 'falla']\n",
    "train= train.merge(rul2, on=['id'], how='left')\n",
    "train['ttf'] = train['falla'] - train['ciclo']\n",
    "train.drop('falla', axis=1, inplace=True)\n",
    "train['clase1']=np.where(train['ttf'] <= 30, 1, 0)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ciclo</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "      <th>ttf</th>\n",
       "      <th>clase1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8125.55</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ciclo    set1    set2   set3  sensor1  sensor2  sensor3  sensor4  \\\n",
       "0   1      1  0.0023  0.0003  100.0   518.67   643.02  1585.29  1398.21   \n",
       "1   1      2 -0.0027 -0.0003  100.0   518.67   641.71  1588.45  1395.42   \n",
       "2   1      3  0.0003  0.0001  100.0   518.67   642.46  1586.94  1401.34   \n",
       "3   1      4  0.0042  0.0000  100.0   518.67   642.44  1584.12  1406.42   \n",
       "4   1      5  0.0014  0.0000  100.0   518.67   642.51  1587.19  1401.92   \n",
       "\n",
       "   sensor5  ...  sensor14  sensor15  sensor16  sensor17  sensor18  sensor19  \\\n",
       "0    14.62  ...   8125.55    8.4052      0.03       392      2388     100.0   \n",
       "1    14.62  ...   8139.62    8.3803      0.03       393      2388     100.0   \n",
       "2    14.62  ...   8130.10    8.4441      0.03       393      2388     100.0   \n",
       "3    14.62  ...   8132.90    8.3917      0.03       391      2388     100.0   \n",
       "4    14.62  ...   8129.54    8.4031      0.03       390      2388     100.0   \n",
       "\n",
       "   sensor20  sensor21  ttf  clase1  \n",
       "0     38.86   23.3735  142       0  \n",
       "1     39.02   23.3916  141       0  \n",
       "2     39.08   23.4166  140       0  \n",
       "3     39.00   23.3737  139       0  \n",
       "4     38.99   23.4130  138       0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rul3=pd.DataFrame(test.groupby('id')['ciclo'].max()).reset_index()\n",
    "rul3.columns = ['id', 'falla']\n",
    "rul['id'] = rul.index + 1\n",
    "rul['falla'] = rul3['falla'] + rul['ttf']\n",
    "rul.drop('ttf', axis=1, inplace=True)\n",
    "test=test.merge(rul, on=['id'], how='left')\n",
    "test['ttf'] = test['falla'] - test['ciclo']\n",
    "test.drop('falla', axis=1, inplace=True)\n",
    "test['clase1']=np.where(test['ttf'] <= 30, 1, 0)\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ciclo</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "      <th>ttf</th>\n",
       "      <th>clase1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ciclo      set1      set2  set3  sensor1   sensor2   sensor3   sensor4  \\\n",
       "0   1      1  0.459770  0.166667   0.0      0.0  0.183735  0.406802  0.309757   \n",
       "1   1      2  0.609195  0.250000   0.0      0.0  0.283133  0.453019  0.352633   \n",
       "2   1      3  0.252874  0.750000   0.0      0.0  0.343373  0.369523  0.370527   \n",
       "3   1      4  0.540230  0.500000   0.0      0.0  0.343373  0.256159  0.331195   \n",
       "4   1      5  0.390805  0.333333   0.0      0.0  0.349398  0.257467  0.404625   \n",
       "\n",
       "   sensor5  ...  sensor14  sensor15  sensor16  sensor17  sensor18  sensor19  \\\n",
       "0      0.0  ...  0.199608  0.363986       0.0  0.333333       0.0       0.0   \n",
       "1      0.0  ...  0.162813  0.411312       0.0  0.333333       0.0       0.0   \n",
       "2      0.0  ...  0.171793  0.357445       0.0  0.166667       0.0       0.0   \n",
       "3      0.0  ...  0.174889  0.166603       0.0  0.333333       0.0       0.0   \n",
       "4      0.0  ...  0.174734  0.402078       0.0  0.416667       0.0       0.0   \n",
       "\n",
       "   sensor20  sensor21  ttf  clase1  \n",
       "0  0.713178  0.724662  191       0  \n",
       "1  0.666667  0.731014  190       0  \n",
       "2  0.627907  0.621375  189       0  \n",
       "3  0.573643  0.662386  188       0  \n",
       "4  0.589147  0.704502  187       0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables=['set1','set2','set3','sensor1','sensor2','sensor3','sensor4','sensor5','sensor6','sensor7','sensor8','sensor9','sensor10','sensor11','sensor12','sensor13','sensor14','sensor15','sensor16','sensor17','sensor18','sensor19','sensor20','sensor21']\n",
    "objetivo='clase1'\n",
    "# escalado de datos sin incluir id, ciclo, ttf y clase\n",
    "scaler = MinMaxScaler()\n",
    "train[variables]=scaler.fit_transform(train[variables])\n",
    "test[variables]=scaler.transform(test[variables])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ciclo</th>\n",
       "      <th>set1</th>\n",
       "      <th>set2</th>\n",
       "      <th>set3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "      <th>ttf</th>\n",
       "      <th>clase1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132160</td>\n",
       "      <td>0.308965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170090</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152751</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ciclo      set1      set2  set3  sensor1   sensor2   sensor3   sensor4  \\\n",
       "0   1      1  0.632184  0.750000   0.0      0.0  0.545181  0.310661  0.269413   \n",
       "1   1      2  0.344828  0.250000   0.0      0.0  0.150602  0.379551  0.222316   \n",
       "2   1      3  0.517241  0.583333   0.0      0.0  0.376506  0.346632  0.322248   \n",
       "3   1      4  0.741379  0.500000   0.0      0.0  0.370482  0.285154  0.408001   \n",
       "4   1      5  0.580460  0.500000   0.0      0.0  0.391566  0.352082  0.332039   \n",
       "\n",
       "   sensor5  ...  sensor14  sensor15  sensor16  sensor17  sensor18  sensor19  \\\n",
       "0      0.0  ...  0.132160  0.308965       0.0  0.333333       0.0       0.0   \n",
       "1      0.0  ...  0.204768  0.213159       0.0  0.416667       0.0       0.0   \n",
       "2      0.0  ...  0.155640  0.458638       0.0  0.416667       0.0       0.0   \n",
       "3      0.0  ...  0.170090  0.257022       0.0  0.250000       0.0       0.0   \n",
       "4      0.0  ...  0.152751  0.300885       0.0  0.166667       0.0       0.0   \n",
       "\n",
       "   sensor20  sensor21  ttf  clase1  \n",
       "0  0.558140  0.661834  142       0  \n",
       "1  0.682171  0.686827  141       0  \n",
       "2  0.728682  0.721348  140       0  \n",
       "3  0.666667  0.662110  139       0  \n",
       "4  0.658915  0.716377  138       0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de dimensiones = 2\n",
      "tamaño de la tabla = (20631, 28)\n",
      "total datos = 577668\n"
     ]
    }
   ],
   "source": [
    "print(\"numero de dimensiones =\", train.ndim)\n",
    "print(\"tamaño de la tabla =\", train.shape)\n",
    "print(\"total datos =\", train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de dimensiones = 2\n",
      "tamaño de la tabla = (13096, 28)\n",
      "total datos = 366688\n"
     ]
    }
   ],
   "source": [
    "print(\"numero de dimensiones =\", test.ndim)\n",
    "print(\"tamaño de la tabla =\", test.shape)\n",
    "print(\"total datos =\", test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcionar para adaptar datos como lo requiere LSTM\n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    df_zeros=pd.DataFrame(np.zeros((seq_length-1,id_df.shape[1])),columns=id_df.columns)\n",
    "    id_df=df_zeros.append(id_df,ignore_index=True)\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    lstm_array=[]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        lstm_array.append(data_array[start:stop, :])\n",
    "    return np.array(lstm_array)\n",
    "\n",
    "# function to generate labels\n",
    "def gen_label(id_df, seq_length, seq_cols,label):\n",
    "    df_zeros=pd.DataFrame(np.zeros((seq_length-1,id_df.shape[1])),columns=id_df.columns)\n",
    "    id_df=df_zeros.append(id_df,ignore_index=True)\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    y_label=[]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        y_label.append(id_df[label][stop])\n",
    "    return np.array(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasos_de_tiempo=40\n",
    "columnas_secuencia=variables\n",
    "\n",
    "# generar data_train\n",
    "data_train=np.concatenate(list(list(gen_sequence(train[train['id']==id], pasos_de_tiempo, columnas_secuencia)) for id in train['id'].unique()))\n",
    "# generar label_train\n",
    "label_train=np.concatenate(list(list(gen_label(train[train['id']==id], pasos_de_tiempo, columnas_secuencia,'clase1')) for id in train['id'].unique()))\n",
    "\n",
    "# generar data_test\n",
    "data_test=np.concatenate(list(list(gen_sequence(test[test['id']==id], pasos_de_tiempo, columnas_secuencia)) for id in test['id'].unique()))\n",
    "# generar label_test\n",
    "label_test=np.concatenate(list(list(gen_label(test[test['id']==id], pasos_de_tiempo, columnas_secuencia,'clase1')) for id in test['id'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de dimensiones Data_train = 3\n",
      "tamaño de la tabla Data_train = (20531, 40, 24)\n",
      "total datos Data_train = 19709760\n",
      "------------------------------------------------------------\n",
      "numero de dimensiones Label_train = 1\n",
      "tamaño de la tabla Label_train = (20531,)\n",
      "total datos Label_train = 20531\n",
      "------------------------------------------------------------\n",
      "numero de dimensiones Data_test = 3\n",
      "tamaño de la tabla Data_test = (12996, 40, 24)\n",
      "total datos Data_test = 12476160\n",
      "------------------------------------------------------------\n",
      "numero de dimensiones Label_test = 1\n",
      "tamaño de la tabla Label_test = (12996,)\n",
      "total datos Label_test = 12996\n"
     ]
    }
   ],
   "source": [
    "print(\"numero de dimensiones Data_train =\", data_train.ndim)\n",
    "print(\"tamaño de la tabla Data_train =\", data_train.shape)\n",
    "print(\"total datos Data_train =\", data_train.size)\n",
    "print('-'*60)\n",
    "print(\"numero de dimensiones Label_train =\", label_train.ndim)\n",
    "print(\"tamaño de la tabla Label_train =\", label_train.shape)\n",
    "print(\"total datos Label_train =\", label_train.size)\n",
    "print('-'*60)\n",
    "print(\"numero de dimensiones Data_test =\", data_test.ndim)\n",
    "print(\"tamaño de la tabla Data_test =\", data_test.shape)\n",
    "print(\"total datos Data_test =\", data_test.size)\n",
    "print('-'*60)\n",
    "print(\"numero de dimensiones Label_test =\", label_test.ndim)\n",
    "print(\"tamaño de la tabla Label_test =\", label_test.shape)\n",
    "print(\"total datos Label_test =\", label_test.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir numero de variables y pasos de tiempo\n",
    "features =data_train.shape[2]\n",
    "time_steps =data_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busqueda del numero de celdas de memoria red LSTM\n",
    "\n",
    "A continuacion se relizara una busqueda del numero optimo de celdas de memoria \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para entrenar modelo LSTM\n",
    "def fit_model(n_cells):\n",
    "   # definir el modelo\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_cells, input_shape=(time_steps, features)))\n",
    "    model.add(Dense(1, activation='sigmoid' ))\n",
    "    # compilar el modelo\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    # entrenar el modelo\n",
    "    history = model.fit(data_train, label_train, epochs=30, batch_size=256, shuffle=False, verbose=1)\n",
    "    # evaluar el modelo\n",
    "    loss = model.evaluate(data_test, label_test, verbose=0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 11s 515us/step - loss: 0.5208\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 271us/step - loss: 0.3597\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.2293\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1790\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 270us/step - loss: 0.1579\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.1411\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1297\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1223\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1164\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.1115\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1074\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1038\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1000\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0952\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0904\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0865\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.0823\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 271us/step - loss: 0.0792\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0769\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.0749\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0735\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0724\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0715\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0708\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 271us/step - loss: 0.0702\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0694\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0686\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0679\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0672\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0666\n",
      ">1/10 param=10.000000, loss=0.023547\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.3921\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.2346\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1847\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.1551\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1380\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1291\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.1194\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1141\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1082\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.1038\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0995\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0957\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0925\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 271us/step - loss: 0.0902\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0883\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0861\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0833\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0807\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0780\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0756\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0732\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0710\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0688\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0669\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0654\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0641\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0631\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.0622\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0615\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0608\n",
      ">2/10 param=10.000000, loss=0.022943\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 6s 306us/step - loss: 0.4723\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.3411\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.2357\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.1885\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1619\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.1437\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1340\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.1293\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1186\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1150\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1097\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.1064\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.1023\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.0993\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.0962\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0939\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0911\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0886\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0860\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0834\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.0809\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0787\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.0767\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0748\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0730\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0713\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0698\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0682\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0670\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0657\n",
      ">3/10 param=10.000000, loss=0.030188\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 7s 323us/step - loss: 0.4422\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.3346\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.2682\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.2080\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.1720\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1521\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1390\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.1297\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1229\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1172\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1105\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1040\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0983\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0941\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0906\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0876\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0848\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0821\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0795\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0773\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0753\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0736\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0721\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0708\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.0697\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0687\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0677\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0669\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.0662\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0656\n",
      ">4/10 param=10.000000, loss=0.026095\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 7s 325us/step - loss: 0.4805\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.3597\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.2347\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.1745\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.1545\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1431\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1341\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.1274\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.1219\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.1171\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1128\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.1089\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1056\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1018\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0990\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0958\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0930\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0903\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0880\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0863\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0853\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0840\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0820\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0820\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0788\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0775\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0765\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0756\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0748\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0746\n",
      ">5/10 param=10.000000, loss=0.027779\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 7s 319us/step - loss: 0.5392\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.3744\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.2395\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.1698\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1437\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1297\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1212\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.1089\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1029\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0985\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0952\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0927\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0911\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0897\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0885\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0872\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0858\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0844\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0831\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0819\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0807\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0796\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0785\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0798\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0759\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0752\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0740\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0730\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0720\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0710\n",
      ">6/10 param=10.000000, loss=0.026608\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 7s 324us/step - loss: 0.4003\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.2993\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.2225\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1840\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1571\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.1418\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1298\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1232\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.1094\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1038\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0981\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0941\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0905\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0871\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0840\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0810\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0794\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0777\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0761\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0745\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0730\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0715\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.0703\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.0692\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0681\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0671\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0663\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0661\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0659\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0652\n",
      ">7/10 param=10.000000, loss=0.031565\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 7s 327us/step - loss: 0.4756\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.3569\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.2634\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.1931\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1590\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.1391\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1271\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.1200\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1151\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.1107\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.1052\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0997\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0927\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0892\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.0854\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0830\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0806\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.0788\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0777\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0772\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0765\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.0744\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0732\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0717\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0706\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0697\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0689\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0682\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0675\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0669\n",
      ">8/10 param=10.000000, loss=0.026049\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 8s 370us/step - loss: 0.5631\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.2609\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1750\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1499\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1329\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.1230\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1141\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.1056\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0990\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.0930\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0881\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0858\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.0808\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0809\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0747\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0742\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0718\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 272us/step - loss: 0.0706\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0699\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0690\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0682\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0670\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0674\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0637\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0672\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0644\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0630\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0621\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0611\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0608\n",
      ">9/10 param=10.000000, loss=0.021807\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 7s 333us/step - loss: 0.4003\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.2580\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.1971\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1608\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.1402\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1271\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.1185\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.1119\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.1067\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.1021\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0979\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0940\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0908\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0880\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0854\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0830\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0807\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0787\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0769\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 276us/step - loss: 0.0753\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0738\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0725\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0713\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 275us/step - loss: 0.0702\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0693\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0684\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 274us/step - loss: 0.0676\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 271us/step - loss: 0.0669\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 273us/step - loss: 0.0662\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0656\n",
      ">10/10 param=10.000000, loss=0.031805\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 7s 348us/step - loss: 0.3987\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.1871\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1359\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.1152\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1063\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0967\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0903\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0861\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0836\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0802\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0782\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0766\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0749\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0736\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.0722\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0712\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0700\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0690\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0681\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0672\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0665\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0658\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0653\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0649\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0636\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0626\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0620\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0612\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0604\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0597 0s - \n",
      ">1/10 param=30.000000, loss=0.024731\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 7s 349us/step - loss: 0.4337\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.2006\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1427\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1229\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1121\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.1069\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1045\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.1019\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0991\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0939\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0861\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0885\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0788\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0781\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0781\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0747\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0714\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0699\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0677\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0671\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0675\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0668\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0636\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0638\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0628\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0627\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0615\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0629\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0619\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0620\n",
      ">2/10 param=30.000000, loss=0.021486\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 7s 357us/step - loss: 0.3773\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1700\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1408\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.1214\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1102\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1062\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.1015\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0947\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0973\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0907\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0908\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0830\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0829\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0768\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0806\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0742\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0722\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0710\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0721\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0688\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0681\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0667\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0659\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0661\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0650\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0648\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0623\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0626\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0603\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0642\n",
      ">3/10 param=30.000000, loss=0.023570\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 7s 360us/step - loss: 0.3859\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1991\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1583\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.1305\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.1178\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.1074\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1033\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0982\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0921\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 279us/step - loss: 0.0905\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0823\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0847\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0800\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0770\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0730\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0741\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 7s 318us/step - loss: 0.0729\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0749\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0696\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0683\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0693\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0656\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0650\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0662\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0673\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0641\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0660\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0662\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0607\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0600\n",
      ">4/10 param=30.000000, loss=0.023106\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 7s 363us/step - loss: 0.3884\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.1814\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1349\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1195\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1103\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1039\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0993\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0954\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0919\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0861\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0824\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0809\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0796\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0792\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0801\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0790\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0774\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0759\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0750\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0740\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0733\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0735\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0720\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0719\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0707\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0717\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0672\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0721\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0670\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0676\n",
      ">5/10 param=30.000000, loss=0.024850\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 8s 367us/step - loss: 0.3373\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.1769\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1350\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1130\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0989\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0913\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0857\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 315us/step - loss: 0.0822\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 7s 319us/step - loss: 0.0796\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0775\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0755\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0737\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0722\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0708\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0696\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0685\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0674\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0664\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0654\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0645\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0637\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0629\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0622\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0615\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0609\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0602\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0596\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0591\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0586\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0583\n",
      ">6/10 param=30.000000, loss=0.023228\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 8s 370us/step - loss: 0.4326\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.2120\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1501\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1206\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1178\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1119\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1134\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1071\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.1013\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0946\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0928\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 305us/step - loss: 0.0887\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0889\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0820\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 310us/step - loss: 0.0831\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0768\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0766\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0720\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0721\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0730\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0671\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0650\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0642\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0635\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0615\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0660\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0610\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0627\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0595\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0618\n",
      ">7/10 param=30.000000, loss=0.020213\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 8s 372us/step - loss: 0.3755\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.1648\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.1257\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.1107\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.1024\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0909\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0857\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0867\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0844\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0822\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0779\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0757\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0734\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0721\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0715\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0711\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0686\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0665\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0659\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0637\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0634\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0624\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0625\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0637\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0609\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0601\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0590\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0586\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0585\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0582\n",
      ">8/10 param=30.000000, loss=0.024541\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 8s 383us/step - loss: 0.3184\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1729\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1359\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1215\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.1069\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1090\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0964\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1052\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0952\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0896\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0827\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0856\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0766\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0770\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0856\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0790\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0762\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0762\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0756\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0711\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 314us/step - loss: 0.0711\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0711\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0697\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0685\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 7s 318us/step - loss: 0.0674\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0658\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 7s 321us/step - loss: 0.0657\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0662\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0645\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0654\n",
      ">9/10 param=30.000000, loss=0.023382\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 8s 386us/step - loss: 0.3393\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.1681\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 311us/step - loss: 0.1377\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1207\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.1101\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1035\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0976\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0924\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0860\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0845\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0789\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0759\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0744\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0699\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0709\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0689\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0654\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0673\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0653\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0617\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0621\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0608\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0620\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0624\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0596\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0614\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.0598\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0582\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0592\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0598\n",
      ">10/10 param=30.000000, loss=0.023139\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 8s 387us/step - loss: 0.3562\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.1686\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.1315\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 278us/step - loss: 0.1149\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1063\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0992\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0919\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0936\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 277us/step - loss: 0.0958\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0843\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0803\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0774\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0748\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 281us/step - loss: 0.0738\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 280us/step - loss: 0.0774\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0708\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0749\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0683\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0728\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0655\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0787\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0710\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0649\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0632\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0703\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0619\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0662\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0600\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0613\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0590\n",
      ">1/10 param=50.000000, loss=0.022225\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 8s 394us/step - loss: 0.3283\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1683\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1340\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1188\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.1156\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1067\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1084\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0947\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0956\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0942\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0840\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0830\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0787\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0780\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0757\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0745\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0730\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0707\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0704\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0680\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0671\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0650\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0667\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0632\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0627\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0625\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0612\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0628\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0616\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0581\n",
      ">2/10 param=50.000000, loss=0.024524\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 8s 401us/step - loss: 0.3615\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1754\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1295\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1169\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1004\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1008\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0902\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0903\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0889\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0789\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0789\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0772\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0758\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0756\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0750\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0731\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0722\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0695\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0680\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0652\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0648\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0639\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0638\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0642\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0614\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0629\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0617\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0600\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0609\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0606\n",
      ">3/10 param=50.000000, loss=0.025812\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 8s 407us/step - loss: 0.3101\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1581\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1226\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1145\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1065\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1033\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.0972\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0893\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0850\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0889\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0799\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0769\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0770\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0722\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0705\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0687\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0699\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0669\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0644\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0668\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0625\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0614\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0634\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0593\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0622\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0578\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0588\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0569\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0584\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0568\n",
      ">4/10 param=50.000000, loss=0.021784\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 8s 412us/step - loss: 0.3811\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.2007\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1653\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1345\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1194\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1127\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1111\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1003\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0956\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0959\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0846\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0862\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0863\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0828\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0830\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0753\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0786\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0800\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0738\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0731\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0696\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0698\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0703\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0708\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0667\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0660\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0710\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0677\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0631\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0633\n",
      ">5/10 param=50.000000, loss=0.024379\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 9s 419us/step - loss: 0.3761\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.1818\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1384\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1212\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.1156\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1069\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0995\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0923\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0932\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0901\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0846\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0799\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0777\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0767\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0756\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0740\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0733\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0727\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0714\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0695\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0685\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0674\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0645\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0646\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0629\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0608\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0614\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0603\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0593\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0590\n",
      ">6/10 param=50.000000, loss=0.023855\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 9s 426us/step - loss: 0.3656\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1728\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1288\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1186\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.1120\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1101\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1066\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1005\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0955\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0905\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0912\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0773\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0827\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0793\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0797\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0761\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0733\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0698\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0716\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0762\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0665\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0662\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0662\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0670\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0633\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0631\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0643\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0599\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0593\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0611\n",
      ">7/10 param=50.000000, loss=0.023517\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 9s 427us/step - loss: 0.3463\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1532\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1193\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1191\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.1275\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1094\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1013\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0927\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0850\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0860\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0848\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0757\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0742\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0716\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0691\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0691\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0694\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0685\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0672\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0661\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0657\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0640\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0642\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0617\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0633\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0625\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0619\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0599\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0604\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0597\n",
      ">8/10 param=50.000000, loss=0.025229\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 9s 432us/step - loss: 0.3275\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1587\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 309us/step - loss: 0.1252\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1085\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1020\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0965\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0857\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0850\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0857\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0812\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0754\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0776\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0767\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0768\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0752\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0732\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0715\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0702\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0677\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0710\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0710\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0703\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0655\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0647\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0667\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0626\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0634\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0627\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0610\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0604\n",
      ">9/10 param=50.000000, loss=0.025747\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 9s 438us/step - loss: 0.3287\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1631\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1231\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1077\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.1170\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0990\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0926\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0884\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0812\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0781\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0773\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0757\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0759\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0734\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0718\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0707\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0694\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0681\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0668\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0657\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0647\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0638\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0630\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0622\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0614\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0607\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0601\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0595\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0590\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0585\n",
      ">10/10 param=50.000000, loss=0.023552\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 9s 441us/step - loss: 0.3249\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1556\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1330\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1194\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1151\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.1138\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1060\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1033\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.1026\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0907\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0915\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 308us/step - loss: 0.0899\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 309us/step - loss: 0.0850\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.0898\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0804\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 308us/step - loss: 0.0770\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 314us/step - loss: 0.0754\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 7s 325us/step - loss: 0.0738\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 305us/step - loss: 0.0742\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0738\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0760\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0686\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0698\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0684\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0663\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0737\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0668\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0623\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0614\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0618\n",
      ">1/10 param=70.000000, loss=0.023400\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 9s 443us/step - loss: 0.3066\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.1446\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1191\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.1158\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1083\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0978\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0945\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0884\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0894\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0823\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0886\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0851\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0769\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0722\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0749\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0803\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0742\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0704\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0761\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0681\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0708\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0680\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0717\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0673\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0734\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0653\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0670\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0632\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0642\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0657\n",
      ">2/10 param=70.000000, loss=0.024990\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 9s 451us/step - loss: 0.3027\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.1561\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1216\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1174\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1034\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1009\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0952\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0929\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0853\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0880\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0826\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0843\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0825\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0776\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0763\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 306us/step - loss: 0.0748\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0733\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0732\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0704\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0674\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0688\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0773\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0659\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0633\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0623\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0610\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0633\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0603\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0582\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0605\n",
      ">3/10 param=70.000000, loss=0.020558\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 9s 461us/step - loss: 0.3393\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1511\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1248\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1144\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1021\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1064\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1009\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0897\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0903\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0821\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0798\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0801\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0785\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0759\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0746\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0741\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0724\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0714\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0708\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0698\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0690\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0675\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0661\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0648\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0633\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0617\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0604\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0594\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0585\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0578\n",
      ">4/10 param=70.000000, loss=0.021048\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 9s 460us/step - loss: 0.3313\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1590\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1284\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1122\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1133\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1128\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0989\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0999\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0923\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 314us/step - loss: 0.0865\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 7s 328us/step - loss: 0.0845\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 7s 325us/step - loss: 0.0862\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0847\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0787\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0812\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0752\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0751\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0735\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0725\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0716\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0699\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0682\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0667\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0655\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0644\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0630\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0622\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0611\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0589\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0627\n",
      ">5/10 param=70.000000, loss=0.022223\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 10s 466us/step - loss: 0.3012\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1670\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1317\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1171\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1153\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1116\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1054\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0973\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1000\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0932\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0840\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0830\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0789\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0826\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0774\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0789\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0727\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0694\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0685\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0668\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0682\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0656\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0636\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0607\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0595\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0588\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0590\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0576\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0647\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0606\n",
      ">6/10 param=70.000000, loss=0.022519\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 10s 474us/step - loss: 0.3412\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1505\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1378\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1107\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.1119\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1079\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0999\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0948\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0896\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0872\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0836\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0824\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0797\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0780\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0764\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0751\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0730\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0724\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0686\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0697\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0669\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0676\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0640\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0646\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0632\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0622\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0618\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0612\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0605\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0600\n",
      ">7/10 param=70.000000, loss=0.023773\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 10s 476us/step - loss: 0.3311\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.1576\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.1256\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1109\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1135\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1007\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0940\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0993\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0854\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0869\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0810\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0827\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0777\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0744\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0761\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0706\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0680\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0695\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0668\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0648\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0637\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0620\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0647\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0614\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0608\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0602\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0584\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0572\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0570\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0582\n",
      ">8/10 param=70.000000, loss=0.020605\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 10s 487us/step - loss: 0.2995\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1455\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1278\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1159\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1030\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0975\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0949\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0926\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0882\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0923\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0883\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0822\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0775\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0750\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0750\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0718\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0714\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0696\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0696\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0657\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0879\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0705\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0695\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0650\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0648\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0623\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0623\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.0618\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0609\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0602\n",
      ">9/10 param=70.000000, loss=0.021503\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 10s 498us/step - loss: 0.3167\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 312us/step - loss: 0.1525\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 7s 325us/step - loss: 0.1319\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.1158\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1093\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0982\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1092\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0994\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0899\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0842\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.0818\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 310us/step - loss: 0.0823\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 317us/step - loss: 0.0791\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0759\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0738\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0717\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0703\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0689\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0680\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0674\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0670\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0659\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0643\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0639\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0628\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0621\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0613\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0609\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0602\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0593\n",
      ">10/10 param=70.000000, loss=0.022267\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 10s 497us/step - loss: 0.3168\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1388\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 7s 320us/step - loss: 0.1127\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 7s 322us/step - loss: 0.1339\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 7s 323us/step - loss: 0.1103\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 7s 330us/step - loss: 0.1097\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 312us/step - loss: 0.1006\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 7s 318us/step - loss: 0.1010\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 7s 319us/step - loss: 0.1068\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 7s 320us/step - loss: 0.0971\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 316us/step - loss: 0.0927\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 7s 321us/step - loss: 0.0943\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0942\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 306us/step - loss: 0.0982\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 306us/step - loss: 0.0879\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0871\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0899\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0801\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0744\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0833\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0763\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0805\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0758\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0804\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0771\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0700\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.0664\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0645\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0628\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0709\n",
      ">1/10 param=100.000000, loss=0.024731\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 10s 502us/step - loss: 0.3209\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1520\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1363\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1151\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1209\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.1179\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1124\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1025\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1012\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0932\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0948\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0919\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0889\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0831\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0843\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0848\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0803\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0869\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0790\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0779\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0742\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0675\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0693\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0656\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0653\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0634\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0627\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0645\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0609\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0603\n",
      ">2/10 param=100.000000, loss=0.021853\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 11s 512us/step - loss: 0.3316\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 315us/step - loss: 0.1607\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 308us/step - loss: 0.1524\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.1185\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.1117\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1143\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.1271\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1129\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1027\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1018\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0980\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0910\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0941\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0855\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0785\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0804\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0701\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0753\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0663\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0690\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0649\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0611\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0620\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0602\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0589\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 309us/step - loss: 0.0569\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0583\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0597\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0559\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0561\n",
      ">3/10 param=100.000000, loss=0.019874\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 11s 517us/step - loss: 0.3088\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1508\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.1219\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1252\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1108\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0991\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1141\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0959\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0922\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0924\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1029\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0900\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0792\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0783\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0776\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0746\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0752\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0762\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.0718\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0696\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0671\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0684\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0652\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0635\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0629\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0619\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0618\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0620\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0605\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0609\n",
      ">4/10 param=100.000000, loss=0.021404\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 11s 525us/step - loss: 0.3118\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.1673\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.1275\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1222\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.1163\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.1009\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1006\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1022\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0979\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1033\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0910\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0869\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0861\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0949\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0873\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0854\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0775\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0823\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0757\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0745\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0727\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 309us/step - loss: 0.0718\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 307us/step - loss: 0.0713\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0693\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0696\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0643\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0678\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0641\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0624\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0614\n",
      ">5/10 param=100.000000, loss=0.021765\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 11s 524us/step - loss: 0.3120\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1637\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1251\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1184\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1047\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1094\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1103\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1099\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.1049\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0989\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1002\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0876\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0922\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0866\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0829\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0900\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0863\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0746\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0774\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0728\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0744\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0722\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0689\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0686\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0647\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0673\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0639\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0657\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0654\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0618\n",
      ">6/10 param=100.000000, loss=0.023902\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 11s 536us/step - loss: 0.3280\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1589\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1418\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.1236\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1281\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.1164\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1074\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1037\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.1046\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0950\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 310us/step - loss: 0.0950\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0941\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0957\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0918\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0819\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0787\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0841\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0845\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0811\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0709\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0781\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0701\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0710\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0687\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0676\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0693\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0669\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0674\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0653\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0650\n",
      ">7/10 param=100.000000, loss=0.027468\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 11s 545us/step - loss: 0.3055\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1642\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1253\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.1201\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.1175\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1129\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1144\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.1066 0s - loss: 0.106\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.1065\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0987\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0981\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0915\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0915\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0876\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0895\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0774\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0758\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0722\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0748\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0790\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0732\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0643\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0649\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0648\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0695\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0619\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.0643\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0617\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0641\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0610\n",
      ">8/10 param=100.000000, loss=0.023318\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 12s 562us/step - loss: 0.3087\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.1555\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.1293\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.1167\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.1146\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.1043\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.1036\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.1161\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.1020\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.1099\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 305us/step - loss: 0.0965\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 306us/step - loss: 0.0981\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0872\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0894\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 312us/step - loss: 0.0908\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 305us/step - loss: 0.0812\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0728\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0728\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 306us/step - loss: 0.0729\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0719\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0692\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0708\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.0695\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 306us/step - loss: 0.0682\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0664\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 311us/step - loss: 0.0641\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 315us/step - loss: 0.0628\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.0622\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 309us/step - loss: 0.0616\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0614\n",
      ">9/10 param=100.000000, loss=0.021452\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 11s 549us/step - loss: 0.2891\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1593\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.1277\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1209\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1129\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1163\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1054\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1095\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.1001\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0977\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0869\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0917\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0929\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0928\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 312us/step - loss: 0.0876\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 7s 335us/step - loss: 0.0795\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 7s 324us/step - loss: 0.0788\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 312us/step - loss: 0.0752\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0711\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0680\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 301us/step - loss: 0.0673\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0660\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0668\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0642\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0634\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 299us/step - loss: 0.0630\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0622\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0629\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 298us/step - loss: 0.0622\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0643\n",
      ">10/10 param=100.000000, loss=0.026307\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 11s 552us/step - loss: 0.2914\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1487\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1288\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.1174\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.2273\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.1165\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1087\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1108\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.1039\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1053\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0992\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0946\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0946\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0870\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0847\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0870\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0843\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0785\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0761\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0766\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0782\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.0766\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0771\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0722\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0773\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0693\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0727\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0700\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0682\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0657\n",
      ">1/10 param=200.000000, loss=0.025200\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 11s 558us/step - loss: 0.2722\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.1604\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1287\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1239\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1101\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1761\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1080\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1116\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1056\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0991\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1077\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0903\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0935\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0871\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0997\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0833\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0777\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0807\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0854\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0776\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0721\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0714\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0704\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0681\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0681\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0663\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0658\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0651\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0650\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0638\n",
      ">2/10 param=200.000000, loss=0.022380\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 12s 573us/step - loss: 0.2736\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1602\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1243\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1194\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1123\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1094\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1118\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1132\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1000\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0997\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1021\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0946\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0991\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0926\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0822\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0948\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0904\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0835\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0856\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0810\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0772\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0770\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0745\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0734\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0739\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0683\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0664\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0688\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0700\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0729\n",
      ">3/10 param=200.000000, loss=0.025448\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 12s 577us/step - loss: 0.2577\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.1353\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.1382\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.1156\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 283us/step - loss: 0.1228\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.1106\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 282us/step - loss: 0.0995\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 7s 317us/step - loss: 0.1183\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 297us/step - loss: 0.1056\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0991\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0956\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0943\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0987\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0960\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0966\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0956\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0917\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0861\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0955\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0852\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0843\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0941\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0884\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0808\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0797\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0724\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0727\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0700\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0780\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0815\n",
      ">4/10 param=200.000000, loss=0.029704\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 12s 577us/step - loss: 0.2677\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1470\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1445\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1195\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1151\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1152\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1044\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1042\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0996\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0971\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1029\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1077\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1025\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1034\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0972\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1111\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0976\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0905\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0871\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0813\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0778\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0790\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0782\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0788\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0849\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0709\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0700\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0688\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0676\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0656\n",
      ">5/10 param=200.000000, loss=0.023295\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 12s 589us/step - loss: 0.2744\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1645\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1226\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1193\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1148\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1121\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1033\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1009\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1017\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0971\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1059\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1000\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0994\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0997\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0891\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1087\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1031\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0940\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0818\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0906\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0826\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0807\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0839\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0734\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0770\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0715\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0741\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0708\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 285us/step - loss: 0.0761\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0743\n",
      ">6/10 param=200.000000, loss=0.025681\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 12s 600us/step - loss: 0.2826\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1486\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1367\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1154\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1073\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1209\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1088\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1082\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1051\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0989\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1080\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1027\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0981\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0925\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0949\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0901\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0953\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0890\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0904\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0955\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0895\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0795\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0833\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0790\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 294us/step - loss: 0.0753\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0681\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0652\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.0626\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0614\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 284us/step - loss: 0.0603\n",
      ">7/10 param=200.000000, loss=0.023230\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 12s 601us/step - loss: 0.2547\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1307\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1635\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.1152\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 293us/step - loss: 0.1156\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.1102\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1166\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1082\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0996\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1053\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0970\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0887\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0921\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1010\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0920\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0928\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0901\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.0890\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0833\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0842\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0994\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0817\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 295us/step - loss: 0.0864\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0777\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 296us/step - loss: 0.0686\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 304us/step - loss: 0.0661\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 300us/step - loss: 0.0684\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 303us/step - loss: 0.0708\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0773\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0929\n",
      ">8/10 param=200.000000, loss=0.029664\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 12s 607us/step - loss: 0.2509\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1548\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1383\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1247\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1190\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.1129\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1120\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1052\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0997\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0991\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0964\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0983\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0991\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0936\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0826\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0879\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0896\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0823\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0774\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0922\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0963\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0891\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0763\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0802\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0723\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0764\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0718\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0687\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0659\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0653\n",
      ">9/10 param=200.000000, loss=0.023047\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 13s 616us/step - loss: 0.2768\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 6s 286us/step - loss: 0.1660\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1305\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1181\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1183\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 6s 287us/step - loss: 0.1095\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1028\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1223\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1053\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1052\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.1001\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.1946\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.1067\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0999\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0955\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0912\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0843\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0957\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0937\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0860\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 6s 302us/step - loss: 0.0850\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 6s 290us/step - loss: 0.0845\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0818\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0741\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0808\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 6s 291us/step - loss: 0.0818\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 6s 289us/step - loss: 0.0755\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 6s 292us/step - loss: 0.0676\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0664\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 6s 288us/step - loss: 0.0654\n",
      ">10/10 param=200.000000, loss=0.024026\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 14s 703us/step - loss: 0.3131\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 8s 369us/step - loss: 0.1532\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 8s 371us/step - loss: 0.1374\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 8s 371us/step - loss: 0.1278\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 8s 371us/step - loss: 0.1114\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 8s 371us/step - loss: 0.1389\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 8s 398us/step - loss: 0.1130\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 8s 371us/step - loss: 0.1169\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 8s 371us/step - loss: 0.1072\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 8s 372us/step - loss: 0.1003\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 8s 371us/step - loss: 0.0965\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 8s 371us/step - loss: 0.0947 0s - loss\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.0954\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0969\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.0983\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0890\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 8s 371us/step - loss: 0.0952\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0920\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0850\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0906\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 8s 371us/step - loss: 0.0784\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 8s 372us/step - loss: 0.0953\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0840\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.0792\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 8s 372us/step - loss: 0.0737\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0806\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 8s 372us/step - loss: 0.0749\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0708\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0721\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 8s 372us/step - loss: 0.0697\n",
      ">1/10 param=400.000000, loss=0.026019\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 15s 720us/step - loss: 0.2749\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1526 1s - \n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1386\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1356\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1263\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.1122\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1286 \n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1066\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0985\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1137\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1048\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1035\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1070\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1022\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1054\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1007\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0929\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0938\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0960\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0922\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 8s 372us/step - loss: 0.0931\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0932\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.0890\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.0904\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0907\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0809\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0754\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0683 0s - loss\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 8s 380us/step - loss: 0.0723\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0837\n",
      ">2/10 param=400.000000, loss=0.029093\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 15s 753us/step - loss: 0.2512\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1851\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1221\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1173\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1075\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.1109\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.1182\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1067\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1056\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0997\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0973\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0990\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0991\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0909\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0974\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1073\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1038\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0916 1 - ETA: 0s - loss: 0.09\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0937\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0938\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0886 0s - lo\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0916 1s -\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0922\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 8s 388us/step - loss: 0.0844\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0802\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0882\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0807\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0832\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0825\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0702\n",
      ">3/10 param=400.000000, loss=0.023762\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 15s 737us/step - loss: 0.2719\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1694 0s - loss\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1237\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1258\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1090\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1061\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1059\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1060\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.1035\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0932\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1031\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1256\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1175\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1021\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0955\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0905\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0878\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0834\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0790\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0909 \n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0892 2s - loss:  - ETA: \n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0846\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0689\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 8s 384us/step - loss: 0.0748\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0751\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 8s 380us/step - loss: 0.0682\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 8s 393us/step - loss: 0.0668\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 8s 391us/step - loss: 0.0628\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 8s 379us/step - loss: 0.0642\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 8s 379us/step - loss: 0.0659\n",
      ">4/10 param=400.000000, loss=0.031193\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 15s 740us/step - loss: 0.2570\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1573\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1271\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1181\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1069\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1229\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1220\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1086\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1020\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 8s 382us/step - loss: 0.1100\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1064\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1028\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1023\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0971\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0906\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 8s 385us/step - loss: 0.0965 1s -\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 8s 388us/step - loss: 0.0892\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0975\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 8s 379us/step - loss: 0.0900\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0831\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0817\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0858 1s \n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0795\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0753\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0729 0s - loss: 0.\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0775\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 8s 390us/step - loss: 0.0726\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0699\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0676\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0657\n",
      ">5/10 param=400.000000, loss=0.024052\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 15s 750us/step - loss: 0.2727\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1877\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1495\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1300\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1170\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1161\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1055\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1128\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1098\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1034\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0968\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1025\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1056\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 8s 379us/step - loss: 0.0979\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 8s 385us/step - loss: 0.0935\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0941\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0945\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0857\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0838\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.1000\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0873\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0803\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0783\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0864\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0892\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0774\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0693\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 8s 381us/step - loss: 0.0651\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 8s 387us/step - loss: 0.0656\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0637\n",
      ">6/10 param=400.000000, loss=0.023634\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 16s 763us/step - loss: 0.2832\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1550\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1375\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1250\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1562\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1335\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 8s 381us/step - loss: 0.1134\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.1091 0s - loss:\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1160\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.1052\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1038\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0981\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1030\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1022\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0935\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0949\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1051\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1023\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0946\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0968\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0865\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1006\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0866\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0860\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 8s 380us/step - loss: 0.0850\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0816\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0861 2s - loss:  - ETA: 0s - loss: 0.085\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0875\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0782\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0763\n",
      ">7/10 param=400.000000, loss=0.028471\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 16s 764us/step - loss: 0.2610\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1589\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1244\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1259\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1114\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1151\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 8s 388us/step - loss: 0.1017\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1044\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1046\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0984\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1003\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0899\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0929\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1051\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0953\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0919\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0929\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0895\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0960\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0827\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0825\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0787\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0791\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0869\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0804\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0754\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 8s 379us/step - loss: 0.0727\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0713\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0830\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0670\n",
      ">8/10 param=400.000000, loss=0.025624\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 16s 777us/step - loss: 0.2850\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1588\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 8s 387us/step - loss: 0.1272\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1318\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1264\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.1170\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 8s 381us/step - loss: 0.1114\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1088\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1162\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1031\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1093\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0975\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0998\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0989\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0966\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0951\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0944\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 8s 379us/step - loss: 0.0937 \n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 8s 389us/step - loss: 0.0945\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1051\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 8s 379us/step - loss: 0.0964\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0891\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0938\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0891\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0928 0s - loss: 0\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0844\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 8s 387us/step - loss: 0.0830 0s - loss: 0.08\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0800\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0765\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0765\n",
      ">9/10 param=400.000000, loss=0.029118\n",
      "Epoch 1/30\n",
      "20531/20531 [==============================] - 16s 786us/step - loss: 0.2560\n",
      "Epoch 2/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1752\n",
      "Epoch 3/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.1397\n",
      "Epoch 4/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1228\n",
      "Epoch 5/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1099\n",
      "Epoch 6/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.1082\n",
      "Epoch 7/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.1097\n",
      "Epoch 8/30\n",
      "20531/20531 [==============================] - 8s 373us/step - loss: 0.0984\n",
      "Epoch 9/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0965\n",
      "Epoch 10/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1108\n",
      "Epoch 11/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.1005\n",
      "Epoch 12/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.1013\n",
      "Epoch 13/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0952\n",
      "Epoch 14/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0997\n",
      "Epoch 15/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0943\n",
      "Epoch 16/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0974\n",
      "Epoch 17/30\n",
      "20531/20531 [==============================] - 8s 374us/step - loss: 0.0917\n",
      "Epoch 18/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0902\n",
      "Epoch 19/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0851\n",
      "Epoch 20/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0918\n",
      "Epoch 21/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0836\n",
      "Epoch 22/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0801\n",
      "Epoch 23/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0828\n",
      "Epoch 24/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0795\n",
      "Epoch 25/30\n",
      "20531/20531 [==============================] - 8s 378us/step - loss: 0.0736\n",
      "Epoch 26/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0742\n",
      "Epoch 27/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0723 0s - loss:\n",
      "Epoch 28/30\n",
      "20531/20531 [==============================] - 8s 377us/step - loss: 0.0701\n",
      "Epoch 29/30\n",
      "20531/20531 [==============================] - 8s 375us/step - loss: 0.0785\n",
      "Epoch 30/30\n",
      "20531/20531 [==============================] - 8s 376us/step - loss: 0.0715\n",
      ">10/10 param=400.000000, loss=0.030021\n",
      "              10         30         50         70        100        200  \\\n",
      "count  10.000000  10.000000  10.000000  10.000000  10.000000  10.000000   \n",
      "mean    0.026839   0.023224   0.024062   0.022289   0.023207   0.025167   \n",
      "std     0.003522   0.001449   0.001364   0.001445   0.002402   0.002624   \n",
      "min     0.021807   0.020213   0.021784   0.020558   0.019874   0.022380   \n",
      "25%     0.024172   0.023114   0.023526   0.021161   0.021531   0.023247   \n",
      "50%     0.026351   0.023305   0.024117   0.022245   0.022585   0.024613   \n",
      "75%     0.029585   0.024298   0.025053   0.023180   0.024523   0.025622   \n",
      "max     0.031805   0.024850   0.025812   0.024990   0.027468   0.029704   \n",
      "\n",
      "             400  \n",
      "count  10.000000  \n",
      "mean    0.027099  \n",
      "std     0.002809  \n",
      "min     0.023634  \n",
      "25%     0.024445  \n",
      "50%     0.027245  \n",
      "75%     0.029111  \n",
      "max     0.031193  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x270257e0a20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# realizar la evalaucion del desempeño de la red con cadas 7 configuraciones de celdas de memoria\n",
    "# debido a la naturaleza estocastica de las red LSTM se repete el experimento 10 veces por cada grupo de celdas de memoria\n",
    "\n",
    "features =data_train.shape[2]\n",
    "time_steps =data_train.shape[1]\n",
    "\n",
    "# definir el alcance de la búsqueda\n",
    "params = [10, 30, 50, 70, 100, 200, 400]\n",
    "n_repeats = 10\n",
    "\n",
    "# valores de parámetros de búsqueda de cuadrícula\n",
    "scores = DataFrame()\n",
    "\n",
    "for value in params:\n",
    "    # repite cada experimento varias veces\n",
    "    loss_values = list()\n",
    "    for i in range(n_repeats):\n",
    "        loss = fit_model(value)\n",
    "        loss_values.append(loss)\n",
    "        print( '>%d/%d param=%f, loss=%f' % (i+1, n_repeats, value, loss))\n",
    "    # almacenar resultados para este parámetro\n",
    "    scores[str(value)] = loss_values\n",
    "\n",
    "# estadísticas resumidas de resultados\n",
    "print(scores.describe())\n",
    "\n",
    "# grafica de cajas y bigotes de los resultados\n",
    "scores.boxplot()\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hallar el numero de celdas de memoria de las capas LSTM se ejecuta el modelo 10 veces con 7 configuraciones definidas entre 10 y 400 celdas de memoria, con la grafica de cajas y bigotes se comparara el desempeño del modelo para cada una de las diferentes configuraciones, partiendo que se busca minimizar la perdida del modelo se observa que la estructura de la capa oculta LSTM con 70 celdas de memoria registra la menor perdida media con 2.23% y la configuracion con 50 celdas de memoria indica\n",
    "la menor desviacion estandar con 0.14 %, considerando que, el objetivo es seleccionar una configuracion con un nivel de perdida bajo (mayor precision) y la menor varianza posible (mayor estabilidad), para este caso es viable seleccionar configuraciones entre 30, 50 y 70 celdas de memoria para la capa LSTM de la red neuronal profunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# exportar el grafico de cajas y bigotes\n",
    "box=scores.boxplot()\n",
    "plt.title(\"Ajuste celdas de memoria LSTM\")\n",
    "plt.xlabel(\"Numero de celdas de memoria\")\n",
    "plt.ylabel(\"Valor de perdida\")\n",
    "plt.savefig('box3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              10         30         50         70        100        200  \\\n",
      "count  10.000000  10.000000  10.000000  10.000000  10.000000  10.000000   \n",
      "mean    0.026839   0.023224   0.024062   0.022289   0.023207   0.025167   \n",
      "std     0.003522   0.001449   0.001364   0.001445   0.002402   0.002624   \n",
      "min     0.021807   0.020213   0.021784   0.020558   0.019874   0.022380   \n",
      "25%     0.024172   0.023114   0.023526   0.021161   0.021531   0.023247   \n",
      "50%     0.026351   0.023305   0.024117   0.022245   0.022585   0.024613   \n",
      "75%     0.029585   0.024298   0.025053   0.023180   0.024523   0.025622   \n",
      "max     0.031805   0.024850   0.025812   0.024990   0.027468   0.029704   \n",
      "\n",
      "             400  \n",
      "count  10.000000  \n",
      "mean    0.027099  \n",
      "std     0.002809  \n",
      "min     0.023634  \n",
      "25%     0.024445  \n",
      "50%     0.027245  \n",
      "75%     0.029111  \n",
      "max     0.031193  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# estadistica descriptiva\n",
    "print(scores.describe())\n",
    "# box and whisker plot of results\n",
    "scores.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Busqueda tamaño de lote (Batch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenar modelo LSTM\n",
    "def fit_model(n_batch):\n",
    "   # definir modelo\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(70, input_shape=(time_steps, features),kernel_initializer='glorot_normal'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compilar modelo\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    # entrenar modelo\n",
    "    history = model.fit(data_train, label_train, epochs=20, batch_size=n_batch, shuffle=False, verbose=0)\n",
    "    # evaluar modelo\n",
    "    loss = model.evaluate(data_test, label_test, verbose=0)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1/3 param=16.000000, loss=0.022579\n",
      ">2/3 param=16.000000, loss=0.020061\n",
      ">3/3 param=16.000000, loss=0.022701\n",
      ">1/3 param=32.000000, loss=0.022434\n",
      ">2/3 param=32.000000, loss=0.023430\n",
      ">3/3 param=32.000000, loss=0.024475\n",
      ">1/3 param=64.000000, loss=0.024442\n",
      ">2/3 param=64.000000, loss=0.025638\n",
      ">3/3 param=64.000000, loss=0.025265\n",
      ">1/3 param=128.000000, loss=0.026736\n",
      ">2/3 param=128.000000, loss=0.021972\n",
      ">3/3 param=128.000000, loss=0.024213\n",
      ">1/3 param=256.000000, loss=0.024617\n",
      ">2/3 param=256.000000, loss=0.025572\n",
      ">3/3 param=256.000000, loss=0.027227\n",
      ">1/3 param=512.000000, loss=0.029378\n",
      ">2/3 param=512.000000, loss=0.032352\n",
      ">3/3 param=512.000000, loss=0.024517\n",
      ">1/3 param=1024.000000, loss=0.034317\n",
      ">2/3 param=1024.000000, loss=0.031553\n",
      ">3/3 param=1024.000000, loss=0.029367\n",
      "             16        32        64       128       256       512      1024\n",
      "count  3.000000  3.000000  3.000000  3.000000  3.000000  3.000000  3.000000\n",
      "mean   0.021780  0.023446  0.025115  0.024307  0.025805  0.028749  0.031746\n",
      "std    0.001490  0.001021  0.000612  0.002383  0.001320  0.003955  0.002480\n",
      "min    0.020061  0.022434  0.024442  0.021972  0.024617  0.024517  0.029367\n",
      "25%    0.021320  0.022932  0.024854  0.023093  0.025095  0.026948  0.030460\n",
      "50%    0.022579  0.023430  0.025265  0.024213  0.025572  0.029378  0.031553\n",
      "75%    0.022640  0.023953  0.025451  0.025475  0.026399  0.030865  0.032935\n",
      "max    0.022701  0.024475  0.025638  0.026736  0.027227  0.032352  0.034317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e2b42dc828>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df7xcdX3n8de7CYSC0ptE6EJgvViQCkhvXI1lZe2FbACpkkZAEn/luvbRRsRHu1Rt8lAxobiIa6vbble3BZssdQsUpZvVaNqVjHaRjeHHDSEE4jWPtLn8bEpEKw+Ikc/+cb43GYaZe2funcl3zp338/E43Pme8z1n3meYfGfmc86cUURgZma94edyBzAzs8PHg76ZWQ/xoG9m1kM86JuZ9RAP+mZmPcSDvplZD2lq0Jd0kaRHJI1IWlln+SxJt6blmyX1p/kLJA2naaukJVXr9Em6XdLDknZIOqddO2VmZvVpovP0Jc0AdgKLgFFgC7AsIh6q6nMlcHZErJC0FFgSEVdIOhrYHxEHJJ0AbAVOTO11wN9HxI2SjgSOjogfdmQvzcwMaO6d/gJgJCJ2RcR+4BZgcU2fxcC6dPt2YKEkRcSzEXEgzT8KCABJxwJvBm4CiIj9HvDNzDqvmUF/HrCnqj2a5tXtkwb5Z4C5AJLeKGk7sA1YkZa/Cvgn4C8k3S/pRknHTGlPzMxsQs0M+qozr7Ym1LBPRGyOiDOBNwCrJB0FzAReB3whIuYDPwFecqzAzMzaa2YTfUaBk6vaJwGPNegzKmkm8AvA09UdImKHpJ8AZ6X+oxGxOS2+nQaDviRfHMjMbBIi4iVvyJt5p78FOE3SKemA61JgfU2f9cDydPsy4M6IiLTOTABJrwROB3ZHxBPAHkmnp3UWAg/RQER0bPrkJz/Z0e07u/N36+T80zt/IxO+04/iTJurgI3ADOBLEbFd0rXAPRGxnuKA7M2SRije4S9Nq58LrJT0U+AF4MqI2JuWfQj4cnoh2QW8b6IsnbB79+4cd9sWZc4Ozp+b8+eVK38z5R0iYgOwoWbeNVW3nwMur7PezcDNDbY5DLy+lbBmZjY1Pf+N3KGhodwRJq3M2cH5c3P+vHLln/DLWbkVp/t3d0Yzs24jiZjkgdxprVKp5I4waWXODs6fm/PnlSt/zw/6Zma9xOUdM7NpyOUdMzPzoF/mumCZs4Pz5+b8ebmmb2ZmHeeavpnZNOSavpmZedAvc12wzNnB+XNz/rxc0zczs45zTd/MbBpyTd/MzDzol7kuWObs4Py5OX9erumbmVnHuaZvZjYNuaZvZmYe9MtcFyxzdnD+3Jw/r66u6Uu6SNIjkkYkrayzfJakW9PyzZL60/wFkobTtFXSkpr1Zki6X9LX2rEzZmbdRlLd6bzzzmu4rKN5JqqXS5oB7AQWAaPAFmBZRDxU1edK4OyIWCFpKbAkIq6QdDSwPyIOSDoB2AqcGBEH0npXU/w4+rER8dYG9++avplNO6tXF1OnTKWmvwAYiYhdEbEfuAVYXNNnMbAu3b4dWKhitH52bIAHjgIOjt6STgJ+HbixtV0xMyu/NWvy3G8zg/48YE9VezTNq9snDfLPAHMBJL1R0nZgG7Ci6kXg88BHgRcmnb4NylwXLHN2cP7cnD+3SpZ7bWbQr1dgqq23NOwTEZsj4kzgDcAqSUdJeivwVETc21JaMzObkmZq+ucAqyPiwtReBRAR11f12Zj63C1pJvAEcFxtMV7SJuAjwKXAe4ADFGWfY4GvRsS769x/LF++nP7+fgD6+voYGBhgcHAQOPRq77bbbrtdprYEmza1b3uVSoW1a9cC0N/fz5o1a+rW9JsZ9GdSHMhdCDxKcSD3nRGxvarPB4HXVh3IfXtEvEPSKcCedCD3lcDdFAd891atOwh82AdyzayXSNDJoW3SB3JTDf4qYCOwA7gtIrZLulbSJanbTcBcSSPA1cDYaZ3nAlslDQN3AFdWD/jdYOyVsozKnB2cPzfnz2v58kqW+53ZTKeI2ABsqJl3TdXt54DL66x3M3DzBNuukOuIhplZJkNDee7X194xM5uGfO0dMzPzoF/mumCZs4Pz5+b8eeXK3/ODvplZL3FN38wsg1zX3vGgb2aWQdeepz/dlbkuWObs4Py5OX9ulSz32vODvplZL3F5x8wsA5d3zMys43p+0C9zXbDM2cH5c3P+9pozp3j33uwElZb6z5nTnpw9P+ibmbXDvn1FuabZadOm1vrv29eenK7pm5m1Qedr9K1t3zV9MzPzoN9tdcFWlDk7OH9uzp+Xr71jZmYd55q+mVkbuKZvZmZdp+cH/TLXBcucHZw/t7Lkl9TyVAZdXdOXdJGkRySNSFpZZ/ksSbem5Zsl9af5CyQNp2mrpCVp/smSNknaIWm7pN9p506Z2fQREXWnTZs2NVxmjU1Y05c0A9gJLAJGgS3Asoh4qKrPlcDZEbFC0lJgSURcIeloYH9EHJB0ArAVOBE4DjghIu6T9HLgXuA3qrdZtW3X9M2s602nmv4CYCQidkXEfuAWYHFNn8XAunT7dmChitH62Yg4kOYfBQRARDweEfel2z8GdgDzmt8dM+t1nfwBkumsmUF/HrCnqj3KSwfog33SIP8MMBdA0hslbQe2ASuqXgRIy/uB+cDm1uNPXVnqmvWUOTs4f25lz79mTSV3hCnJ9fjPbKJPvaMitR8yGvaJiM3AmZJeA6yT9I2IeA5A0suArwC/GxE/ahRgaGiI/v5+APr6+hgYGGBwcBA49MBNtj08PDyl9d122223u6FdqVRYu3YtwMHxsp5mavrnAKsj4sLUXgUQEddX9dmY+twtaSbwBHBcbTFe0ibgIxFxj6QjgK8BGyPij8a5f9f0zewlOl1Db9V0qulvAU6TdIqkI4GlwPqaPuuB5en2ZcCdERFpnZkpwCuB04HdKs6pugnYMd6Ab2Zm7TXhoJ9q8FcBGykOuN4WEdslXSvpktTtJmCupBHgamDstM5zga2ShoE7gCsjYi/wJuA9wPlVp3Re3NY9a9LYx6MyKnN2cP7cyp4/12/Mtkuux7+Zmj4RsQHYUDPvmqrbzwGX11nvZuDmOvP/L/WPA5iZNWX58on72Ev52jtmZm0wnWr6ZmY2TfT8oF/mumaZs4Pz5+b87RW08IO3EpVWfiBXKrbfBj0/6JuZtYNo4QdvJ/EjuXrJ16MmmbPb6+Wu6ZtZGbimb2bWQb72zuT0/KDfbXXBVpQ5Ozh/bmXP72vvTE7PD/pmZr3ENX0zKyVfe2ei/q7pm5n1vJ4f9Mtc1yxzdnD+3Mqe39femZyeH/TNrDvMmdPSd5WA1vrPmZN3/7qFa/pm1hW6rSZe9u27pm9mZh70y1zXLHN2cP7cnD8v1/TNzKzjXNM3s67QbTXxsm+/UU2/qV/OMjOzieklQ2z7zJ7dnu30fHmnzHXBMmcH58/N+durlasqF+/YKy31f/rp9uRsatCXdJGkRySNSFpZZ/ksSbem5Zsl9af5C6p++HyrpCXNbtPMzNpvwpq+pBnATmARMApsAZZFxENVfa4Ezo6IFZKWAksi4gpJRwP7I+KApBOArcCJQEy0zaptu6Zv1gO6rSbeaZ3f38mfp78AGImIXRGxH7gFWFzTZzGwLt2+HVioYrR+NiIOpPlHwcGffmlmm2Zm1mbNDPrzgD1V7dE0r26fNMg/A8wFkPRGSduBbcCKtLyZbR4W3VYXbEWZs4Pz5+b8uVWy3GszZ+/UOx5d+6GkYZ+I2AycKek1wDpJ32hymwcNDQ3R398PQF9fHwMDAwwODgKH/sdPtj08PDyl9d122223J9Nevry926tUKqxduxbg4HhZTzM1/XOA1RFxYWqvAoiI66v6bEx97pY0E3gCOK62GC9pE/AR4IiJtlm1jmv6Zj2g12r6nTaVmv4W4DRJp0g6ElgKrK/psx5Ynm5fBtwZEZHWmZkCvBI4Hdjd5DbNzKzNJhz0Uw3+KmAjsAO4LSK2S7pW0iWp203AXEkjwNXA2CmY5wJbJQ0DdwBXRsTeRtts5441a+zjURmVOTs4f27On1eu/E19IzciNgAbauZdU3X7OeDyOuvdDNzc7DbNzKyzfO0dM+sKrum3l6+nb2bWRVavznO/PT/ol7kuWObs4Py5OX9ea9ZUstxvzw/6Zma9xDV9M+sOnbwu8ZgMY4kmsV/tGPN8PX0z62oiOn8gt3Obb6jb3rT2fHmnzHXBMmcH58/N+fPKlb/nB30zs17imr6ZdQWfp99ePk/fzMw86Je5Lljm7OD8uTl/Xq7pm5lZx7mmb2ZdwTX99nJN38zMPOiXuS5Y5uzg/Lk5f16u6ZuZWce5pm9mXcE1/fZyTd/MzDzol7kuWObs4Py5OX9eXV3Tl3SRpEckjUhaWWf5LEm3puWbJfWn+Ysk3StpW/p7ftU6y9L8ByR9U9Ir2rVTZmZW34Q1fUkzgJ3AImAU2AIsi4iHqvpcCZwdESskLQWWRMQVkuYDT0bEY5LOAjZGxDxJM4HHgDMiYq+kzwDPRsTqOvfvmr5ZD3BNv72mUtNfAIxExK6I2A/cAiyu6bMYWJdu3w4sVDFa3x8Rj6X524GjJM0ClKZjVPzCwLEULwJmZtZBzQz684A9Ve3RNK9un4g4ADwDzK3pcylwf0Q8HxE/BT4AbCO94wduajl9G5S5Lljm7OD8uTl/XrnyN/PLWfV+66v2Q9K4fSSdCdwAXJDaR1AM+vOBXcCfAKuA6+oFGBoaor+/H4C+vj4GBgYYHBwEDj1wk20PDw9PaX233Xbb7W5oVyoV1q5dC3BwvKynmZr+OcDqiLgwtVcBRMT1VX02pj53p3r9E8BxERGSTgLuBN4XEXel/m8APh0RC1P7zcDKiLi4zv27pm/WA1zTb6+p1PS3AKdJOkXSkcBSYH1Nn/XA8nT7MuDONOD3AV8HVo0N+MmjwBmSjkvtRcCO5nfHzMwmY8JBP9XorwI2UgzMt0XEdknXSrokdbsJmCtpBLgaGDut8yrgVOATkobTdHw6uLsG+I6kB4AB4D+1dc+aNPbxqIzKnB2cPzfnzytX/mZq+kTEBmBDzbxrqm4/B1xeZ73raFCnj4gvAl9sJayZmU2Nr71jZl3BNf328rV3zMzMg36Z64Jlzg7On5vz55Urf88P+mZmvcQ1fTPrCq7pt5dr+mZm5kG/zHXBMmcH5z9cJLU8lUFZHv9GXNM3s46IiLrTpk2bGi6z6cs1fTPrCq7pt5dr+mZm5kG/zHXBMmcH58+tG/NLrUyVlvrPnp17716sq6+9Y2bWaa2WXnqtXNMurumb9ajVq4uprDzoj69RTd+DvtkEJnMKYxmes2UfNMuev9N8ILeBbqxrNqvM2aE8+Ruf1lj2Ux4ruQNMUSV3gCnxefpmZtZxLu+YTVLZywtlz1/2YxKd5pq+WZuVfdAse34bn2v6DZSlrlxPmbND+fMvX17JHeFF5sxp7Tx3aO089zlzcu/hi5X9+dPVNX1JF0l6RNKIpJV1ls+SdGtavllSf5q/SNK9kralv+dXrXOkpD+TtFPSw5IubddOmR0OQ0O5E7zYvn3FO/dmp02bWuu/b1/uPbR2mLC8I2kGsBNYBIwCW4BlEfFQVZ8rgbMjYoWkpcCSiLhC0nzgyYh4TNJZwMaImJfWWQPMiIiPS/o5YE5E7K1z/y7vmDXB166xapOu6Us6B1gdERem9iqAiLi+qs/G1OduSTOBJ4DjqkdrFSc77wVOjIjnJe0BfjkifjLB/XvQN2uCB32rNpWa/jxgT1V7NM2r2yciDgDPAHNr+lwK3J8G/L407w8k3SfpryX9YhNZ2q7MdcEyZwfnz63s+YeGKrkjTEk3X3un3tcRa1/vx+0j6UzgBuCCqvs9CbgrIq6WdDXwWeA99QIMDQ3R398PQF9fHwMDAwwODgKHHrjJtoeHh6e0vttuu52nvW7doYG/G/LkblcqFdauXQtwcLysp+PlHUknAXcC74uIu1J/Af8CvDwiXpB0MvDNiDizzv27vGNdqdvOE++18k635ek2UynvbAFOk3SKpCOBpcD6mj7rgeXp9mXAnWnA7wO+DqwaG/AB0ij+v4HBNGsh8BBmJbJmTe4EZq2bcNBPNfqrgI3ADuC2iNgu6VpJl6RuNwFzJY0AVwNjp3VeBZwKfELScJqOT8t+H1gt6QGKss7vtW2vWjD28aiMypwdyp/f137JrZI7wJTkevybup5+RGwANtTMu6bq9nPA5XXWuw64rsE2/wF4cythzcxsanwZBus4X5r48Oi1mn63HVPpNr72jnWdbhtEWtV1+Sfx4tqyrtphG4+vvdNAmeuaZc5eqOQO8CJlv3aNaOGaChFUWrwOg15ypnZeZX/+58rf84O+tU/rg2Zr/Ts9aPraNdYLXN6xtil7Tdnbz7t9a69G5Z2mzt4xa0ag+t/Nbtv2D/3XzCan58s7Za4Ldlt215TLpez5fe2dyen5Qd/MymndutwJysk1fWubsteUp8P2O2n2bHj66c7eRyt8jGF8rumbTXOtDoAeNHtTz5d3ylzXLHN2cP78KrkDTFEld4Ap6epr75g1q5MlhtmzO7dts17hmr5l023lhbLX9FvVbXla5WvvjM/X3rGu022Djgd9m0587Z0GylyXLXP2QiV3gCkpy+Mvqe4E9edP5qqoOZTl8W/E5+mbWUdERN1p06ZNDZfZ9OXyTgn4evSHR6+Vd8piuj7/O83n6ZdY2Z/A4/2jbbSo7Pts7ePnQnv1fHmnzHXBslx7ZLqWF8r83AHnz62ra/qSLpL0iKQRSSvrLJ8l6da0fLOk/jR/kaR7JW1Lf8+vs+56SQ9OdUd6ka89YmatmrCmL2kGsBNYBIwCW4BlEfFQVZ8rgbMjYoWkpcCSiLhC0nzgyYh4TNJZwMaImFe13tuBy9K6ZzW4/56v6TfiGnGb+ecGbRqZyimbC4CRiNgVEfuBW4DFNX0WA2PvO28HFqoYre+PiMfS/O3AUZJmpUAvA64Grmt9d8zar9VLQ7c6dduloa03NTPozwP2VLVH07y6fSLiAPAMMLemz6XA/RHxfGr/AfCHwLMtZm6rctcFK7kDTEm5H3vnz835J6eZs3fqfeatfcsybh9JZwI3ABek9gBwakT8x7H6/3iGhobo7y+69fX1MTAwwODgIHDogZtse3h4eErru+222253Q7tSqbB27VqAg+NlPc3U9M8BVkfEham9CiAirq/qszH1uVvSTOAJ4LiICEknAXcC74uIu1L/DwCfAPZTvPAcD3w3Igbr3H/P1PTnzOnsj2d32/XQu43P07fpZNLX3kmD+E5gIfAoxYHcd0bE9qo+HwReW3Ug9+0R8Q5JfcC3gWsj4isNtt8PfM0Hcj3o5ObH36aTSR/ITTX6q4CNwA7gtojYLulaSZekbjcBcyWNUBycHTut8yrgVOATkobTdHwb9qdtxj4elVGZs4Pz5+b8eeXK39Q3ciNiA7ChZt41VbefAy6vs951THB2TkTsBuq+yzczs/bytXe6iMsLefnxt+nEl1Y2MzMP+mWuC5Y5Ozh/bs6fV1fX9O3wCFT/Gw9t2/6h/5pZb3JNv4u4ppyXH3+bTlzTNzMzD/plrguWOTs4f27On1eu/D0/6JuZ9RLX9LuIa8p5dfpy+r72kR1O/o1cswm0+oLoF1Ero54v73RbXVBqZaq01H/27Nx792Ld9ti3rpI7wJSU/fF3/snxO/0u4neaZtZprumXmAf9vPz4Wzfr+Zq+JnGUzi82ZjbdTLua/pw59evZxeUH6k2bGi6rt505c3LsVSOV3AGmpOw12eXLK7kjTEnZH3/nn5xp907/6X2tvaOvAIOtrLAPfP0aAxgayp3ArHXTrqbfS+e6r15dTGZmtSb9G7m5edD38Qgza92ULrgm6SJJj0gakbSyzvJZkm5NyzenHztH0iJJ90ralv6en+YfLenrkh6WtF3Sp6e2e5NXhrpgRNSdNm3a1HBZGZThsR+P8+fl/JMz4aAvaQbwp8BbgDOAZZLOqOn2fmBfRJwKfA64Ic3fC7wtIl4LLAdurlrnsxHxy8B84E2S3jKlPTEzswlNWN6RdA6wOiIuTO1VABFxfVWfjanP3ZJmAk8Ax1XXZVTUKPYCJ0bE8zX38V+AByPiz+vcf8+Xd6w7+ZiKdbOplHfmAXuq2qNpXt0+EXEAeAaYW9PnUuD+OgN+H/A24FtNZDHrGmvW5E5g1rpmBv16RxFr3+uO20fSmRQln99+0UrFp4K/Av44InY1kaXtylwXLHN2KH9+f08iL+efnGbO0x8FTq5qnwQ81qDPaBrIfwF4GkDSScAdwHsj4gc16/0Z8P2I+Px4AYaGhujv7wegr6+PgYEBBgcHgUMP3FgbKlQqNFxe2x4eHh53+VS373b52+eddx6NNDqxaqwk2Q353e6NdqVSYe3atQAHx8t6mqnpzwR2AguBR4EtwDsjYntVnw8Cr42IFZKWAm+PiHek0s23gWsj4is1270OeA1weUS8MM79u6ZvZtaiKZ2nL+li4PPADOBLEfEpSdcC90TEeklHUZyZM5/iHf7SiNgl6ePAKuD7VZu7ADiS4hjAw8BYjf+/RsSNde7bg76ZWYumdJ5+RGyIiFdHxC9FxKfSvGsiYn26/VxEXB4Rp0bEgrH6fERcFxHHRMRA1fRURIxGhCLiNVXzXzLgHw5jH4/KqMzZwflzc/68cuWfdhdcMzOzxnwZhpbzuLxjZt1vSuUdMzObHnp+0C9zXbDM2cH5c3P+vFzTNzOzjpuWNf1Omj0bnn66s/dhZjZVPfMbua2+hvnArJn1Epd3Snz9FNc083L+vJx/cjzom5n1kGlX0299+y7vmNn04/P0zczMg/7y5ZXcESbNNc28nD8v55+cnh/0h4ZyJzAzO3x6vqZvZjYduaZvZmYe9MtcFyxzdnD+3Jw/L9f0zcys43q+pr96dTGZmU0nU/qN3Jz85Swzs9ZN6UCupIskPSJpRNLKOstnSbo1Ld8sqT/NXyTpXknb0t/zq9b5N2n+iKQ/ljp9fcxGKnnutg1c08zL+fNy/smZcNCXNAP4U+AtwBnAMkln1HR7P7AvIk4FPgfckObvBd4WEa8FlgM3V63zBeC3gNPSdNEU9mMKhvPcbRsMD5c3Ozh/bs6fV678zbzTXwCMRMSuiNgP3AIsrumzGFiXbt8OLFRRl7k/Ih5L87cDR6VPBScAx0bE3al28z+A35jy3kzKD/PcbRv88IflzQ7On5vz55UrfzOD/jxgT1V7NM2r2yciDgDPAHNr+lwK3B8Rz6f+oxNs08zM2qyZH1GpV2uvPfQ5bh9JZ1KUfC5oYZttNd4hA2lN3fndfpB79+7duSNMifPn5fx5ZcsfEeNOwDnAxqr2KmBVTZ+NwDnp9kyKWv7YmUEnATuBN1X1PwF4uKq9DPjvDe4/PHny5MlT61O9MbWZd/pbgNMknQI8CiwF3lnTZz3Fgdq7gcuAOyMiJPUBX6d4kbhrrHNEPC7px5J+FdgMvBf4k3p3Xu+UIzMzm5ymztOXdDHweWAG8KWI+JSka4F7ImK9pKMozsyZDzwNLI2IXZI+TvHJ4PtVm7sgIp6S9HpgLfDzwDeAD/nKamZmndX1X84yM7P26Zlr70j6kqSnJD1YM/9D6Ytn2yV9Jle+iUg6StL3JG1NWdek+V9O+R9M+3hE7qyNSOqTdLukhyXtkHRO1bIPSwpJr8iZsVq954yk/5zyPyDpjlTCRNIRktalLxzukLQqX3KQdLKkTSnLdkm/k+avlvSopOE0XVy1ztmS7k79t6VP8NlI2p1yDEu6J827POV7IVULxvo2/CLoYcxb7/kyR9LfSfp++js7zX9Xeg49IOm7kn6lZlszJN0v6WttDzrRgdzpMgFvBl4HPFg17zzg/wCzUvv43DnHyS/gZen2ERTHQn4VuDgtE/BXwAdyZx1nH9YBv5luHwn0pdsnU5wM8A/AK3LnnOA5cwEwM92+Abgh3X4ncEu6fTSwG+jPmP0E4HXp9sspTqY4A1gNfLhO/5nAA8CvpPZcYEbmx3937fMBeA1wOsVX6V9fNX8+cGK6fRbwaJc8Xz4DrEy3V1Y9X/4tMDvdfguwuWZbVwP/E/hau3P2zDv9iPgOxfGGah8APh3FdweIiKcOe7AmReFfUvOINEVEbEjLAvgexdlSXUfSsRT/KG4CiIj9ETH27ZTPAR+lOOOga9R7zkTE30bxXRSA/8ehxzuAYyTNpDhOtR/40eHKWisiHo+I+9LtHwM7GP+7MBcAD0TE1rTOP0fEzzqftDURsSMiHqkzv+4XQQ9ztnpjTPUXV9eRvoQaEd+NiH1pfvXzCEknAb8O3NiJnD0z6DfwauDfpesFfVvSG3IHGk/6yDcMPAX8XURsrlp2BPAe4Ju58k3gVcA/AX+RPrbeKOkYSZdQvCvbmjnfZPwHipMQoPgm+k+Ax4F/BD4bEbUDQBbpWljzKT4dAlyVygpfGis3UPxbCEkbJd0n6aMZotYK4G9Tuea3Wliv+ouguf1iRDwOxQsxcHydPu/n0PMIipNmPgq80IlAvT7ozwRmU5RJPgLclu/CbxOLiJ9FxADFu4IFks6qWvzfgO9ExN/nSTehmRQffb8QEfMpBsjVwMeAazLmmhRJHwMOAF9OsxYAPwNOBE4Bfk/SqzLFO0jSy4CvAL8bET+iuObVLwEDFC9Qf5i6zgTOBd6V/i6RtPDwJ36RN0XE6yjKHx+U9OaJVqj6IuhvdzpcO0g6j2LQ//3UfivwVETc26n77PVBfxT4aqqOfI/ilbVrDiQ2ksoiFdJF6iR9EjiOog7YrUaB0apPJ7dTvAicAmyVtJvixew+Sf8qT8TmSFoOvBV4VyqrQVHT/2ZE/DSVCe8CXt9oG4dD+vT3FeDLEfFVgIh4Mr15eAH4c4oXKyj+/3w7IvZGxLPABor/P9mMlWvS43kHh7LWlcoidwDvjYgfdD5hU55Uca0x0t+DJWRJZ1OUcBZHxD+n2W8CLkn/Hm4Bzpf0l+0M1OuD/t8A5wNIejXFwcW9WRM1IOm4qjNFfh7498DDkn4TuBBYlv4hd6WIeALYI+n0NGshcF9EHB8R/RHRTzHwvC717d/EoogAAAFrSURBVEqSLqJ4V3ZJGhzH/CPFP1BJOobi0+PDOTICpE+sNwE7IuKPquafUNVtCTB2pslG4GxJR6fjEr8GPHS48tZKpb+Xj92mOObw4Dj9634RtAuMfXGV9Pd/AUj618BXgfdExM6xzhGxKiJOSv8ellJ80fXdbU3U7iPD3TpRnNnyOPBTisHl/RSD/F9SPJnuA87PnXOc/GcD91OcYfEgcE2afwD4AcU1oofH5nfjRFFSuCftw9+Qzl6oWr6b7jp7p95zZoTi4oJjj/cXU9+XAX9NcRDxIeAjmbOfS1ETf6Aq68UUX6LcluavB06oWufdKf+DwGcy538VsDVN24GPpflL0v+L54EnSZeIAT5OUTIcrpoO69l4DZ4vc4FvUXxB9VvAnNT3RmBfVdZ76mxvkA6cveMvZ5mZ9ZBeL++YmfUUD/pmZj3Eg76ZWQ/xoG9m1kM86JuZ9RAP+mZmPcSDvplZD/Ggb2bWQ/4/ZSGow3hgiNsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "features =data_train.shape[2]\n",
    "time_steps =data_train.shape[1]\n",
    "\n",
    "\n",
    "params = [16, 32, 64, 128, 256, 512, 1024]\n",
    "n_repeats = 3\n",
    "\n",
    "\n",
    "scores = DataFrame()\n",
    "\n",
    "for value in params:\n",
    "    # repetir\n",
    "    loss_values = list()\n",
    "    for i in range(n_repeats):\n",
    "        loss = fit_model(value)\n",
    "        loss_values.append(loss)\n",
    "        print( '>%d/%d param=%f, loss=%f' % (i+1, n_repeats, value, loss))\n",
    "    # almacenar\n",
    "    scores[str(value)] = loss_values\n",
    "\n",
    "# estadisticas resumidas\n",
    "print(scores.describe())\n",
    "\n",
    "# graficar\n",
    "scores.boxplot()\n",
    "#pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presenta la grafica de cajas y bigotes con los resultados finales con el proposito de medir el desempeño y variacion del modelo, el tamaño de lote con valor de 16 da como resultado la menor perdida media con 2.18% y una desviacion estandar de 0.15%. Para encontrar un balance entre velocidad de\n",
    "aprendizaje y menor perdida, se selecciona como tamaño de lote optimo para el modelo\n",
    "el valor de 32 con una perdida media de 2.34% y una desviacion estandar de 0.1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# exportar grafico\n",
    "box8=scores.boxplot()\n",
    "plt.title(\"Ajuste tamaño de lote LSTM\")\n",
    "plt.xlabel(\"Tamaño de lote\")\n",
    "plt.ylabel(\"Valor de perdida\")\n",
    "plt.savefig('box8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar tamaño de lote 8 y 16 para compararlo\n",
    "\n",
    "def fit_model(n_batch):\n",
    "   \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(time_steps, features),kernel_initializer='glorot_normal'))\n",
    "    model.add(Dense(1, activation='sigmoid' ))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    history = model.fit(data_train, label_train, epochs=20, batch_size=n_batch, shuffle=False, verbose=1)\n",
    "    \n",
    "    loss = model.evaluate(data_test, label_test, verbose=0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/20\n",
      "20531/20531 [==============================] - 142s 7ms/step - loss: 0.2310\n",
      "Epoch 2/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.1561\n",
      "Epoch 3/20\n",
      "20531/20531 [==============================] - 132s 6ms/step - loss: 0.1351\n",
      "Epoch 4/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.1235\n",
      "Epoch 5/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.1194\n",
      "Epoch 6/20\n",
      "20531/20531 [==============================] - 133s 7ms/step - loss: 0.1144\n",
      "Epoch 7/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.1080\n",
      "Epoch 8/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.1083\n",
      "Epoch 9/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.1184\n",
      "Epoch 10/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.0993\n",
      "Epoch 11/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.0935\n",
      "Epoch 12/20\n",
      "20531/20531 [==============================] - 132s 6ms/step - loss: 0.0902\n",
      "Epoch 13/20\n",
      "20531/20531 [==============================] - 130s 6ms/step - loss: 0.1052\n",
      "Epoch 14/20\n",
      "20531/20531 [==============================] - 131s 6ms/step - loss: 0.0788\n",
      "Epoch 15/20\n",
      "20531/20531 [==============================] - 130s 6ms/step - loss: 0.0780\n",
      "Epoch 16/20\n",
      "20531/20531 [==============================] - 130s 6ms/step - loss: 0.0840\n",
      "Epoch 17/20\n",
      "20531/20531 [==============================] - 130s 6ms/step - loss: 0.0850\n",
      "Epoch 18/20\n",
      "20531/20531 [==============================] - 130s 6ms/step - loss: 0.0739\n",
      "Epoch 19/20\n",
      "20531/20531 [==============================] - 130s 6ms/step - loss: 0.0796\n",
      "Epoch 20/20\n",
      "20531/20531 [==============================] - 130s 6ms/step - loss: 0.0691\n",
      ">1/2 param=8.000000, loss=0.023051\n",
      "Epoch 1/20\n",
      "20531/20531 [==============================] - 135s 7ms/step - loss: 0.2200\n",
      "Epoch 2/20\n",
      "20531/20531 [==============================] - 134s 7ms/step - loss: 0.1419\n",
      "Epoch 3/20\n",
      "20531/20531 [==============================] - 134s 7ms/step - loss: 0.1323\n",
      "Epoch 4/20\n",
      "20531/20531 [==============================] - 135s 7ms/step - loss: 0.1225\n",
      "Epoch 5/20\n",
      "20531/20531 [==============================] - 135s 7ms/step - loss: 0.1189\n",
      "Epoch 6/20\n",
      "20531/20531 [==============================] - 134s 7ms/step - loss: 0.1158\n",
      "Epoch 7/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.1167\n",
      "Epoch 8/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.1080\n",
      "Epoch 9/20\n",
      "20531/20531 [==============================] - 135s 7ms/step - loss: 0.1027\n",
      "Epoch 10/20\n",
      "20531/20531 [==============================] - 135s 7ms/step - loss: 0.1074\n",
      "Epoch 11/20\n",
      "20531/20531 [==============================] - 135s 7ms/step - loss: 0.0915\n",
      "Epoch 12/20\n",
      "20531/20531 [==============================] - 135s 7ms/step - loss: 0.0858\n",
      "Epoch 13/20\n",
      "20531/20531 [==============================] - 135s 7ms/step - loss: 0.0793\n",
      "Epoch 14/20\n",
      "20531/20531 [==============================] - 134s 7ms/step - loss: 0.0767\n",
      "Epoch 15/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.0765\n",
      "Epoch 16/20\n",
      "20531/20531 [==============================] - 133s 6ms/step - loss: 0.0730\n",
      "Epoch 17/20\n",
      "20531/20531 [==============================] - 134s 7ms/step - loss: 0.0706\n",
      "Epoch 18/20\n",
      "20531/20531 [==============================] - 135s 7ms/step - loss: 0.0701\n",
      "Epoch 19/20\n",
      "20531/20531 [==============================] - 135s 7ms/step - loss: 0.0662\n",
      "Epoch 20/20\n",
      "20531/20531 [==============================] - 135s 7ms/step - loss: 0.0637\n",
      ">2/2 param=8.000000, loss=0.020259\n",
      "Epoch 1/20\n",
      "20531/20531 [==============================] - 78s 4ms/step - loss: 0.2699\n",
      "Epoch 2/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.1524\n",
      "Epoch 3/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.1286\n",
      "Epoch 4/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.1306\n",
      "Epoch 5/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1147\n",
      "Epoch 6/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1209\n",
      "Epoch 7/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1379\n",
      "Epoch 8/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1169\n",
      "Epoch 9/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.1084\n",
      "Epoch 10/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0992\n",
      "Epoch 11/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.0887\n",
      "Epoch 12/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.0837\n",
      "Epoch 13/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.0816\n",
      "Epoch 14/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.0818\n",
      "Epoch 15/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.0798\n",
      "Epoch 16/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.0753\n",
      "Epoch 17/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.0741\n",
      "Epoch 18/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.0704\n",
      "Epoch 19/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0658\n",
      "Epoch 20/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0635\n",
      ">1/2 param=16.000000, loss=0.020622\n",
      "Epoch 1/20\n",
      "20531/20531 [==============================] - 77s 4ms/step - loss: 0.2799: 0s - \n",
      "Epoch 2/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1681\n",
      "Epoch 3/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1370\n",
      "Epoch 4/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1199\n",
      "Epoch 5/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1427\n",
      "Epoch 6/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1137\n",
      "Epoch 7/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1093\n",
      "Epoch 8/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1025\n",
      "Epoch 9/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.1267\n",
      "Epoch 10/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0971\n",
      "Epoch 11/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0887\n",
      "Epoch 12/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0817\n",
      "Epoch 13/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0782\n",
      "Epoch 14/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0811\n",
      "Epoch 15/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0727\n",
      "Epoch 16/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0757\n",
      "Epoch 17/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0753\n",
      "Epoch 18/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0664\n",
      "Epoch 19/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0742\n",
      "Epoch 20/20\n",
      "20531/20531 [==============================] - 76s 4ms/step - loss: 0.0725\n",
      ">2/2 param=16.000000, loss=0.037465\n",
      "              8        16\n",
      "count  2.000000  2.000000\n",
      "mean   0.021655  0.029044\n",
      "std    0.001974  0.011909\n",
      "min    0.020259  0.020622\n",
      "25%    0.020957  0.024833\n",
      "50%    0.021655  0.029044\n",
      "75%    0.022353  0.033254\n",
      "max    0.023051  0.037465\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "features =data_train.shape[2]\n",
    "time_steps =data_train.shape[1]\n",
    "\n",
    "\n",
    "params = [8, 16]\n",
    "n_repeats = 2\n",
    "\n",
    "\n",
    "scores = DataFrame()\n",
    "\n",
    "for value in params:\n",
    "    loss_values = list()\n",
    "    for i in range(n_repeats):\n",
    "        loss = fit_model(value)\n",
    "        loss_values.append(loss)\n",
    "        print( '>%d/%d param=%f, loss=%f' % (i+1, n_repeats, value, loss))\n",
    "    # almacenar\n",
    "    scores[str(value)] = loss_values\n",
    "\n",
    "\n",
    "print(scores.describe())\n",
    "\n",
    "\n",
    "scores.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamaño de lote en 8 aumenta significativamente el tiempo de entrenamiento de la red por lo que se descarta para este analisis, un tamaño de lote entre 32 y 128 mejora la velocidad de entrenamiento con un nivel de perdida aceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizacion - Busqueda % de abandono - Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# busqueda capa de abandono % de dropout\n",
    "\n",
    "def fit_model(n_dropout):\n",
    "   # definir modelo\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(70, input_shape=(time_steps, features),kernel_initializer='glorot_normal'))\n",
    "    model.add(Dropout(n_dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compilar modelo\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    # entrenar modelo\n",
    "    history = model.fit(data_train, label_train, epochs=20, batch_size=32, shuffle=False, verbose=0)\n",
    "    # evaluar modelo\n",
    "    loss = model.evaluate(data_test, label_test, verbose=0)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      ">1/3 param=0.100000, loss=0.024248\n",
      ">2/3 param=0.100000, loss=0.022994\n",
      ">3/3 param=0.100000, loss=0.023284\n",
      ">1/3 param=0.200000, loss=0.033632\n",
      ">2/3 param=0.200000, loss=0.022064\n",
      ">3/3 param=0.200000, loss=0.024520\n",
      ">1/3 param=0.400000, loss=0.022586\n",
      ">2/3 param=0.400000, loss=0.024508\n",
      ">3/3 param=0.400000, loss=0.021796\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      ">1/3 param=0.600000, loss=0.023393\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      ">2/3 param=0.600000, loss=0.023645\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      ">3/3 param=0.600000, loss=0.025695\n"
     ]
    }
   ],
   "source": [
    "features =data_train.shape[2]\n",
    "time_steps =data_train.shape[1]\n",
    "\n",
    "# % de abandono\n",
    "params = [0.1, 0.2, 0.4, 0.6]\n",
    "n_repeats = 3\n",
    "\n",
    "scores = DataFrame()\n",
    "\n",
    "for value in params:\n",
    "    # repetir\n",
    "    loss_values = list()\n",
    "    for i in range(n_repeats):\n",
    "        loss = fit_model(value)\n",
    "        loss_values.append(loss)\n",
    "        print( '>%d/%d param=%f, loss=%f' % (i+1, n_repeats, value, loss))\n",
    "    # almacenar resultados\n",
    "    scores[str(value)] = loss_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0.1       0.2       0.4       0.6\n",
      "count  3.000000  3.000000  3.000000  3.000000\n",
      "mean   0.023509  0.026739  0.022963  0.024245\n",
      "std    0.000657  0.006095  0.001395  0.001263\n",
      "min    0.022994  0.022064  0.021796  0.023393\n",
      "25%    0.023139  0.023292  0.022191  0.023519\n",
      "50%    0.023284  0.024520  0.022586  0.023645\n",
      "75%    0.023766  0.029076  0.023547  0.024670\n",
      "max    0.024248  0.033632  0.024508  0.025695\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# estadistica descriptiva resumida \n",
    "print(scores.describe())\n",
    "\n",
    "# grafica de cajas y bigotes\n",
    "scores.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la grafica de cajas y bigotes se observa que al incluir una capa de regularizacion donde se evaluan diferentes porcentajes de abandono, en este caso la capa con Dropout de valor 40% da como resultado la menor perdida media con 2.30% y una desviacion estandar de 0.14%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# exportar grafica\n",
    "box9=scores.boxplot()\n",
    "plt.title(\"Regularización capa LSTM\")\n",
    "plt.xlabel(\"Porcentaje de abandono\")\n",
    "plt.ylabel(\"Valor de perdida\")\n",
    "plt.savefig('box9.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de pesos por clase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste de pesos por desequilibrio de clases en la base de entrenamiento\n",
    "def fit_model(weights):\n",
    "   # definir modelo\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(70, input_shape=(time_steps, features),kernel_initializer='glorot_normal'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compilar modelo\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    # entrenar modelo\n",
    "    history = model.fit(data_train, label_train, epochs=20, batch_size=32, shuffle=False, verbose=2, class_weight=weights)\n",
    "    # evaluar modelo\n",
    "    loss = model.evaluate(data_test, label_test, verbose=0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 43s - loss: 0.2684\n",
      "Epoch 2/20\n",
      " - 42s - loss: 0.1713\n",
      "Epoch 3/20\n",
      " - 42s - loss: 0.1422\n",
      "Epoch 4/20\n",
      " - 42s - loss: 0.1274\n",
      "Epoch 5/20\n",
      " - 42s - loss: 0.1272\n",
      "Epoch 6/20\n",
      " - 42s - loss: 0.1086\n",
      "Epoch 7/20\n",
      " - 42s - loss: 0.1017\n",
      "Epoch 8/20\n",
      " - 42s - loss: 0.0958\n",
      "Epoch 9/20\n",
      " - 42s - loss: 0.0904\n",
      "Epoch 10/20\n",
      " - 42s - loss: 0.0867\n",
      "Epoch 11/20\n",
      " - 42s - loss: 0.0825\n",
      "Epoch 12/20\n",
      " - 42s - loss: 0.0780\n",
      "Epoch 13/20\n",
      " - 42s - loss: 0.0747\n",
      "Epoch 14/20\n",
      " - 42s - loss: 0.0737\n",
      "Epoch 15/20\n",
      " - 42s - loss: 0.0723\n",
      "Epoch 16/20\n",
      " - 42s - loss: 0.0708\n",
      "Epoch 17/20\n",
      " - 42s - loss: 0.0729\n",
      "Epoch 18/20\n",
      " - 42s - loss: 0.0622\n",
      "Epoch 19/20\n",
      " - 42s - loss: 0.0636\n",
      "Epoch 20/20\n",
      " - 42s - loss: 0.0610\n",
      "Epoch 1/20\n",
      " - 43s - loss: 0.2377\n",
      "Epoch 2/20\n",
      " - 42s - loss: 0.1452\n",
      "Epoch 3/20\n",
      " - 41s - loss: 0.1266\n",
      "Epoch 4/20\n",
      " - 42s - loss: 0.1225\n",
      "Epoch 5/20\n",
      " - 42s - loss: 0.1167\n",
      "Epoch 6/20\n",
      " - 42s - loss: 0.1148\n",
      "Epoch 7/20\n",
      " - 41s - loss: 0.1090\n",
      "Epoch 8/20\n",
      " - 41s - loss: 0.1168\n",
      "Epoch 9/20\n",
      " - 41s - loss: 0.1010\n",
      "Epoch 10/20\n",
      " - 41s - loss: 0.1002\n",
      "Epoch 11/20\n",
      " - 41s - loss: 0.0959\n",
      "Epoch 12/20\n",
      " - 41s - loss: 0.0915\n",
      "Epoch 13/20\n",
      " - 41s - loss: 0.0895\n",
      "Epoch 14/20\n",
      " - 41s - loss: 0.0829\n",
      "Epoch 15/20\n",
      " - 41s - loss: 0.0787\n",
      "Epoch 16/20\n",
      " - 41s - loss: 0.0769\n",
      "Epoch 17/20\n",
      " - 41s - loss: 0.0756\n",
      "Epoch 18/20\n",
      " - 41s - loss: 0.0727\n",
      "Epoch 19/20\n",
      " - 41s - loss: 0.0721\n",
      "Epoch 20/20\n",
      " - 41s - loss: 0.0702\n",
      "Epoch 1/20\n",
      " - 42s - loss: 0.2570\n",
      "Epoch 2/20\n",
      " - 41s - loss: 0.1519\n",
      "Epoch 3/20\n",
      " - 41s - loss: 0.1655\n",
      "Epoch 4/20\n",
      " - 41s - loss: 0.1404\n",
      "Epoch 5/20\n",
      " - 41s - loss: 0.1197\n",
      "Epoch 6/20\n",
      " - 42s - loss: 0.1132\n",
      "Epoch 7/20\n",
      " - 41s - loss: 0.1088\n",
      "Epoch 8/20\n",
      " - 41s - loss: 0.1050\n",
      "Epoch 9/20\n",
      " - 41s - loss: 0.0984\n",
      "Epoch 10/20\n",
      " - 41s - loss: 0.0928\n",
      "Epoch 11/20\n",
      " - 41s - loss: 0.0918\n",
      "Epoch 12/20\n",
      " - 41s - loss: 0.0822\n",
      "Epoch 13/20\n",
      " - 41s - loss: 0.0788\n",
      "Epoch 14/20\n",
      " - 41s - loss: 0.0755\n",
      "Epoch 15/20\n",
      " - 41s - loss: 0.0741\n",
      "Epoch 16/20\n",
      " - 41s - loss: 0.0728\n",
      "Epoch 17/20\n",
      " - 41s - loss: 0.0708\n",
      "Epoch 18/20\n",
      " - 41s - loss: 0.0694\n",
      "Epoch 19/20\n",
      " - 41s - loss: 0.0676\n",
      "Epoch 20/20\n",
      " - 41s - loss: 0.0668\n",
      "Epoch 1/20\n",
      " - 43s - loss: 0.8027\n",
      "Epoch 2/20\n",
      " - 42s - loss: 0.4397\n",
      "Epoch 3/20\n",
      " - 41s - loss: 0.3967\n",
      "Epoch 4/20\n",
      " - 42s - loss: 0.5610\n",
      "Epoch 5/20\n",
      " - 42s - loss: 0.3609\n",
      "Epoch 6/20\n",
      " - 42s - loss: 0.3347\n",
      "Epoch 7/20\n",
      " - 42s - loss: 0.3427\n",
      "Epoch 8/20\n",
      " - 42s - loss: 0.2724\n",
      "Epoch 9/20\n",
      " - 41s - loss: 0.2599\n",
      "Epoch 10/20\n",
      " - 41s - loss: 0.2519\n",
      "Epoch 11/20\n",
      " - 41s - loss: 0.2324\n",
      "Epoch 12/20\n",
      " - 42s - loss: 0.2273\n",
      "Epoch 13/20\n",
      " - 42s - loss: 0.2259\n",
      "Epoch 14/20\n",
      " - 42s - loss: 0.2178\n",
      "Epoch 15/20\n",
      " - 42s - loss: 0.2217\n",
      "Epoch 16/20\n",
      " - 42s - loss: 0.2246\n",
      "Epoch 17/20\n",
      " - 41s - loss: 0.2038\n",
      "Epoch 18/20\n",
      " - 41s - loss: 0.2015\n",
      "Epoch 19/20\n",
      " - 42s - loss: 0.1973\n",
      "Epoch 20/20\n",
      " - 42s - loss: 0.1963\n",
      "Epoch 1/20\n",
      " - 43s - loss: 0.8280\n",
      "Epoch 2/20\n",
      " - 41s - loss: 0.4583\n",
      "Epoch 3/20\n",
      " - 41s - loss: 0.4387\n",
      "Epoch 4/20\n",
      " - 41s - loss: 0.3642\n",
      "Epoch 5/20\n",
      " - 41s - loss: 0.3568\n",
      "Epoch 6/20\n",
      " - 41s - loss: 0.3423\n",
      "Epoch 7/20\n",
      " - 41s - loss: 0.4087\n",
      "Epoch 8/20\n",
      " - 41s - loss: 0.3344\n",
      "Epoch 9/20\n",
      " - 41s - loss: 0.3175\n",
      "Epoch 10/20\n",
      " - 41s - loss: 0.2863\n",
      "Epoch 11/20\n",
      " - 42s - loss: 0.2877\n",
      "Epoch 12/20\n",
      " - 42s - loss: 0.2613\n",
      "Epoch 13/20\n",
      " - 42s - loss: 0.3362\n",
      "Epoch 14/20\n",
      " - 42s - loss: 0.2784\n",
      "Epoch 15/20\n",
      " - 41s - loss: 0.2385\n",
      "Epoch 16/20\n",
      " - 41s - loss: 0.2320\n",
      "Epoch 17/20\n",
      " - 42s - loss: 0.2298\n",
      "Epoch 18/20\n",
      " - 42s - loss: 0.2230\n",
      "Epoch 19/20\n",
      " - 41s - loss: 0.2197\n",
      "Epoch 20/20\n",
      " - 42s - loss: 0.2123\n",
      "Epoch 1/20\n",
      " - 44s - loss: 0.7711\n",
      "Epoch 2/20\n",
      " - 42s - loss: 0.4914\n",
      "Epoch 3/20\n",
      " - 42s - loss: 0.3878\n",
      "Epoch 4/20\n",
      " - 42s - loss: 0.3632\n",
      "Epoch 5/20\n",
      " - 42s - loss: 0.4197\n",
      "Epoch 6/20\n",
      " - 42s - loss: 0.3622\n",
      "Epoch 7/20\n",
      " - 42s - loss: 0.3636\n",
      "Epoch 8/20\n",
      " - 42s - loss: 0.4302\n",
      "Epoch 9/20\n",
      " - 42s - loss: 0.2968\n",
      "Epoch 10/20\n",
      " - 42s - loss: 0.3128\n",
      "Epoch 11/20\n",
      " - 42s - loss: 0.2812\n",
      "Epoch 12/20\n",
      " - 42s - loss: 0.2584\n",
      "Epoch 13/20\n",
      " - 42s - loss: 0.2803\n",
      "Epoch 14/20\n",
      " - 42s - loss: 0.2631\n",
      "Epoch 15/20\n",
      " - 42s - loss: 0.2327\n",
      "Epoch 16/20\n",
      " - 42s - loss: 0.2251\n",
      "Epoch 17/20\n",
      " - 42s - loss: 0.2107\n",
      "Epoch 18/20\n",
      " - 42s - loss: 0.2121\n",
      "Epoch 19/20\n",
      " - 42s - loss: 0.2016\n",
      "Epoch 20/20\n",
      " - 42s - loss: 0.2112\n",
      "Epoch 1/20\n",
      " - 43s - loss: 2.2904\n",
      "Epoch 2/20\n",
      " - 42s - loss: 1.1805\n",
      "Epoch 3/20\n",
      " - 42s - loss: 1.1697\n",
      "Epoch 4/20\n",
      " - 42s - loss: 1.1847\n",
      "Epoch 5/20\n",
      " - 42s - loss: 1.0505\n",
      "Epoch 6/20\n",
      " - 42s - loss: 0.9686\n",
      "Epoch 7/20\n",
      " - 42s - loss: 1.0572\n",
      "Epoch 8/20\n",
      " - 42s - loss: 1.0419\n",
      "Epoch 9/20\n",
      " - 42s - loss: 0.8605\n",
      "Epoch 10/20\n",
      " - 42s - loss: 0.8298\n",
      "Epoch 11/20\n",
      " - 42s - loss: 0.8047\n",
      "Epoch 12/20\n",
      " - 42s - loss: 0.7687\n",
      "Epoch 13/20\n",
      " - 42s - loss: 0.7937\n",
      "Epoch 14/20\n",
      " - 42s - loss: 0.7608\n",
      "Epoch 15/20\n",
      " - 42s - loss: 0.7661\n",
      "Epoch 16/20\n",
      " - 42s - loss: 0.7004\n",
      "Epoch 17/20\n",
      " - 42s - loss: 0.7219\n",
      "Epoch 18/20\n",
      " - 42s - loss: 0.6895\n",
      "Epoch 19/20\n",
      " - 42s - loss: 0.6690\n",
      "Epoch 20/20\n",
      " - 42s - loss: 0.6394\n",
      "Epoch 1/20\n",
      " - 44s - loss: 2.3132\n",
      "Epoch 2/20\n",
      " - 43s - loss: 1.1624\n",
      "Epoch 3/20\n",
      " - 42s - loss: 1.1667\n",
      "Epoch 4/20\n",
      " - 42s - loss: 1.0625\n",
      "Epoch 5/20\n",
      " - 42s - loss: 1.2553\n",
      "Epoch 6/20\n",
      " - 42s - loss: 0.9637\n",
      "Epoch 7/20\n",
      " - 43s - loss: 0.9508\n",
      "Epoch 8/20\n",
      " - 42s - loss: 0.8562\n",
      "Epoch 9/20\n",
      " - 42s - loss: 0.7776\n",
      "Epoch 10/20\n",
      " - 42s - loss: 0.7788\n",
      "Epoch 11/20\n",
      " - 42s - loss: 0.8180\n",
      "Epoch 12/20\n",
      " - 42s - loss: 0.8264\n",
      "Epoch 13/20\n",
      " - 43s - loss: 0.7793\n",
      "Epoch 14/20\n",
      " - 43s - loss: 0.7990\n",
      "Epoch 15/20\n",
      " - 43s - loss: 0.7298\n",
      "Epoch 16/20\n",
      " - 42s - loss: 0.7558\n",
      "Epoch 17/20\n",
      " - 43s - loss: 0.8157\n",
      "Epoch 18/20\n",
      " - 42s - loss: 0.7416\n",
      "Epoch 19/20\n",
      " - 43s - loss: 0.8401\n",
      "Epoch 20/20\n",
      " - 45s - loss: 0.6091\n",
      "Epoch 1/20\n",
      " - 45s - loss: 2.1088\n",
      "Epoch 2/20\n",
      " - 43s - loss: 1.2735\n",
      "Epoch 3/20\n",
      " - 42s - loss: 1.1060\n",
      "Epoch 4/20\n",
      " - 42s - loss: 0.9948\n",
      "Epoch 5/20\n",
      " - 42s - loss: 0.8810\n",
      "Epoch 6/20\n",
      " - 42s - loss: 1.0631\n",
      "Epoch 7/20\n",
      " - 42s - loss: 1.0017\n",
      "Epoch 8/20\n",
      " - 42s - loss: 0.9866\n",
      "Epoch 9/20\n",
      " - 42s - loss: 0.7881\n",
      "Epoch 10/20\n",
      " - 42s - loss: 0.7896\n",
      "Epoch 11/20\n",
      " - 42s - loss: 0.7788\n",
      "Epoch 12/20\n",
      " - 42s - loss: 0.7784\n",
      "Epoch 13/20\n",
      " - 42s - loss: 0.7947\n",
      "Epoch 14/20\n",
      " - 42s - loss: 1.0207\n",
      "Epoch 15/20\n",
      " - 42s - loss: 0.8181\n",
      "Epoch 16/20\n",
      " - 42s - loss: 0.7943\n",
      "Epoch 17/20\n",
      " - 42s - loss: 0.7248\n",
      "Epoch 18/20\n",
      " - 42s - loss: 0.7036\n",
      "Epoch 19/20\n",
      " - 42s - loss: 0.8438\n",
      "Epoch 20/20\n",
      " - 42s - loss: 0.7523\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features =data_train.shape[2]\n",
    "time_steps =data_train.shape[1]\n",
    "\n",
    "# definir 3 posibles configuraciones de pesos de clase\n",
    "params = [{0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
    "n_repeats = 3\n",
    "\n",
    "\n",
    "scores = DataFrame()\n",
    "\n",
    "for value in params:\n",
    "    # repetir experimiento\n",
    "    loss_values = list()\n",
    "    for i in range(n_repeats):\n",
    "        loss = fit_model(value)\n",
    "        loss_values.append(loss)\n",
    "    # almacenar resultados\n",
    "    scores[str(value)] = loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       {0: 1, 1: 1}  {0: 1, 1: 10}  {0: 1, 1: 100}\n",
      "count      3.000000       3.000000        3.000000\n",
      "mean       0.023628       0.062752        0.301658\n",
      "std        0.002278       0.004072        0.065390\n",
      "min        0.020997       0.058750        0.226763\n",
      "25%        0.022960       0.060683        0.278784\n",
      "50%        0.024923       0.062616        0.330805\n",
      "75%        0.024943       0.064753        0.339106\n",
      "max        0.024963       0.066891        0.347407\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resultados estadistica descriptiva y grafico\n",
    "print(scores.describe())\n",
    "\n",
    "scores.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presenta la grafica de cajas y bigotes con las diferentes ponderaciones de clase, que se asignan para penalizar los errores de clasificacion de la clase minoritaria, cuando se establece un peso de 100 a la\n",
    "clase 1 el error de precision aumenta, ya que se genera un aumento de los falsos positivos, por lo tanto, el rango de valor de configuracion de peso para la clase minoritaria puede oscilar entre 1 y 10 para una precision equilibrada entre las dos clases del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# expotar grafica\n",
    "box11=scores.boxplot()\n",
    "plt.title(\"Ajuste de pesos por clase\")\n",
    "plt.xlabel(\"Ponderaciones de clase LSTM\")\n",
    "plt.ylabel(\"Valor de perdida\")\n",
    "plt.savefig('box11.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
